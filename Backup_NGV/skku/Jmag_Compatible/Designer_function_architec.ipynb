{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running date: August 01, 2022\n",
      "Pyleecan version:1.3.9\n",
      "SciDataTool version:2.4.8\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "print(\"Running date:\", date.today().strftime(\"%B %d, %Y\"))\n",
    "import pyleecan\n",
    "print(\"Pyleecan version:\" + pyleecan.__version__)\n",
    "import SciDataTool\n",
    "print(\"SciDataTool version:\" + SciDataTool.__version__)\n",
    "\n",
    "from SciDataTool import Data1D, DataLinspace, DataPattern, DataTime, DataFreq, VectorField\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# jmag 파일에서 공극 중앙에서 공극자속밀도 추출\n",
    "\n",
    "\n",
    "#Input.radius = 81.34*10^-3\n",
    "#Input.initial_angle=52.5;                % Motion 초기각도 설정   \n",
    "\n",
    "#공극자속밀도 기반으로 AGSF 계산\n",
    "\n",
    "#AGSF 기반으로 2D FFT 수행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JMAG acticex 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from win32com import client  #activeX연결 모듈\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#cont_path=u'c:/work/test/cont.png'\n",
    "#vect_path=u'c:/work/test/vect.png'\n",
    "jprojfile = u'D:\\KDH\\Thesis\\HDEV\\01_JMAG\\Mes_V_excit\\HDEV_V_excitation.jproj'\n",
    "dname=u'Gap magnetic flux density'\n",
    "\n",
    "\n",
    "app = client.dynamic.Dispatch('designer.Application.202') #제이맥 연결 버젼지정시   client.dynamic.Dispatch('designer.Application.180')\n",
    "#app.newproject('project X1')\n",
    "app.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "#import designer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import copy\n",
    "import importlib\n",
    "import gc\n",
    "#import psutil\n",
    "\n",
    "\n",
    "app = client.dynamic.Dispatch('designer.Application.202') #제이맥 연결 버젼지정시   client.dynamic.Dispatch('designer.Application.180')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN param\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "\n",
    "num_epoch = 50\n",
    "num_batch = 10\n",
    "ins_dir = \"\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version\n",
    "py_error = 0\n",
    "# NN param\n",
    "num_epoch = 50\n",
    "num_batch = 10\n",
    "ins_dir = \"\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show_message_immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_message_immediately(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (sys.version >= \"3.8\"):\n",
    "\ttry:\n",
    "\t\timport tensorflow as tf\n",
    "\t\tfrom tensorflow.python.eager import context\n",
    "\t\tfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\t\tfrom sklearn.preprocessing import StandardScaler\n",
    "\t\tfrom sklearn.svm import SVR\n",
    "\t\tfrom sklearn.tree import DecisionTreeRegressor\n",
    "\t\tfrom sklearn.model_selection import KFold\n",
    "\t\tfrom sklearn.metrics import r2_score\n",
    "\t\tfrom sklearn.metrics import mean_squared_error\n",
    "\t\tfrom pathlib import Path\n",
    "\t\ttf.get_logger().setLevel(\"ERROR\")\n",
    "\texcept:\n",
    "\t\ttitle_en = \"Python library error\"\n",
    "\t\ttitle_jp = \"Python�@���C�u�����G���[\"\n",
    "\t\tmessage_en = \"The runtime library cannot be found. Please refer to the manual for the required packages.\"\n",
    "\t\tmessage_jp = \"�����^�C�����C�u�������������܂����B�K�v�ȃp�b�P�[�W�̓}�j���A�����Q�Ƃ��Ă��������B\"\n",
    "\t\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\t\tpy_error = 1\n",
    "\n",
    "if (sys.version < \"3.8\"):\n",
    "\ttitle_en = \"Python Version Error\"\n",
    "\ttitle_jp = \"Python�@�o�[�W�����G���[\"\n",
    "\tmessage_en = \"Please use Python of newer version over 3.8\"\n",
    "\tmessage_jp = \"�o�[�W����3.8�ȏ���Python���g�p���Ă��������B\"\n",
    "\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\tpy_error = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class DialogData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DialogData:\n",
    "\tdef __init__(self):\n",
    "\t\tself.model_path = \"\"\n",
    "\t\tself.compute_mode=0\n",
    "\t\tself.bitmap_mode = 1\n",
    "\t\tself.bitmap_size= 1\n",
    "\t\tself.cross_val = 5\n",
    "\t\tself.cross_frag = 1\n",
    "\t\tself.num_thread = 8 \n",
    "\t\tself.input_dir = \"\"\n",
    "\t\tself.isValid  = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Topology_setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Topology_setting:\n",
    "\tdef __init__(self):\n",
    "\t\tself.num_study = 1\n",
    "\t\tself.AnalysisGroup = 0\n",
    "\t\tself.study_name = []\n",
    "\t\tself.equation_num_study = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "class Surrogate_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Surrogate_data:\n",
    "\tdef __init__(self):\n",
    "\t\tself.Readjcf_name = []\n",
    "\t\tself.OutJCF_name = []\n",
    "\t\tself.Readjcf_name_opt = \"\"\n",
    "\t\tself.bitmap_run_cmd = []\t\n",
    "\t\t\n",
    "\t\tself.Read_file_num = 0\n",
    "\t\tself.JCF_file_num = 0\n",
    "\t\tself.Response_name = []\n",
    "\t\tself.Response_num = 0\n",
    "\t\tself.Response_value = []\n",
    "\t\tself.Response_value_scale = []\n",
    "\t\tself.Response_multi_num = []\n",
    "\t\tself.equation_num_base = 0\n",
    "\t\tself.equation_num_study = []\n",
    "\t\t\n",
    "\t\tself.Bitmap_path = []\n",
    "\t\tself.Bitmap_path_tmp = []\n",
    "\t\tself.Bitmap_data = []\n",
    "\t\tself.Bitmap_data_scale = []\n",
    "\t\t\n",
    "\t\tself.model_path = []\n",
    "\t\tself.output_data = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Make_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Make_model:\n",
    "\tdef __init__(self):\n",
    "\t\tself.model_path = \"\"\n",
    "\t\tself.cross_frag = 1\n",
    "\t\tself.cross_val = 5\n",
    "\t\tself.num_thread = 8\n",
    "\t\tself.compute_mode = 1\n",
    "\t\tself.bitmap_size = 200\n",
    "\t\tself.Modelsavepath = \"\"\n",
    "\t\tself.Responsename = \"\"\n",
    "\t\tself.Res_val = None\n",
    "\t\tself.Bitmap_path_num = 0\n",
    "\t\tself.Bitmap_data = None\n",
    "\t\tself.Bitmap_data_scale = None\t\n",
    "\t\tself.output_data = None\n",
    "\t\tself.sc_y = None\n",
    "\t\tself.OutJCF_name = None\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\tglobal ins_path\n",
    "\t\n",
    "\tif os.getenv(\"JMAG_CNN_MODEL_MAKE_MODE\") != \"1\": \n",
    "\n",
    "\t\tRMS = 0.0\n",
    "\t\tR2 = 0.0\n",
    "\t\tError = 0\n",
    "\t\trandom_seed = random.randint(0,2**32-1)\n",
    "\t\n",
    "\t\tSet_data = Topology_setting()\n",
    "\t\tSur_data = Surrogate_data()\n",
    "\t\n",
    "\t\tAnalysisGroup  = app.GetCurrentAnalysisGroup()\n",
    "\t\tSet_data.AnalysisGroup = 1\n",
    "\n",
    "\t\tif AnalysisGroup.IsValid() == False:\n",
    "\t\t\tSet_data.AnalysisGroup = 0\n",
    "\t\t\tAnalysisGroup = app.GetCurrentStudy()\n",
    "\n",
    "\t\tif AnalysisGroup.IsValid() == False:\n",
    "\t\t\tmessage_en = \"The study or analysis group cannot be found.\"\n",
    "\t\t\tmessage_jp = \"study�܂��͉��̓O���[�v���������܂����B\"\n",
    "\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\treturn\n",
    "\n",
    "\t\tError = Get_Topology_Setting(Set_data,AnalysisGroup)\n",
    "\t\n",
    "\t\tif Error ==  1:\n",
    "\t\t\treturn\n",
    "\t\n",
    "\t\tin_usr_param = get_data_from_input_dialog()\n",
    "\t\tif in_usr_param.isValid == False:\n",
    "\t\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_warning_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check_Run_Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_error_exit_message(message_en, message_jp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create_bitmapcsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\tcheck_path()\n",
    "\t\n",
    "\t\twarning_GPU,warning_CPU = Check_Run_Mode(in_usr_param)\n",
    "\t\n",
    "\t\tif warning_GPU == 1:\n",
    "\t\t\tmessage_en = \"The library to run on the GPU is insufficient, or the corresponding GPU cannot be found. It runs in CPU mode, is that okay?\"\n",
    "\t\t\tmessage_jp = \"GPU�œ��삳���邽�߂̃��C�u�������s���A�܂��͑Ή����Ă���GPU���������܂����BCPU���[�h�Ŏ��s���܂����A���낵���ł��傤���B\"\n",
    "\t\t\tcancell = show_warning_message(message_en, message_jp)\n",
    "\t\t\tif cancell:\n",
    "\t\t\t\treturn\n",
    "\n",
    "\t\tif warning_CPU != 0:\n",
    "\t\t\tmessage_en = \"The specified number of parallels and the number of parallels executed are different. Designer must be restarted for the settings to take effect.\"\n",
    "\t\t\tmessage_jp = \"�㗝���f���쐬���ɂ� \" + str(warning_CPU) + \" �����Ŏ��s�����܂��B�ݒ��𔽉f�����邽�߂ɂ�Designer�̍ċN�����K�v�ł��B\"\n",
    "\t\t\tcancell = show_warning_message(message_en, message_jp)\n",
    "\t\t\n",
    "\t\t\tif cancell:\n",
    "\t\t\t\treturn\n",
    "\t\n",
    "\t\tSearch_jcf(in_usr_param,Sur_data,Set_data)\n",
    "\t\n",
    "\t\tif Sur_data.Read_file_num == 0:\n",
    "\t\t\tmessage_en = \"JCF file not found. Make sure that the path you specified is correct.\"\n",
    "\t\t\tmessage_jp = \"JCF�t�@�C�����������܂����B�w�肵���p�X�����������m�F���Ă��������B\"\n",
    "\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\treturn\n",
    "\t\n",
    "\t\tRead_Response_value(in_usr_param,Set_data,Sur_data)\n",
    "\t\tCreate_bitmapcsv(in_usr_param,Sur_data,Set_data)\n",
    "\t\tMake_dir(in_usr_param,Sur_data)\n",
    "\t\n",
    "\t\tos.environ[\"JMAG_CNN_MODEL_MAKE_MODE\"] = \"1\"\n",
    "\t\tos.environ[\"JMAG_TOPOLOGY_CNN_MODELPATH\"]= in_usr_param.model_path.decode()\n",
    "\n",
    "\t\tfor i in range(Sur_data.Response_num):\n",
    "\t\t\tfor j in range(Sur_data.Response_multi_num[i]):\n",
    "\t\t\t\tstart = time.time()\n",
    "\n",
    "\t\t\t\t#f = open(in_usr_param.model_path.decode() + \"/cnn_memory.log\", 'a')\n",
    "\n",
    "\t\t\t\tif Sur_data.Response_multi_num[i]== 1:\n",
    "\t\t\t\t\tname = Sur_data.Response_name[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tname = Sur_data.Response_name[i] + str(j + 1)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#f.write(name + \"\\n\")\n",
    "\t\t\t\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"   \")\n",
    "\t\t\t\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\")\n",
    "\t\t\t\t#f.flush()\n",
    "\n",
    "\t\t\t\tSave_param(in_usr_param,Sur_data,i,j)\n",
    "\t\t\t\tSTD_scale(in_usr_param,Sur_data,i,j)\n",
    "\n",
    "\t\t\t\tif os.name == 'nt':\t\n",
    "\t\t\t\t\tsubprocess.run([ins_path + r\"/designer.exe\",ins_path + \"/scripts/Make_Surrogate_Model_for_CNN.py\",r\"-w\"])\t\t\t\t\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsubprocess.run([ins_path + r\"/designer\",ins_path + \"/scripts/Make_Surrogate_Model_for_CNN.py\",r\"-w\"])\t\t\n",
    "\n",
    "\t\t\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/Error.csv\"):\n",
    "\t\t\t\t\tErr = np.loadtxt(in_usr_param.model_path.decode() + \"/Error.csv\", encoding=\"utf-8\",delimiter=\",\")\n",
    "\t\t\t\t\tError = int(Err)\n",
    "\n",
    "\t\t\t\tif Error == 1:\n",
    "\t\t\t\t\tmessage_en = \"The save path for the surrogate model is too long. Please shorten the path.\"\n",
    "\t\t\t\t\tmessage_jp = \"�㗝���f���̕ۑ��p�X���������܂��B�p�X���Z�����Ă��������B\"\n",
    "\t\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/csvfilepath.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/param.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/response.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/Error.csv\")\n",
    "\n",
    "\t\t\t\t\treturn\n",
    "\t\t\t\t\n",
    "\t\t\t\tif Error == 2:\n",
    "\t\t\t\t\tmessage_en = \"The response value \" + Sur_data.Response_name[i] + \" may contain an outlier. Delete the case that contains an outlier.\"\n",
    "\t\t\t\t\tmessage_jp = \"�����l\" + Sur_data.Response_name[i] + \"�Ɉُ��l���܂܂��Ă����\\���������܂��B�ُ��l���܂܂����P�[�X���폜���Ă��������B\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/csvfilepath.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/param.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/response.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/Error.csv\")\n",
    "\n",
    "\t\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\n",
    "\t\t\t\tend = time.time()\n",
    "\t\t\t\telapsed_time = end - start\n",
    "\t\t\t\t\n",
    "\t\t\t\tif in_usr_param.cross_frag == 1:\n",
    "\t\t\t\t\tRMS,R2 = Load_result(Sur_data,in_usr_param)\n",
    "\t\t\t\t\n",
    "\t\t\t\tsave_set_file(in_usr_param,Set_data,Sur_data,i,j)\t\n",
    "\t\t\t\tsave_zip(Sur_data,i,j)\n",
    "\t\t\t\tsave_csv(in_usr_param,Sur_data,elapsed_time,RMS,R2,i,j)\n",
    "\n",
    "\t\t\t\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"  \")\n",
    "\t\t\t\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\" )\n",
    "\t\t\t\t#f.close()\n",
    "\t\t\n",
    "\t\tos.remove(in_usr_param.model_path.decode() + \"/csvfilepath.csv\")\n",
    "\t\tos.remove(in_usr_param.model_path.decode() + \"/param.csv\")\n",
    "\t\tos.remove(in_usr_param.model_path.decode() + \"/response.csv\")\n",
    "\t\t\n",
    "\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/Error.csv\"):\n",
    "\t\t\tos.remove(in_usr_param.model_path.decode() + \"/Error.csv\")\n",
    "\n",
    "\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/R2RMS.csv\"):\n",
    "\t\t\tos.remove(in_usr_param.model_path.decode() + \"/R2RMS.csv\")\n",
    "\n",
    "\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/result.csv\"):\n",
    "\t\t\tos.remove(in_usr_param.model_path.decode() + \"/result.csv\")\n",
    "\t\t\n",
    "\t\tif in_usr_param.compute_mode == 1:\n",
    "\t\t\tmessage_en = \"If you want to create a surrogate model using GPU again, restart Designer. Memory may overflow.\"\n",
    "\t\t\tmessage_jp = \"�Ă�GPU���p���đ㗝���f�����쐬�����ꍇ�ɂ�Designer���ċN�����Ă��������B���������I�[�o�[�t���[�����\\���������܂��B\"\n",
    "\t\t\tshow_warning_message(message_en, message_jp)\n",
    "\n",
    "\t\tshow_normal_exit_message()\t\n",
    "\n",
    "\t\tos.environ.pop(\"JMAG_CNN_MODEL_MAKE_MODE\",None)\n",
    "\t\tos.environ.pop(\"JMAG_TOPOLOGY_CNN_MODELPATH\",None)\n",
    "\t\tos.environ.pop(\"JMAG_CNN_MODEL_ERROR\",None)\n",
    "\n",
    "\telse:\n",
    "\t\tMake_Surrogate_Model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make_Surrogate_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Make_Surrogate_Model():\n",
    "\tmake_data = Make_model()\n",
    "\tmodel_path = os.getenv(\"JMAG_TOPOLOGY_CNN_MODELPATH\")\n",
    "\t\n",
    "\t#f = open(model_path + \"/cnn_memory.log\", 'a')\n",
    "\t#f.write(\"child process \\n\")\n",
    "\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"   \")\n",
    "\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\")\n",
    "\n",
    "\tLoad_param(make_data,model_path)\n",
    "\tLoad_Response_val(make_data)\n",
    "\tLoad_std(make_data)\n",
    "\tLoad_bitmap(make_data)\n",
    "\t\n",
    "\tmodel,optimizers,reduce_lr = CNN_function(make_data)\n",
    "\tError = CNN_model(optimizers,reduce_lr,model,make_data)\n",
    "\n",
    "\tif Error == 1:\n",
    "\t\tError_log(make_data,1)\n",
    "\t\tapp.Quit()\n",
    "\n",
    "\tif make_data.cross_frag == 1:\n",
    "\t\tRMS,R2,Error = CNN_KFold(optimizers,reduce_lr,model,make_data)\n",
    "\t\tsave_result_csv(make_data,RMS,R2,Error)\n",
    "\n",
    "\tif Error == 1:\n",
    "\t\tError_log(make_data,2)\n",
    "\t\tapp.Quit()\n",
    "\t\n",
    "\tos.environ[\"JMAG_CNN_MODEL_ERROR\"] = \"0\"\n",
    "\n",
    "\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"  \")\n",
    "\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\" )\n",
    "\t#f.write(\"child process End\\n\")\n",
    "\t#f.close()\n",
    "\t\n",
    "\tapp.Quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Save_param(in_usr_param,Sur_data,index_i,index_j):\n",
    "\n",
    "\tsave = np.empty(shape=(8,2), dtype=np.object)\n",
    "\n",
    "\tsave[0][0] = \"model_path\" \n",
    "\tsave[1][0] = \"cross_frag\"\n",
    "\tsave[2][0] = \"cross_val\"\n",
    "\tsave[3][0] = \"num_thread\"\n",
    "\tsave[4][0] = \"compute_mode\" \n",
    "\tsave[5][0] = \"bitmap_size\"\n",
    "\tsave[6][0] = \"Modelsavepath\"\n",
    "\tsave[7][0] = \"Responsename\"\n",
    "\n",
    "\tsave[0][1] = str(in_usr_param.model_path.decode())\t\n",
    "\tsave[1][1] = str(in_usr_param.cross_frag)\n",
    "\tsave[2][1] = str(in_usr_param.cross_val)\n",
    "\tsave[3][1] = str(in_usr_param.num_thread)\n",
    "\tsave[4][1] = str(in_usr_param.compute_mode)\n",
    "\tsave[5][1] = str(in_usr_param.bitmap_size)\n",
    "\t\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tname = Sur_data.model_path[index_i] \n",
    "\t\tresname = Sur_data.Response_name[index_i]\n",
    "\telse:\n",
    "\t\tname = Sur_data.model_path[index_i] + str(index_j + 1) \n",
    "\t\tresname = Sur_data.Response_name[index_i] + str(index_j + 1)\n",
    "\n",
    "\tsave[6][1] = name\n",
    "\tsave[7][1] = resname\n",
    "\n",
    "\tfile_name = in_usr_param.model_path.decode() + \"/param.csv\"\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get_Topology_Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Topology_Setting(Set_data,AnalysisGroup):\n",
    "\t\n",
    "\tif Set_data.AnalysisGroup == 1:\n",
    "\t\tSet_data.num_study = AnalysisGroup.NumStudies()\n",
    "\t\tfor i in range(Set_data.num_study):\n",
    "\t\t\tSet_data.study_name.append(AnalysisGroup.GetStudy(i).GetName())\t\n",
    "\t\t\tSet_data.study_name[i] = Set_data.study_name[i].replace(\" \",\"_\")\n",
    "\n",
    "\t\tfor i in range(Set_data.num_study):\n",
    "\t\t\tSet_data.equation_num_study.append(AnalysisGroup.GetStudy(i).GetDesignTable().NumParameters())\n",
    "\telse:\n",
    "\t\tSet_data.equation_num_study.append(0)\n",
    "\t\t\n",
    "\tSet_data.study_name.append(AnalysisGroup.GetName())\n",
    "\tSet_data.study_name[0] = Set_data.study_name[0].replace(\" \",\"_\")\n",
    "\tSet_data.equation_num_base = AnalysisGroup.GetDesignTable().NumParameters()\n",
    "\n",
    "\tif Set_data.AnalysisGroup == 1:\n",
    "\t\tcount = 0 \t\n",
    "\t\tfor i in range(Set_data.equation_num_base):\n",
    "\t\t\tname = AnalysisGroup.GetDesignTable().ParameterName(i)\n",
    "\t\t\tif \"CAD parameters:\" in name:\n",
    "\t\t\t\tcount = count + 1\n",
    "\n",
    "\t\tSet_data.equation_num_base = Set_data.equation_num_base - count \n",
    "\t\n",
    "\tif Set_data.AnalysisGroup == 0:\n",
    "\t\tNum_cond = AnalysisGroup.NumConditions()\n",
    "\t\tfor i in range(Num_cond):\t\n",
    "\t\t\tif AnalysisGroup.GetCondition(i).GetScriptTypeName() == \"SensitivityAnalysis\":\n",
    "\t\t\t\tmessage_en = \"You cannot create a surrogate model with a model for which topology optimization(Sensitivity Analysis) conditions have been set.\"\n",
    "\t\t\t\tmessage_jp = \"�g�|���W�[�œK�������i���x���́j���ݒ肵�����f���ő㗝���f���̍쐬�͍s���܂����B\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\treturn 1\n",
    "\telse:\n",
    "\t\tfor i in range(Set_data.num_study):\n",
    "\t\t\tstudy = AnalysisGroup.GetStudy(i)\n",
    "\t\t\tfor j in range(study.NumConditions()):\n",
    "\t\t\t\tif study.GetCondition(j).GetScriptTypeName() == \"SensitivityAnalysis\":\n",
    "\t\t\t\t\tmessage_en = \"You cannot create a surrogate model with a model for which topology optimization(Sensitivity Analysis) conditions have been set.\"\n",
    "\t\t\t\t\tmessage_jp = \"�g�|���W�[�œK�������i���x���́j���ݒ肵�����f���ő㗝���f���̍쐬�͍s���܂����B\"\n",
    "\t\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\t\treturn 1\n",
    "\n",
    "\tif AnalysisGroup.GetOptimizationTable().NumParameters() != 0:\n",
    "\t\tmessage_en = \"It cannot be used with parametric optimization when creating a surrogate model using CNN.\"\n",
    "\t\tmessage_jp = \"CNN���p���đ㗝���f�����쐬�����ۂɁA�p�����g���b�N�œK���ƕ��p�͂ł��܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn 1\n",
    "\n",
    "\tif os.getenv(\"JMAG_TOPOLOGY_WITH_PARAMETER\") != None:\n",
    "\t\tmessage_en = \"It cannot be used with parametric optimization when creating a surrogate model using CNN.\"\n",
    "\t\tmessage_jp = \"CNN���p���đ㗝���f�����쐬�����ۂɁA�p�����g���b�N�œK���ƕ��p�͂ł��܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn 1\n",
    "\n",
    "\treturn 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read_Response_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Read_Response_value(in_usr_param,Set_data,Sur_data):\n",
    "\tglobal ins_path\t\n",
    "\n",
    "\tindex = []\n",
    "\tRes_val_max = 0\n",
    "\t\n",
    "\tfor i in range(Set_data.num_study):\n",
    "\t\tif Set_data.AnalysisGroup == 0:\n",
    "\t\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/\" + Set_data.study_name[i] + \"*.csv\"\n",
    "\t\telse:\n",
    "\t\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/**/\" + Set_data.study_name[i] + \"*.csv\"\n",
    "\n",
    "\t\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\t\tpathlist =list(glob.glob(search_path))\t\n",
    "\n",
    "\t\tfor j in range(len(pathlist)):\t\t\t\t\n",
    "\t\t\tfilename = os.path.splitext(os.path.basename(pathlist[j]))[0]\t\t\n",
    "\t\t\tinclude = 0\n",
    "\t\t\tfor k in range(len(Sur_data.Response_name)):\n",
    "\t\t\t\tif Sur_data.Response_name[k] == filename:\n",
    "\t\t\t\t\tinclude = 1\n",
    "\t\t\t\t\tbreak;\n",
    "\t\t\tif \tinclude == 0:\n",
    "\t\t\t\tval_tmp = []\n",
    "\t\t\t\tSur_data.Response_name.append(filename)\n",
    "\t\t\t\tSur_data.equation_num_study.append(Set_data.equation_num_study[i])\n",
    "\t\t\t\tval_tmp = np.loadtxt(pathlist[j], encoding=\"utf-8\",delimiter=\",\", skiprows=Set_data.equation_num_base + Set_data.equation_num_study[i] + 3,usecols=1,dtype=np.object)\n",
    "\t\t\t\tlen_tmp = len(val_tmp)\n",
    "\t\t\t\tindex.append(0)\n",
    "\n",
    "\t\t\t\tSur_data.Response_multi_num.append(len_tmp - 1)\n",
    "\t\t\t\tif Res_val_max < len_tmp:\n",
    "\t\t\t\t\tRes_val_max = len_tmp\n",
    "\t\t\t\t\n",
    "\tRes_val_max = Res_val_max - 1\n",
    "\tSur_data.Response_num = len(Sur_data.Response_name)\n",
    "\tSur_data.Response_value = np.empty(shape=(Sur_data.Read_file_num,Sur_data.Response_num,Res_val_max), dtype=np.float64)\n",
    "\tSur_data.OutJCF_name = np.empty(shape=(Sur_data.Read_file_num,Sur_data.Response_num), dtype=np.object)\n",
    "\n",
    "\tfor i in range(Sur_data.JCF_file_num):\n",
    "\t\tfor j in range(Sur_data.Response_num):\n",
    "\t\t\tpath_tmp = Sur_data.Readjcf_name[i] \n",
    "\t\t\tpath_tmp = path_tmp.replace(\"Designer.jcf\",Sur_data.Response_name[j]+\".csv\")\n",
    "\t\t\t\n",
    "\t\t\tif os.path.isfile(path_tmp):\n",
    "\t\t\t\tval_tmp = np.loadtxt(path_tmp, encoding=\"utf-8\",delimiter=\",\", skiprows=Set_data.equation_num_base + Sur_data.equation_num_study[j] + 4,usecols=1,dtype=np.object)\t\n",
    "\t\t\t\tSur_data.OutJCF_name[index[j]][j] = Sur_data.Readjcf_name[i] \n",
    "\t\t\t\n",
    "\t\t\t\tif Sur_data.Response_multi_num[j] > 1:\n",
    "\t\t\t\t\tfor k in range(Sur_data.Response_multi_num[j]):\n",
    "\t\t\t\t\t\tSur_data.Response_value[index[j]][j][k] = float(val_tmp[k])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tSur_data.Response_value[index[j]][j][0] = float(val_tmp)\t\n",
    "\t\t\t\n",
    "\t\t\t\tindex[j] = index[j] + 1 \n",
    "\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search_jcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Search_jcf(in_usr_param,Sur_data,Set_data):\n",
    "\tglobal ins_path\t\n",
    "\n",
    "\tif os.name == 'nt':\t\n",
    "\t\ttobitmap_exe = ins_path.replace(os.path.sep, '/') + \"/createbitmap.exe\"\n",
    "\telse:\n",
    "\t\ttobitmap_exe = ins_path.replace(os.path.sep, '/') + \"/solver/bin/createbitmap\"\n",
    "\t\n",
    "\trename_bitmap = \"_bitmap_\" + str(in_usr_param.bitmap_size) + \".csv\"\n",
    "\t\n",
    "\tif Set_data.AnalysisGroup == 0:\n",
    "\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/Designer.jcf\"\n",
    "\t\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\telse:\n",
    "\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/**/Designer.jcf\"\n",
    "\t\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\n",
    "\tpathlist =list(glob.glob(search_path))\n",
    "\torg_jcf_path = in_usr_param.input_dir.decode() +  \"/Designer.jcf\"\n",
    "\tSur_data.Readjcf_name_opt = org_jcf_path\n",
    "\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\n",
    "\tn_data = len(pathlist)\n",
    "\tpathlist = sorted(pathlist)\n",
    "\n",
    "\tfor i in range(n_data):\n",
    "\t\tpath,ext = os.path.splitext(pathlist[i])\n",
    "\t\tcsvpath = path + rename_bitmap\n",
    "\t\tcsvpath = csvpath.replace(os.path.sep, '/')\n",
    "\t\t#if os.path.exists(csvpath) == False:\n",
    "\t\tpathlist[i] = pathlist[i].replace(os.path.sep, '/')\n",
    "\t\tcmd = tobitmap_exe ,pathlist[i] ,csvpath ,str(in_usr_param.bitmap_size) ,str(in_usr_param.btimap_mode) ,org_jcf_path\n",
    "\t\t\n",
    "\t\tSur_data.Readjcf_name.append(pathlist[i])\n",
    "\t\t\n",
    "\t\tif Set_data.AnalysisGroup == 0:\n",
    "\t\t\tSur_data.Bitmap_path.append(csvpath)\n",
    "\t\t\tSur_data.bitmap_run_cmd.append(cmd)\n",
    "\t\telse:\n",
    "\t\t\tif \"/0000/\" in csvpath:\n",
    "\t\t\t\tSur_data.Bitmap_path.append(csvpath)\n",
    "\t\t\t\tSur_data.bitmap_run_cmd.append(cmd)\n",
    "\n",
    "\tSur_data.Read_file_num = len(Sur_data.Bitmap_path)\n",
    "\tSur_data.JCF_file_num = len(Sur_data.Readjcf_name)\n",
    "\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Error_log(make_data,num):\n",
    "\tError = np.empty(shape=(1), dtype=np.object)\n",
    "\tError[0] = str(num)\n",
    "\t\n",
    "\tfile_name = make_data.model_path + \"/Error.csv\"\n",
    "\tnp.savetxt(file_name,Error,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def Load_param(make_data,model_path):\n",
    "\n",
    "\tparam = np.loadtxt(model_path + \"/param.csv\", encoding=\"utf-8\",delimiter=\",\",usecols=1,dtype=np.object)\n",
    "\t\n",
    "\tmake_data.model_path = param[0]\n",
    "\tmake_data.cross_frag = int(param[1])\n",
    "\tmake_data.cross_val = int(int(param[2]))\n",
    "\tmake_data.num_thread = int(param[3])\n",
    "\tmake_data.compute_mode = int(param[4])\n",
    "\tmake_data.bitmap_size = int(param[5])\n",
    "\tmake_data.Modelsavepath = param[6]\n",
    "\tmake_data.Responsename = param[7]\n",
    "\n",
    "def Load_std(make_data):\n",
    "\tpath = make_data.Modelsavepath\n",
    "\tmodel_name = make_data.Responsename\n",
    "\tmake_data.sc_y = pickle.load(open(path +\"/\" + model_name + \"_y.pkl\", 'rb'))\t\n",
    "\n",
    "def Load_Response_val(make_data):\n",
    "\tdata = np.loadtxt(make_data.model_path + \"/response.csv\", encoding=\"utf-8\",delimiter=\",\",usecols=0,dtype=np.float64)\n",
    "\tmake_data.Res_val = data\t\n",
    "\n",
    "def Load_bitmap(make_data):\n",
    "\tpath =  np.loadtxt(make_data.model_path + \"/csvfilepath.csv\", encoding=\"utf-8\",delimiter=\",\",dtype=np.object)\n",
    "\tmake_data.Bitmap_path_num = len(path)\n",
    "\tmake_data.OutJCF_name = path\n",
    "\tbitmap = []\n",
    "\n",
    "\tmake_data.Bitmap_data = np.zeros((make_data.Bitmap_path_num,make_data.bitmap_size,make_data.bitmap_size,1))\n",
    "\n",
    "\tfor i in range(make_data.Bitmap_path_num):\n",
    "\t\timage = pd.read_csv(path[i],header=None)\n",
    "\t\timage = image.values\n",
    "\t\timage = image.reshape(make_data.bitmap_size,make_data.bitmap_size,1)\n",
    "\t\tmake_data.Bitmap_data[i] = image\n",
    "\n",
    "\tmax_btimap = np.amax(make_data.Bitmap_data)\n",
    "\tmake_data.Bitmap_data_scale = make_data.Bitmap_data / max_btimap\n",
    "\t\n",
    "def save_set_file(in_usr_param,Set_data,Sur_data,index_i,index_j):\n",
    "\t\n",
    "\tsave = np.empty(shape=(9,2), dtype=np.object)\n",
    "\tres_name = Sur_data.Response_name[index_i]\n",
    "\n",
    "\tfor i in range(Set_data.num_study):\t\n",
    "\t\tres_name = res_name.replace(Set_data.study_name[i]+\"_\",\"\")\n",
    "\n",
    "\tsave[0][0] = \"model\" \n",
    "\tsave[1][0] = \"btimapsize\"\n",
    "\tsave[2][0] = \"res_name\" \n",
    "\tsave[3][0] = \"AnalysisGroup\"\n",
    "\tsave[4][0] = \"Response_multi_num\"\n",
    "\tsave[5][0] = \"Response_multi_index\"\n",
    "\tsave[6][0] = \"Path\"\n",
    "\tsave[7][0] = \"equation_num_base\"\n",
    "\tsave[8][0] = \"equation_num_study\"\n",
    "\n",
    "\tsave[0][1] = str(in_usr_param.btimap_mode)\n",
    "\tsave[1][1] = str(in_usr_param.bitmap_size)\n",
    "\tsave[2][1] = str(res_name)\n",
    "\tsave[3][1] = str(Set_data.AnalysisGroup)\n",
    "\tsave[4][1] = str(Sur_data.Response_multi_num[index_i])\n",
    "\tsave[5][1] = str(index_j)\n",
    "\n",
    "\tif Set_data.AnalysisGroup == 0:\n",
    "\t\tsave[6][1] = \"\"\n",
    "\telse:\n",
    "\t\tsave[6][1] = os.path.basename(os.path.dirname(Sur_data.OutJCF_name[0][index_i]))\n",
    "\t\n",
    "\tsave[7][1] =  str(Set_data.equation_num_base) \n",
    "\tsave[8][1] =  str(Sur_data.equation_num_study[index_i]) \n",
    "\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tfile_name = Sur_data.model_path[index_i] + \"/CNN_param.csv\"\n",
    "\telse:\n",
    "\t\tfile_name = Sur_data.model_path[index_i] + str(index_j + 1) + \"/CNN_param.csv\"\n",
    "\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def Load_result(Sur_data,in_usr_param):\n",
    "\tpath = in_usr_param.model_path.decode()\n",
    "\tSur_data.output_data = np.loadtxt(path + \"/result.csv\", encoding=\"utf-8\",delimiter=\",\",dtype=np.object)\n",
    "\t\n",
    "\tpath = in_usr_param.model_path.decode() \n",
    "\tRMS_R2 = np.loadtxt(path + \"/R2RMS.csv\", encoding=\"utf-8\",delimiter=\",\",usecols=1,dtype=np.object)\n",
    "\t\n",
    "\treturn RMS_R2[0],RMS_R2[1]\n",
    "\n",
    "def check_path():\n",
    "\tglobal \tins_path\n",
    "\n",
    "\tif os.name == 'nt':\t\n",
    "\t\tpath_tmp = os.getenv(\"path\")\n",
    "\t\tpath_tmp = path_tmp.split(';')\n",
    "\n",
    "\t\tfor i in range(len(path_tmp)):\n",
    "\t\t\tif os.path.isfile(path_tmp[i] + \"/scripts/Make_Surrogate_Model_for_CNN.py\"):\n",
    "\t\t\t\tins_path = path_tmp[i]\n",
    "\t\t\t\treturn 0\n",
    "\t\tif os.path.isfile(r\"C:/Program Files/JMAG-Designer21.0/scripts/Make_Surrogate_Model_for_CNN.py\"):\n",
    "\t\t\tins_path = \"C:/Program Files/JMAG-Designer21.0\"\n",
    "\t\t\treturn 0\n",
    "\t\tif os.getenv('InsDir') != None:\n",
    "\t\t\tins_path = os.getenv('InsDir')\n",
    "\t\t\treturn 0\n",
    "\n",
    "\t\tmessage_en = \"The installation directory cannot be found. Set the environment variable path or insdir to the installation directory.\"\n",
    "\t\tmessage_jp = \"�C���X�g�[�f�B���N�g�����������܂����B���ϐ�path�͂܂���insdir�ɃC���X�g�[���f�B���N�g�����ݒ肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\tins_path = os.getenv('InsDir')\n",
    "\t\treturn 0\n",
    "\n",
    "def Make_dir(in_usr_param,Sur_data):\n",
    "\tfor i in range(Sur_data.Response_num):\n",
    "\t\tSur_data.model_path.append(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i])\n",
    "\t\tif Sur_data.Response_multi_num[i]== 1:\n",
    "\t\t\tif not os.path.exists(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i]):\n",
    "\t\t\t\tos.mkdir(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i])\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(Sur_data.Response_multi_num[i]):\n",
    "\t\t\t\tif not os.path.exists(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i] + str(j + 1)):\n",
    "\t\t\t\t\tos.mkdir(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i] + str(j + 1))\n",
    "\n",
    "def STD_scale(in_usr_param,Sur_data,index_i,index_j):\n",
    "\t\n",
    "\tcorrect_data = np.zeros((Sur_data.Read_file_num, 1))\n",
    "\t\n",
    "\tsc_y = StandardScaler()\n",
    "\tfor i in range(Sur_data.Read_file_num):\n",
    "\t\tcorrect_data[i,0] = Sur_data.Response_value[i][index_i][index_j]\n",
    "\n",
    "\tin_y = sc_y.fit_transform(correct_data)\n",
    "\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tpickle.dump(sc_y, open(Sur_data.model_path[index_i] + \"/\" + Sur_data.Response_name[index_i] + \"_y.pkl\", 'wb'))\n",
    "\telse:\n",
    "\t\tpickle.dump(sc_y, open(Sur_data.model_path[index_i] + str(index_j + 1) + \"/\" + Sur_data.Response_name[index_i] + str(index_j + 1) + \"_y.pkl\", 'wb'))\n",
    "\n",
    "\tfile_name = in_usr_param.model_path.decode() + \"/response.csv\"\n",
    "\tnp.savetxt(file_name,np.array(in_y),fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "\treturn in_y,sc_y\n",
    "\n",
    "def Create_bitmapcsv(in_usr_param,Sur_data,Set_data):\n",
    "\t\n",
    "\tproc_list = []\n",
    "\tnumproc = in_usr_param.num_thread\n",
    "\tif len(Sur_data.bitmap_run_cmd) < numproc:\n",
    "\t\tnumproc = len(Sur_data.bitmap_run_cmd)\n",
    "\t\n",
    "\tn_data = len(Sur_data.bitmap_run_cmd)\n",
    "\tSur_data.Bitmap_data = np.zeros((Sur_data.Read_file_num,in_usr_param.bitmap_size,in_usr_param.bitmap_size))\n",
    "\t\n",
    "\tif os.name == 'nt':\t\n",
    "\t\tstartupinfo = subprocess.STARTUPINFO()\n",
    "\t\tstartupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n",
    "\t\tstartupinfo.wShowWindow = subprocess.SW_HIDE\n",
    "\telse:\n",
    "\t\tstartupinfo = None\n",
    "\n",
    "\tfor i in range(n_data):\n",
    "\t\tproc = subprocess.Popen(Sur_data.bitmap_run_cmd[i],stdout=subprocess.DEVNULL,startupinfo=startupinfo)\n",
    "\t\tproc_list.append(proc)\n",
    "\t\tif len(proc_list) % numproc == 0 or (i + 1) == n_data:\n",
    "\t\t\tfor subproc in proc_list:\n",
    "\t\t\t\tsubproc.wait()\n",
    "\t\tproc_list = []\t\n",
    "\n",
    "\tcsv_path = []\n",
    "\t\n",
    "\tfor i in range(Sur_data.Read_file_num):\n",
    "\t\tif Set_data.AnalysisGroup == 0:\n",
    "\t\t\tcsv_path.append(Sur_data.Bitmap_path[i])\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tif \"/0000/\"  in Sur_data.Bitmap_path[i]:\n",
    "\t\t\t\tcsv_path.append(Sur_data.Bitmap_path[i])\n",
    "\n",
    "\tfile_name = in_usr_param.model_path.decode() + \"/csvfilepath.csv\"\n",
    "\tnp.savetxt(file_name,np.array(csv_path),fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "\n",
    "def save_zip(Sur_data,index_i,index_j):\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tshutil.make_archive(Sur_data.model_path[index_i], format='zip', root_dir = Sur_data.model_path[index_i])\n",
    "\t\tshutil.rmtree(Sur_data.model_path[index_i])\n",
    "\telse:\n",
    "\t\tshutil.make_archive(Sur_data.model_path[index_i] + str(index_j + 1), format='zip', root_dir = Sur_data.model_path[index_i] + str(index_j + 1))\n",
    "\t\tshutil.rmtree(Sur_data.model_path[index_i] + str(index_j + 1))\n",
    "\t\n",
    "def CNN_function(make_data):\n",
    "\n",
    "\toptimizers = tf.keras.optimizers.Adam(lr=0.0005)\n",
    "\treduce_lr = ReduceLROnPlateau(monitor='loss',factor=0.5,patience=2,min_lr=0.0001)\n",
    "\n",
    "\tif make_data.compute_mode == 0:\n",
    "\t\tos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\t\t\n",
    "\t\tset_thread = tf.config.threading.get_inter_op_parallelism_threads()\n",
    "\t\tif set_thread == 0:\n",
    "\t\t\tcontext._context = None\n",
    "\t\t\tcontext._create_context()\n",
    "\t\t\n",
    "\t\t\ttf.config.threading.set_inter_op_parallelism_threads(make_data.num_thread)\n",
    "\t\t\ttf.config.threading.set_intra_op_parallelism_threads(make_data.num_thread)\n",
    "\t\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\n",
    "\tmodel.add(tf.keras.layers.InputLayer(input_shape=(make_data.bitmap_size,make_data.bitmap_size, 1)))\n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))  \n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\",activation=\"relu\")) \n",
    "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\",activation=\"relu\")) \n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))  \n",
    "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(tf.keras.layers.Flatten())\n",
    "\tmodel.add(tf.keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "\tmodel.add(tf.keras.layers.Dense(units=512, activation=\"relu\")) \n",
    "\tmodel.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "\tmodel.compile(optimizer = optimizers, loss = \"mean_squared_error\")\n",
    "\n",
    "\treturn model,optimizers,reduce_lr\n",
    "\n",
    "def Check_Run_Mode(in_usr_param):\n",
    "\t\n",
    "\twarning_GPU = 0\n",
    "\twarning_CPU = 0\n",
    "\n",
    "\tif in_usr_param.compute_mode == 0:\n",
    "\t\tos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\t\t\n",
    "\t\tset_thread = tf.config.threading.get_inter_op_parallelism_threads()\n",
    "\t\tif (set_thread != in_usr_param.num_thread) and (set_thread != 0):\n",
    "\t\t\twarning_CPU = set_thread\n",
    "\telse:\n",
    "\t\tgpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "\t\tif len(gpus) < 1:\n",
    "\t\t\twarning_GPU\t = 1\n",
    "\n",
    "\treturn warning_GPU,warning_CPU\n",
    "\n",
    "def CNN_model(optimizers,reduce_lr,model,make_data):\n",
    "\tError = 0\n",
    "\t\n",
    "\tfor ix, layer in enumerate(model.layers):\n",
    "\t\t\tif hasattr(model.layers[ix], 'kernel_initializer') and \\\n",
    "\t\t\t\thasattr(model.layers[ix], 'bias_initializer'):\n",
    "\t\t\t\tweight_initializer = model.layers[ix].kernel_initializer\n",
    "\t\t\t\tbias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "\t\t\t\told_weights, old_biases = model.layers[ix].get_weights()\n",
    "\n",
    "\t\t\t\tmodel.layers[ix].set_weights([\n",
    "\t\t\t\t\tweight_initializer(shape=old_weights.shape),\n",
    "\t\t\t\t\tbias_initializer(shape=len(old_biases))])\n",
    "\n",
    "\tmodel.fit(make_data.Bitmap_data_scale,make_data.Res_val, epochs = num_epoch, batch_size = num_batch, verbose=0,callbacks=[reduce_lr])\n",
    "\n",
    "\ttry:\n",
    "\t\tsave_path = make_data.Modelsavepath\n",
    "\t\tmodel_name = make_data.Responsename\n",
    "\t\tmodel.save(save_path+ \"/tmp/\")\n",
    "\t\tos.rename(save_path + \"/tmp/\" , save_path + \"/\" + model_name + \".surm\")\n",
    "\texcept:\n",
    "\t\tError = 1\n",
    "\n",
    "\ttf.keras.backend.clear_session()\n",
    "\tgc.collect()\n",
    "\n",
    "\treturn Error\n",
    "\n",
    "\t\n",
    "def CNN_KFold(optimizers,reduce_lr,model,make_data):\n",
    "\trandom_seed = random.randint(0,2**32-1)\n",
    "\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tError = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\n",
    "\tmake_data.output_data = np.empty(shape=(make_data.Bitmap_path_num,4), dtype=np.object)\n",
    "\n",
    "\tkf = KFold(n_splits = make_data.cross_val, shuffle=True,random_state = random_seed)\n",
    "\t\n",
    "\tfor train_index, test_index in kf.split(make_data.Bitmap_data_scale):\t\n",
    "\t\t\n",
    "\t\tfor ix, layer in enumerate(model.layers):\n",
    "\t\t\tif hasattr(model.layers[ix], 'kernel_initializer') and \\\n",
    "\t\t\t\thasattr(model.layers[ix], 'bias_initializer'):\n",
    "\t\t\t\tweight_initializer = model.layers[ix].kernel_initializer\n",
    "\t\t\t\tbias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "\t\t\t\told_weights, old_biases = model.layers[ix].get_weights()\n",
    "\n",
    "\t\t\t\tmodel.layers[ix].set_weights([\n",
    "\t\t\t\t\tweight_initializer(shape=old_weights.shape),\n",
    "\t\t\t\t\tbias_initializer(shape=len(old_biases))])\n",
    "\t\t\n",
    "\t\tmodel.fit(make_data.Bitmap_data_scale[train_index,:],make_data.Res_val[train_index], epochs = num_epoch, batch_size = num_batch, verbose=0,callbacks=[reduce_lr])\n",
    "\t\t\n",
    "\t\tresult_predict_tmp = make_data.sc_y.inverse_transform(model.predict(make_data.Bitmap_data_scale[test_index, :]))\n",
    "\t\tresult_correct_tmp = make_data.sc_y.inverse_transform(make_data.Res_val[test_index])\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,make_data)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\n",
    "\t\ttf.keras.backend.clear_session()\n",
    "\t\tgc.collect()\n",
    "\n",
    "\treturn RMS/make_data.cross_val,R2/make_data.cross_val,Error\n",
    "\n",
    "def save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,make_data):\n",
    "\t\n",
    "\tfor i in range(len(test_index)):\n",
    "\t\tmake_data.output_data[Start_index][0] = str(index_count)\n",
    "\t\tmake_data.output_data[Start_index][1] = float(result_correct_tmp[i])\n",
    "\t\tmake_data.output_data[Start_index][2] = float(result_predict_tmp[i])\n",
    "\t\tfilename = \"Designer_bitmap_\" + str(make_data.bitmap_size) + \".csv\"\n",
    "\t\tmake_data.output_data[Start_index][3] = make_data.OutJCF_name[test_index[i]].replace(filename,\"Designer.jcf\")\n",
    "\n",
    "\t\tStart_index = Start_index + 1\n",
    "\treturn Start_index\n",
    "\n",
    "def save_result_csv(make_data,RMS,R2,Error):\n",
    "\t\n",
    "\tsave_path = make_data.model_path + \"/result.csv\"\n",
    "\tnp.savetxt(save_path,np.array(make_data.output_data),encoding=\"utf-8\",fmt=\"%s\",delimiter=',')\n",
    "\n",
    "\tsave = np.empty(shape=(2,2), dtype=np.object)\n",
    "\n",
    "\tsave[0][0] = \"RMS\" \n",
    "\tsave[1][0] = \"R2\"\n",
    "\t\n",
    "\tsave[0][1] = str(RMS)\n",
    "\tsave[1][1] = str(R2)\n",
    "\n",
    "\tsave_path = make_data.model_path + \"/R2RMS.csv\"\n",
    "\tnp.savetxt(save_path,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def save_csv(in_usr_param,Sur_data,elapsed_time,RMS,R2,index_i,index_j):\n",
    "\t\n",
    "\tif in_usr_param.cross_frag == 1:\n",
    "\t\tsave = np.empty(shape=(Sur_data.Read_file_num+7,6), dtype=np.object)\n",
    "\t\tfor i in range(Sur_data.Read_file_num+7):\n",
    "\t\t\tfor j in range(6):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\n",
    "\t\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i]\n",
    "\t\telse:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i] + str(index_j + 1)\n",
    "\t\t\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tsave[1][1] = \"CNN\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\tsave[3][0] = \"RMS\"\n",
    "\t\tsave[3][1] = str(RMS)\n",
    "\t\tsave[4][0] = \"R2\"\n",
    "\t\tsave[4][1] = str(R2)\n",
    "\t\tsave[6][0] = \"case\"\n",
    "\t\tsave[6][1] = \"K-fold\" \n",
    "\t\tsave[6][2] = \"correct\"\n",
    "\t\tsave[6][3] = \"predict\"\n",
    "\n",
    "\t\tfor i in range(Sur_data.Read_file_num):\n",
    "\t\t\tsave[i+7][0] = str(i)\n",
    "\t\t\tsave[i+7][1] = str(Sur_data.output_data[i][0])\n",
    "\t\t\tsave[i+7][2] = float(Sur_data.output_data[i][1])\n",
    "\t\t\tsave[i+7][3] = float(Sur_data.output_data[i][2])\n",
    "\t\t\tsave[i+7][5] = str(Sur_data.output_data[i][3])\n",
    "\t\t\t\n",
    "\telse:\n",
    "\t\tsave = np.empty(shape=(3,2), dtype=np.object)\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tfor j in range(2):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i]\n",
    "\t\telse:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i] + str(index_j + 1)\n",
    "\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tsave[1][1] = \"CNN\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tfile_name = in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[index_i] + \".csv\"\n",
    "\telse:\n",
    "\t\tfile_name = in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[index_i] + str(index_j + 1) + \".csv\"\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def get_data_from_input_dialog():\n",
    "\tdialog = create_input_dialog()\n",
    "\tdialog.Show()\n",
    "\tif dialog.WasCancelled() == False:\n",
    "\t\tdata = get_values_from_input_dialog(dialog)\n",
    "\t\treturn data\n",
    "\treturn DialogData()\n",
    "\n",
    "def get_values_from_input_dialog(dialog):\n",
    "\tdata = DialogData()\n",
    "\tdata.model_path = dialog.GetValue(\"surrogate_model_path\")\n",
    "\tdata.cross_val = dialog.GetValue(\"cross_val\")\n",
    "\tdata.btimap_mode = dialog.GetValue(\"model\")\n",
    "\tdata.bitmap_size = dialog.GetValue(\"bitmap_size\")\n",
    "\tdata.cross_frag = dialog.GetValue(\"cross_frag\")\n",
    "\tdata.num_thread = dialog.GetValue(\"num_thread\")\n",
    "\tdata.compute_mode = dialog.GetValue(\"compute_mode\")\n",
    "\tdata.input_dir = dialog.GetValue(\"input_dir\")\t\n",
    "\t\n",
    "\tif (data.bitmap_size < 50) or (data.bitmap_size > 1000) or (data.bitmap_size == \"\"):\n",
    "\t\tmessage_en = \"The size of the bitmap must range from 50 to 1000.\"\n",
    "\t\tmessage_jp = \"bitmap�̃T�C�Y��50�`1000�͈̔͂Ŏw�肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.input_dir == \"\":\n",
    "\t\tmessage_en = \"Specify input file name.\"\n",
    "\t\tmessage_jp = \"���̓t�@�C�������w�肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isdir(data.input_dir) == 0:\n",
    "\t\tmessage_en = \"Specify input file name.\"\n",
    "\t\tmessage_jp = \"���̓t�H���_�������������܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.model_path == b\"\":\n",
    "\t\tmessage_en = \"Specify output directory name.\"\n",
    "\t\tmessage_jp = \"�o�̓t�H���_�����w�肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isdir(data.model_path) == 0:\n",
    "\t\tmessage_en = \"The output folder is incorrect.\"\n",
    "\t\tmessage_jp = \"�o�̓t�H���_�������������܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tif data.cross_val <= 1:\n",
    "\t\tmessage_en = \"Set the number of divisions to 2 or more.\"\n",
    "\t\tmessage_jp = \"��������2�ȏ��Őݒ肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.num_thread == \"\" or data.num_thread < 1:\n",
    "\t\tmessage_en = \"Please enter an integer greater than or equal to 1.\"\n",
    "\t\tmessage_jp = \"���񐔂͂P�ȏ��̐��������͂��Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tdata.isValid = True\n",
    "\treturn data\n",
    "\n",
    "def create_input_dialog():\n",
    "\tapp = designer.GetApplication()\n",
    "\tdialog = app.CreateDialogBox()\n",
    "\n",
    "\ttitle_jp = \"CNN�㗝���f���쐬(����)\"\n",
    "\ttitle_en = \"Create a surrogate model for CNN (beta version)\"\n",
    "\toutputlbl_jp = \"�o��:\"\n",
    "\toutputlbl_en = \"Output:\"\n",
    "\tinputlbl_jp = \"����:\"\n",
    "\tinputlbl_en = \"Input:\"\n",
    "\tsurrogate_path_jp = \"�㗝���f���o�̓p�X\"\n",
    "\tsurrogate_path_en = \"Surrogate model output path\" \n",
    "\tcross_val_jp = \"K-������������\"\n",
    "\tcross_val_en = \"K-Fold Cross validation\"\t\n",
    "\tfold_val_jp = \"������\"\n",
    "\tfold_val_en = \"K-fold\"\n",
    "\tresponse_jp = \"�����l\"\n",
    "\tresponse_en = \"Response value\"\t\n",
    "\tcross_use_jp = \"��������\"\n",
    "\tcross_use_en = \"Cross validation\"\n",
    "\tcross_notuse_jp = \"���؂Ȃ�\" \n",
    "\tcross_notuse_en = \"No verification\"\n",
    "\tinput_dir_jp = \"�w�K�f�[�^�Z�b�g�p�X\"\n",
    "\tinput_dir_en = \"Training dataset�@path\" \n",
    "\tOutput_area_jp = \"�o�͗̈�\"\n",
    "\tOutput_area_en = \"Output area\"\n",
    "\tOutput_area_All_jp = \"���ׂ�\"\n",
    "\tOutput_area_ALL_en = \"ALL\"\n",
    "\tOutput_area_Topt_jp = \"�g�|���W�[�œK���̈�\" \n",
    "\tOutput_area_Topt_en = \"Topology optimization area\"\n",
    "\tBitmap_num_ja = \"�r�b�g��\"\n",
    "\tBitmap_num_en = \"Number of bits\"\n",
    "\tParalell_num_ja = \"������\" \n",
    "\tParalell_num_en = \"Number of parallels\"\n",
    "\tSurrogate_para_ja = \"�����v�Z(�㗝���f���쐬�j\"\n",
    "\tSurrogate_para_en = \"Parallel computing (surrogate model creation)\"\n",
    "\tBitmap_para_ja = \"���񐔁i�㗝���f���쐬�y��bitmap�t�@�C���쐬�j\"\n",
    "\tBitmap_para_en = \"Parallel number (surrogate model creation and bitmap file creation)\"\n",
    "\tCompute_Capability_ja = \"���j Compute Capability 8.6 ��GPU�ɂ͑Ή����Ă��܂����B\"\n",
    "\tCompute_Capability_en = \"note�j Compute Capability 8.6 GPU is not supported.\"\n",
    "\t\n",
    "\tdialog.SetTranslation(title_en, title_jp)\n",
    "\n",
    "\tdialog.SetTranslation(response_en, response_jp)\n",
    "\tdialog.SetTranslation(fold_val_en, fold_val_jp)\n",
    "\tdialog.SetTranslation(cross_val_en, cross_val_jp)\n",
    "\tdialog.SetTranslation(outputlbl_en, outputlbl_jp)\n",
    "\tdialog.SetTranslation(surrogate_path_en, surrogate_path_jp)\n",
    "\tdialog.SetTranslation(cross_use_en, cross_use_jp)\n",
    "\tdialog.SetTranslation(cross_notuse_en, cross_notuse_jp)\n",
    "\tdialog.SetTranslation(inputlbl_en,inputlbl_jp)\n",
    "\tdialog.SetTranslation(input_dir_en,input_dir_jp)\n",
    "\tdialog.SetTranslation(Output_area_en,Output_area_jp)\n",
    "\tdialog.SetTranslation(Output_area_ALL_en,Output_area_All_jp)\n",
    "\tdialog.SetTranslation(Output_area_Topt_jp,Output_area_Topt_jp)\n",
    "\tdialog.SetTranslation(Bitmap_num_en,Bitmap_num_ja)\n",
    "\tdialog.SetTranslation(Paralell_num_en,Paralell_num_ja)\n",
    "\tdialog.SetTranslation(Surrogate_para_en,Surrogate_para_ja)\t\n",
    "\tdialog.SetTranslation(Bitmap_para_en,Bitmap_para_ja)\n",
    "\tdialog.SetTranslation(Output_area_Topt_en,Output_area_Topt_jp)\n",
    "\tdialog.SetTranslation(Compute_Capability_en,Compute_Capability_ja)\n",
    "\t\n",
    "\tdialog.SetTitle(title_en)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(cross_val_en)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_use_en,1)\n",
    "\tdialog.AddInteger(\"cross_val\", fold_val_en, 5)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_notuse_en, 2)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(Output_area_en)\n",
    "\tdialog.AddRadio(\"model\", Output_area_ALL_en, 1)\n",
    "\tdialog.AddRadio(\"model\", Output_area_Topt_en, 2)\n",
    "\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(Surrogate_para_en)\n",
    "\tdialog.AddRadio(\"compute_mode\", \"CPU\", 0)\n",
    "\tdialog.AddRadio(\"compute_mode\", \"GPU\", 1)\n",
    "\tdialog.AddLabel(Compute_Capability_en)\n",
    "\n",
    "\tdialog.AddLine()\n",
    "\tdialog.AddLabel(Bitmap_para_en)\n",
    "\tdialog.AddInteger(\"num_thread\", Paralell_num_en, 8)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddInteger(\"bitmap_size\",Bitmap_num_en, 200)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(inputlbl_en)\n",
    "\tdialog.AddDirectoryPath(\"input_dir\", input_dir_en,\"\")\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(outputlbl_en)\n",
    "\tdialog.AddDirectoryPath(\"surrogate_model_path\", surrogate_path_en,\"./\")\n",
    "\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\treturn dialog\n",
    "\n",
    "def show_normal_exit_message():\n",
    "\ttitle_en = \"Finished\"\n",
    "\ttitle_jp = \"�I��\"\n",
    "\tmessage_en = \"Finished.\"\n",
    "\tmessage_jp = \"�I��\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_error_exit_message(message_en, message_jp):\n",
    "\ttitle_en = \"Error\"\n",
    "\ttitle_jp = \"�G���[\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_message(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\n",
    "def show_warning_message(message_en, message_jp):\n",
    "\ttitle_en = \"warning\"\n",
    "\ttitle_jp = \"�x��\"\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\t\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\t\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\treturn msgdlg.WasCancelled()\n",
    "\n",
    "if py_error == 0:\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class DialogData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import math\n",
    "#import designer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "\n",
    "py_error = 0\n",
    "\n",
    "# NN param\n",
    "num_neuron = 20\n",
    "num_layer = 3\n",
    "num_epoch = 100\n",
    "num_batch = 10\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def show_message_immediately(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\n",
    "if (sys.version >= \"3.8\"):\n",
    "\ttry:\n",
    "\t\timport tensorflow as tf\n",
    "\t\tfrom sklearn.preprocessing import StandardScaler\n",
    "\t\tfrom sklearn.svm import SVR\n",
    "\t\tfrom sklearn.tree import DecisionTreeRegressor\n",
    "\t\tfrom sklearn.model_selection import KFold\n",
    "\t\tfrom sklearn.metrics import r2_score\n",
    "\t\tfrom sklearn.metrics import mean_squared_error\n",
    "\texcept:\n",
    "\t\ttitle_en = \"Python library error\"\n",
    "\t\ttitle_jp = \"Python���C�u�����G���[\"\n",
    "\t\tmessage_en = \"The runtime library cannot be found. Please refer to the manual for the required packages.\"\n",
    "\t\tmessage_jp = \"�����^�C�����C�u�������������܂����B�K�v�ȃp�b�P�[�W�̓}�j���A�����Q�Ƃ��Ă��������B\"\n",
    "\t\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\t\tpy_error = 1\n",
    "\n",
    "if (sys.version < \"3.8\"):\n",
    "\ttitle_en = \"Python Version Error\"\n",
    "\ttitle_jp = \"Python�o�[�W�����G���[\"\n",
    "\tmessage_en = \"Please use Python of newer version over 3.8\"\n",
    "\tmessage_jp = \"�o�[�W����3.8�ȏ���Python���g�p���Ă��������B\"\n",
    "\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\tpy_error = 1\n",
    "\n",
    "class DialogData:\n",
    "\tdef __init__(self):\n",
    "\t\tself.model_path = \"\"\n",
    "\t\tself.csv_path   = \"\"\n",
    "\t\tself.model = 1\n",
    "\t\tself.cross_val = 5\n",
    "\t\tself.cross_frag = 1\n",
    "\t\tself.response_name = []\n",
    "\t\tself.isValid  = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "\tobj_list = []\n",
    "\tparam_list = []\n",
    "\tmodel_save_path = []\n",
    "\trandom_seed = 0\n",
    "\tnum_case = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\trandom_seed = random.randint(0,2**32-1)\n",
    "\t\n",
    "\tAnalysisGroup  = app.GetCurrentAnalysisGroup()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tAnalysisGroup = app.GetCurrentStudy()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tmessage_en = \"The study or analysis group cannot be found.\"\n",
    "\t\tmessage_jp = \"study�܂��͉��̓O���[�v���������܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn\n",
    "\n",
    "\tdata = get_data_from_input_dialog()\n",
    "\tif data.isValid == False:\n",
    "\t\treturn\n",
    "\n",
    "\tOptTable = AnalysisGroup.GetOptimizationTable()\n",
    "\tnum_param = OptTable.NumParameters()\t\n",
    "\tnum_obj = len(data.response_name)\n",
    "\tkfold_split = data.cross_val\n",
    " \n",
    "\tfor i in range(num_obj):\n",
    "\t\ttmp = data.response_name[i]\n",
    "\t\tobj_list.append(tmp.decode())\n",
    "\t\tmodel_save_path.append(data.model_path + b\"/\" + data.response_name[i] + b\"/\" + data.response_name[i])\n",
    "\t\tif not os.path.exists(data.model_path + b\"/\" + data.response_name[i]):\n",
    "\t\t\tos.mkdir(data.model_path + b\"/\" + data.response_name[i])\n",
    "\t\t\n",
    "\tfor i in range(num_param):\n",
    "\t\tparam = OptTable.GetParametricItem(i)\n",
    "\t\tif param.GetItemName() != \"\":\n",
    "\t\t\tparam_list.append(param.GetItemName())\n",
    "\t\telse:\n",
    "\t\t\tparam_list.append(param.GetParameterName())\n",
    "\n",
    "\tinput_param,result_correct,Error,learn_data =loadcsv(data.csv_path,param_list,obj_list)\n",
    "\tif Error == 1:\n",
    "\t\treturn\n",
    "\n",
    "\tnum_case = len(input_param)\n",
    "\n",
    "\tcorrect_data = np.zeros([num_case])\n",
    "\tresult_out_csv = np.zeros([num_case,num_param + 3])\n",
    "\n",
    "\tif data.model ==1:\n",
    "\t\ttf.get_logger().setLevel(\"ERROR\")\n",
    "\t\tann_tmp = NN_function()\n",
    "\n",
    "\tfor i in range(num_obj):\n",
    "\t\tsc_X = StandardScaler()\n",
    "\t\tsc_y = StandardScaler()\n",
    "\t\tfor j in range(num_case):\n",
    "\t\t\tcorrect_data[j] = result_correct[j][i]\t\n",
    "\t\tcorrect_data = correct_data.reshape(num_case, 1)\n",
    "\n",
    "\t\ttmp_X = sc_X.fit_transform(input_param)\n",
    "\t\ttmp_y = sc_y.fit_transform(correct_data)\n",
    "\t\tpickle.dump(sc_X, open(model_save_path[i] + b\"_x.pkl\", 'wb'))\n",
    "\t\tpickle.dump(sc_y, open(model_save_path[i] + b\"_y.pkl\", 'wb'))\n",
    "\t\t\n",
    "\t\tstart = time.time()\n",
    "\t\tif data.cross_frag == 1:\n",
    "\t\t\tif data.model ==1:\n",
    "\t\t\t\tNN_model(tmp_X,tmp_y,sc_y,model_save_path,i,ann_tmp)\n",
    "\t\t\t\tRMS,R2,Error = NN_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split,ann_tmp)\n",
    "\t\t\telif data.model ==2:\n",
    "\t\t\t\tSVR_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\t\tRMS,R2,Error = SVR_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split)\n",
    "\t\t\telif data.model ==3:\n",
    "\t\t\t\tRT_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\t\tRMS,R2,Error = RT_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split)\n",
    "\t\telse:\n",
    "\t\t\tif data.model ==1:\n",
    "\t\t\t\tNN_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\telif data.model ==2:\n",
    "\t\t\t\tSVR_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\telif data.model ==3:\n",
    "\t\t\t\tRT_model(tmp_X,tmp_y,sc_y,model_save_path,i)\t \n",
    "\t\t\n",
    "\t\tend = time.time()\n",
    "\t\telapsed_time = end - start\n",
    "\t\t\n",
    "\t\tsave_csv(model_save_path,result_out_csv,i,num_case,num_param,param_list,elapsed_time,obj_list,RMS,R2,data)\n",
    "\t\tsave_zip(model_save_path,data,i,learn_data)\n",
    "\n",
    "\t\tif Error:\n",
    "\t\t\tmessage_en = \"The response value \" + data.response_name[i].decode() + \" may contain an outlier. Delete the case that contains an outlier.\"\n",
    "\t\t\tmessage_jp = \"�����l\" + data.response_name[i].decode() + \"�Ɉُ��l���܂܂��Ă����\\���������܂��B�ُ��l���܂܂����P�[�X���폜���Ă��������B\"\n",
    "\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\n",
    "\tshow_normal_exit_message()\n",
    "\n",
    "def save_zip(model_save_path,data,index,learn_data):\n",
    "\tsave_path = data.model_path + b\"/\" + data.response_name[index] + b\"/learn_data.csv\"\n",
    "\tsave_path = save_path.decode()\n",
    "\n",
    "\twith open(save_path, \"a\",encoding=\"cp932\") as f:\n",
    "\t\tfor i in range(len(learn_data)):\n",
    "\t\t\tfor j in range(len(learn_data[0])):\n",
    "\t\t\t\tf.write(\"\\\"\"+learn_data[i][j] + \"\\\"\" + \",\")\n",
    "\t\t\tf.write(\"\\n\")\n",
    "\n",
    "\tdirname = data.model_path + b\"/\" + data.response_name[index]\n",
    "\tdirname = dirname.decode()\n",
    "\tshutil.make_archive(dirname, format='zip', root_dir = data.model_path + b\"/\" + data.response_name[index])\n",
    "\tshutil.rmtree(dirname)\n",
    "\n",
    "def NN_function():\n",
    "\tann = tf.keras.models.Sequential()\n",
    "\tfor i in range(num_layer):\n",
    "\t\tann.add(tf.keras.layers.Dense(units=num_neuron, activation='relu'))\n",
    "\tann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "\treturn ann \n",
    "\n",
    "def NN_model(tmp_X,tmp_y,sc_y,model_save_path,index,ann_tmp):\n",
    "\tlocal_y = tmp_y\n",
    "\tlocal_y = np.reshape(local_y,(-1))\n",
    "\tann = tf.keras.models.clone_model(ann_tmp)\n",
    "\tann.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\tann.fit(tmp_X,local_y, epochs = num_epoch, batch_size = num_batch, verbose=0)\n",
    "\tann.save(model_save_path[index] + b\".surm\")\n",
    "\n",
    "def NN_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split,ann_tmp):\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tError = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tkf = KFold(n_splits=kfold_split, shuffle=True,random_state =random_seed)\n",
    "\n",
    "\tfor train_index, test_index in kf.split(tmp_X):\n",
    "\t\tlocal_y = tmp_y[train_index, :]\n",
    "\t\tlocal_y = np.reshape(local_y,(-1))\n",
    "\t\t\n",
    "\t\tann = tf.keras.models.clone_model(ann_tmp)\n",
    "\t\tann.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\t\tann.fit(tmp_X[train_index, :],local_y, epochs = num_epoch, batch_size = num_batch, verbose=0)\n",
    "\t\tresult_predict_tmp = sc_y.inverse_transform(ann.predict(tmp_X[test_index, :]))\n",
    "\t\tresult_correct_tmp = sc_y.inverse_transform(tmp_y[test_index, :])\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\treturn RMS/kfold_split,R2/kfold_split,Error\n",
    "\n",
    "def SVR_model(tmp_X,tmp_y,sc_y,model_save_path,i):\n",
    "\tregressor_svr = SVR(kernel='rbf')\n",
    "\tlocal_y = tmp_y\n",
    "\tlocal_y = np.reshape(local_y,(-1))\n",
    "\tregressor_svr.fit(tmp_X,local_y)\n",
    "\tpickle.dump(regressor_svr, open(model_save_path[i] + b\".surm\", 'wb'))\n",
    "\n",
    "def SVR_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split):\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\tkf = KFold(n_splits=kfold_split, shuffle=True,random_state =random_seed)\n",
    "\n",
    "\tfor train_index, test_index in kf.split(tmp_X):\n",
    "\t\tlocal_y = tmp_y[train_index, :]\n",
    "\t\tlocal_y = np.reshape(local_y,(-1))\n",
    "\t\tregressor_svr = SVR(kernel='rbf')\n",
    "\t\tregressor_svr.fit(tmp_X[train_index, :],local_y)\n",
    "\t\tresult_predict_tmp = sc_y.inverse_transform(regressor_svr.predict(tmp_X[test_index, :]))\n",
    "\t\tresult_correct_tmp = sc_y.inverse_transform(tmp_y[test_index, :])\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\treturn RMS/kfold_split,R2/kfold_split,Error\n",
    "\n",
    "def RT_model(tmp_X,tmp_y,sc_y,model_save_path,i):\n",
    "\tregressor_tree = DecisionTreeRegressor(random_state=0)\n",
    "\tlocal_y = tmp_y\n",
    "\tlocal_y = np.reshape(local_y,(-1))\n",
    "\tregressor_tree.fit(tmp_X,local_y)\n",
    "\tpickle.dump(regressor_tree, open(model_save_path[i] + b\".surm\", 'wb'))\n",
    "\n",
    "def RT_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split):\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\n",
    "\tkf = KFold(n_splits=kfold_split, shuffle=True,random_state =random_seed)\n",
    "\tfor train_index, test_index in kf.split(tmp_X):\n",
    "\t\tlocal_y = tmp_y[train_index, :]\n",
    "\t\tlocal_y = np.reshape(local_y,(-1))\n",
    "\t\tregressor_tree = DecisionTreeRegressor(random_state=0)\n",
    "\t\tregressor_tree.fit(tmp_X[train_index, :],local_y)\n",
    "\t\tresult_predict_tmp = sc_y.inverse_transform(regressor_tree.predict(tmp_X[test_index, :]))\n",
    "\t\tresult_correct_tmp = sc_y.inverse_transform(tmp_y[test_index, :])\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\treturn RMS/kfold_split,R2/kfold_split,Error\n",
    "\n",
    "def save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param):\n",
    "\tfor i in range(len(test_index)):\n",
    "\t\tresult_out_csv[Start_index][0] = index_count\n",
    "\t\tresult_out_csv[Start_index][1] = result_correct_tmp[i]\n",
    "\t\tresult_out_csv[Start_index][2] = result_predict_tmp[i]\n",
    "\t\tfor j in range(num_param):\n",
    "\t\t\tresult_out_csv[Start_index][3+j] = input_param[test_index[i]][j]\n",
    "\t\tStart_index = Start_index + 1\n",
    "\treturn Start_index\n",
    "\n",
    "def save_csv(model_save_path,result_out_csv,index,num_case,num_param,param_list,elapsed_time,obj_list,RMS,R2,data):\n",
    "\t\n",
    "\n",
    "\tif data.cross_frag == 1:\n",
    "\t\tsave = np.empty(shape=(num_case+7,num_param+5), dtype=np.object)\n",
    "\t\tfor i in range(num_case+7):\n",
    "\t\t\tfor j in range(num_param+5):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\n",
    "\t\tsave[0][0] = obj_list[index]\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tif data.model ==1:\n",
    "\t\t\tsave[1][1] = \"NN\"\n",
    "\t\telif data.model ==2:\n",
    "\t\t\tsave[1][1] = \"SVR\"\n",
    "\t\telif data.model == 3:\n",
    "\t\t\tsave[1][1] = \"RT\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\tsave[3][0] = \"RMS\"\n",
    "\t\tsave[3][1] = str(RMS)\n",
    "\t\tsave[4][0] = \"R2\"\n",
    "\t\tsave[4][1] = str(R2)\n",
    "\t\tsave[6][0] = \"case\"\n",
    "\t\tsave[6][1] = \"K-fold\" \n",
    "\t\tsave[6][2] = \"correct\"\n",
    "\t\tsave[6][3] = \"predict\"\n",
    "\t\tfor j in range(num_param):\n",
    "\t\t\tsave[6][5+j] = param_list[j]\n",
    "\n",
    "\t\tfor i in range(num_case):\n",
    "\t\t\tsave[i+7][0] = str(i)\n",
    "\t\t\tsave[i+7][1] = str(result_out_csv[i][0])\n",
    "\t\t\tsave[i+7][2] = str(result_out_csv[i][1])\n",
    "\t\t\tsave[i+7][3] = str(result_out_csv[i][2])\n",
    "\t\t\tfor j in range(num_param):\n",
    "\t\t\t\tsave[i+7][5+j] = str(result_out_csv[i][3+j])\n",
    "\telse:\n",
    "\t\tsave = np.empty(shape=(3,2), dtype=np.object)\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tfor j in range(2):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\n",
    "\t\tsave[0][0] = obj_list[index]\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tif data.model ==1:\n",
    "\t\t\tsave[1][1] = \"NN\"\n",
    "\t\telif data.model ==2:\n",
    "\t\t\tsave[1][1] = \"SVR\"\n",
    "\t\telif data.model == 3:\n",
    "\t\t\tsave[1][1] = \"RT\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\n",
    "\tfile_name = data.model_path + b\"/\" + data.response_name[index] + b\".csv\"\n",
    "\tfile_name = file_name.decode()\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",delimiter=',')\n",
    "\n",
    "def loadcsv(csv_path,param_list,obj_list):\n",
    "\terror = 0\n",
    "\trow_offset = 0\n",
    "\tindex_param = []\n",
    "\tindex_result = []\n",
    "\tinput_param = None\n",
    "\tresult_correct = None\n",
    "\twith open(csv_path, \"r\",encoding='cp932') as f:\n",
    "\t\tfor tmp_col in csv.reader(f):\n",
    "\t\t\tbreak;\n",
    "\n",
    "\tcol_param = len(param_list)\t\n",
    "\tcol_correct = len(obj_list)\n",
    "\n",
    "\tif tmp_col[0] == \"Objective Values\":\n",
    "\t\trow_offset = 1\n",
    "\t\tcount = 0\n",
    "\t\twith open(csv_path, \"r\",encoding='cp932') as f:\n",
    "\t\t\tfor tmp_col in csv.reader(f):\n",
    "\t\t\t\tif count == 1:\n",
    "\t\t\t\t\tbreak;\n",
    "\t\t\t\tcount = count + 1\n",
    "\t\n",
    "\tcol = len(tmp_col)\n",
    "\n",
    "\tfor i in range(col_param):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tif param_list[i] == tmp_col[j]:\n",
    "\t\t\t\tindex_param.append(j) \n",
    "\t\t\t\tbreak;\n",
    "\t\t\tif j == (col-1):\n",
    "\t\t\t\tmessage_en = \"The variable name \" + param_list[i] + \"�@cannot be found in the csv file.\"\n",
    "\t\t\t\tmessage_jp = \"�ϐ��� \" + param_list[i] + \"�@��csvfile���猩�����܂���\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\t\t\t\treturn input_param,result_correct,error\n",
    "\t\n",
    "\tfor i in range(col_correct):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tif obj_list[i] == tmp_col[j]:\n",
    "\t\t\t\tindex_result.append(j) \n",
    "\t\t\t\tbreak;\n",
    "\t\t\tif j == (col-1):\n",
    "\t\t\t\tmessage_en = \"The variable name \" + param_list[i] + \"�@cannot be found in the csv file.\"\n",
    "\t\t\t\tmessage_jp = \"�ϐ��� \" + obj_list[i] + \"�@��csvfile���猩�����܂���\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\t\t\t\treturn input_param,result_correct,error\n",
    "\t\n",
    "\twith open(csv_path, \"r\",encoding='cp932') as f:\n",
    "\t\treader = csv.reader(f)\n",
    "\t\tstring_list = [row for row in reader]\n",
    "\trow = len(string_list)\n",
    "\t\n",
    "\tinput_param = np.zeros([row - 1 - row_offset,col_param])\n",
    "\tresult_correct = np.zeros([row - 1- row_offset,col_correct])\n",
    "\n",
    "\tfor i in range(row_offset,row - 1):\n",
    "\t\tfor j in range(col_param):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tinput_param[i-row_offset][j]=float(string_list[i+1][int(index_param[j])])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmessage_en = \"A character string was detected in the \" + str(i) + \"row and \" +  str(j) + \"column. Please delete it.\"\n",
    "\t\t\t\tmessage_jp = str(i + 2 + row_offset) + \"�s�� \" + str(j) + \"���ڂɕ����������m���܂����B�폜���Ă��������B\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\t\t\t\n",
    "\tfor i in range(row_offset,row- 1):\n",
    "\t\tfor j in range(col_correct):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresult_correct[i - row_offset][j] = float(string_list[i+1][int(index_result[j])])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmessage_en = \"A character string was detected in the \" + str(i) + \"row and \" +  str(j) + \"column. Please delete it.\"\n",
    "\t\t\t\tmessage_jp = str(i + 2 + row_offset) + \"�s�� \" + str(j) + \"���ڂɕ����������m���܂����B�폜���Ă��������B\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\n",
    "\tlearn_data_tmp = []\n",
    "\tfor i in range(row_offset,row):\n",
    "\t\tlearn_data_tmp.append(string_list[i]) \n",
    "\n",
    "\treturn input_param,result_correct,error,learn_data_tmp\n",
    "\n",
    "def get_data_from_input_dialog():\n",
    "\tdialog = create_input_dialog()\n",
    "\tdialog.Show()\n",
    "\tif dialog.WasCancelled() == False:\n",
    "\t\tdata = get_values_from_input_dialog(dialog)\n",
    "\t\treturn data\n",
    "\treturn DialogData()\n",
    "\n",
    "def get_values_from_input_dialog(dialog):\n",
    "\tdata = DialogData()\n",
    "\tdata.model_path = dialog.GetValue(\"surrogate_model_path\")\n",
    "\tdata.csv_path = dialog.GetValue(\"csv_file_name\")\n",
    "\tdata.cross_val = dialog.GetValue(\"cross_val\")\n",
    "\tdata.model = dialog.GetValue(\"model\")\n",
    "\tdata.cross_frag = dialog.GetValue(\"cross_frag\")\n",
    "\tparam_tmp = dialog.GetValue(\"response_name\")\n",
    "\tparam_tmp = param_tmp.decode()\n",
    "\tparam = param_tmp.split(',')\n",
    "\t\n",
    "\tif data.csv_path == b\"\":\n",
    "\t\tmessage_en = \"Specify input file name.\"\n",
    "\t\tmessage_jp = \"���̓t�@�C�������w�肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.model_path == b\"\":\n",
    "\t\tmessage_en = \"Specify output directory name.\"\n",
    "\t\tmessage_jp = \"�o�̓t�H���_�����w�肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isfile(data.csv_path) == 0 :\n",
    "\t\tmessage_en = \"The input file path is incorrect.\"\n",
    "\t\tmessage_jp = \"���̓t�@�C���p�X�������������܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isdir(data.model_path) == 0:\n",
    "\t\tmessage_en = \"The output folder is incorrect.\"\n",
    "\t\tmessage_jp = \"�o�̓t�H���_�������������܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tif param_tmp == \"\":\n",
    "\t\tmessage_en = \"Specify the name of the response value.\"\n",
    "\t\tmessage_jp = \"�����l�̖��O���w�肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tif data.cross_val <= 1:\n",
    "\t\tmessage_en = \"Set the number of divisions to 2 or more.\"\n",
    "\t\tmessage_jp = \"��������2�ȏ��Őݒ肵�Ă��������B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tfor i in range(len(param)):\n",
    "\t\tError = 0\n",
    "\t\tfor j in range(len(data.response_name)):\n",
    "\t\t\tif param[i].encode() == data.response_name[j]:\n",
    "\t\t\t\tError = 1\n",
    "\t\tif Error == 0:\n",
    "\t\t\tdata.response_name.append(param[i].encode())\n",
    "\n",
    "\tdata.isValid = True\n",
    "\treturn data\n",
    "\n",
    "def create_input_dialog():\n",
    "\tapp = designer.GetApplication()\n",
    "\tdialog = app.CreateDialogBox()\n",
    "\n",
    "\ttitle_jp = \"�㗝���f���쐬(����)\"\n",
    "\ttitle_en = \"Create a surrogate model (beta version)\"\n",
    "\tinputlbl_jp = \"����:\"\n",
    "\tinputlbl_en = \"Input:\"\n",
    "\toutputlbl_jp = \"�o��:\"\n",
    "\toutputlbl_en = \"Output:\"\n",
    "\tcsvinput_jp = \"�w�K�f�[�^�Z�b�g\"\n",
    "\tcsvinput_en = \"Training dataset\" \n",
    "\tsurrogate_path_jp = \"�㗝���f���o�̓p�X\"\n",
    "\tsurrogate_path_en = \"Surrogate model output path\" \n",
    "\tcross_val_jp = \"K-������������\"\n",
    "\tcross_val_en = \"K-Fold  Cross validation\"\t\n",
    "\tfold_val_jp = \"������\"\n",
    "\tfold_val_en = \"K-fold\"\n",
    "\tresponse_jp = \"�����l\"\n",
    "\tresponse_en = \"Response value\"\t\n",
    "\tresponse_name_jp = \"�ϐ����i�J���}���؂��j\"\n",
    "\tresponse_name_en = \"Variable name(Comma separated)\"\t\n",
    "\tcross_use_jp = \"��������\"\n",
    "\tcross_use_en = \"Cross validation\"\n",
    "\tcross_notuse_jp = \"���؂Ȃ�\" \n",
    "\tcross_notuse_en = \"No verification\"\n",
    "\n",
    "\tdialog.SetTranslation(title_en, title_jp)\n",
    "\n",
    "\tdialog.SetTranslation(response_en, response_jp)\n",
    "\tdialog.SetTranslation(response_name_en, response_name_jp)\n",
    "\tdialog.SetTranslation(fold_val_en, fold_val_jp)\n",
    "\tdialog.SetTranslation(cross_val_en, cross_val_jp)\n",
    "\tdialog.SetTranslation(inputlbl_en, inputlbl_jp)\n",
    "\tdialog.SetTranslation(outputlbl_en, outputlbl_jp)\n",
    "\tdialog.SetTranslation(csvinput_en, csvinput_jp)\n",
    "\tdialog.SetTranslation(surrogate_path_en, surrogate_path_jp)\n",
    "\tdialog.SetTranslation(cross_use_en, cross_use_jp)\n",
    "\tdialog.SetTranslation(cross_notuse_en, cross_notuse_jp)\n",
    "\n",
    "\tdialog.AddLabel(response_en)\n",
    "\tdialog.AddString(\"response_name\", response_name_en, \"\")\n",
    "\tdialog.AddLine()\n",
    "\t\n",
    "\tdialog.AddLabel(cross_val_en)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_use_en, 1)\n",
    "\tdialog.AddInteger(\"cross_val\", fold_val_en, 5)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_notuse_en, 2)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddRadio(\"model\", \"Neural network\", 1)\n",
    "\tdialog.AddRadio(\"model\", \"Support Vector Regression\", 2)\n",
    "\tdialog.AddRadio(\"model\", \"Regression tree\", 3)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.SetTitle(title_en)\n",
    "\tdialog.AddLabel(inputlbl_en)\n",
    "\tdialog.AddOpenFilename(\"csv_file_name\", csvinput_en,\"\",\"CSV file (*.csv)\")\n",
    "\t\n",
    "\tdialog.AddLine()\n",
    "\tdialog.AddLabel(outputlbl_en)\n",
    "\tdialog.AddDirectoryPath(\"surrogate_model_path\", surrogate_path_en,\"./\")\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\treturn dialog\n",
    "\n",
    "def show_normal_exit_message():\n",
    "\ttitle_en = \"Finished\"\n",
    "\ttitle_jp = \"�I��\"\n",
    "\tmessage_en = \"Finished.\"\n",
    "\tmessage_jp = \"�I��\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_error_exit_message(message_en, message_jp):\n",
    "\ttitle_en = \"Error\"\n",
    "\ttitle_jp = \"�G���[\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_message(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\n",
    "if py_error == 0:\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_54592/2700465325.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_54592/2700465325.py\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    AnalysisGroup  = app.GetCurrentAnalysisGroup()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\tobj_list = []\n",
    "\tparam_list = []\n",
    "\tmodel_save_path = []\n",
    "\trandom_seed = 0\n",
    "\tnum_case = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\trandom_seed = random.randint(0,2**32-1)\n",
    "\t\t\n",
    " AnalysisGroup  = app.GetCurrentAnalysisGroup()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tAnalysisGroup = app.GetCurrentStudy()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tmessage_en = \"The study or analysis group cannot be found.\"\n",
    "\t\tmessage_jp = \"study�܂��͉��̓O���[�v���������܂����B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jmag에서 export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import os\n",
    "from win32com import client  #activeX연결 모듈\n",
    "\n",
    "jprojfile = u'D:\\KDH\\Thesis\\HDEV\\01_JMAG\\HYH\\ironloss.jproj'\n",
    "dname=u'Gap magnetic flux density'\n",
    "\n",
    "\n",
    "designer = client.dynamic.Dispatch('designer.Application.210') #제이맥 연결 버젼지정시   client.dynamic.Dispatch('designer.Application.180')\n",
    "designer.SetCurrentStudy(u\"Load_Hysteresis_steel_noload\")\n",
    "designer.GetDataManager().GetGraphModel(u\"[Cases] untitled 1\").WriteTable(u\"D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_r_case_no_load_4p12s.csv\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyleecan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:55] Starting running simulation tuto_jmag (machine=SPMSM_4p12s)\n",
      "[20:04:55] Starting Magnetic module\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:21] Solving time step: 100%\n",
      "[20:05:21] Solving time step: 100%\n",
      "[20:05:21] Solving time step: 100%\n",
      "[20:05:22] Solving time step: 100%\n",
      "[20:05:22] Starting Force module\n",
      "[20:05:22] End of simulation tuto_jmag\n",
      "[20:05:22] Starting running simulation tuto_jmag (machine=SPMSM_4p12s)\n",
      "[20:05:22] Starting Magnetic module\n",
      "[20:05:22] Solving time steps: 0%\n",
      "[20:05:22] Solving time steps: 0%\n",
      "[20:05:23] Solving time steps: 0%\n",
      "[20:05:23] Solving time steps: 0%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Starting Force module\n",
      "[20:05:46] End of simulation tuto_jmag\n"
     ]
    }
   ],
   "source": [
    "# Import Pyleecan modules\n",
    "from numpy import exp, sqrt, pi\n",
    "from os.path import join\n",
    "from pyleecan.Classes.Simu1 import Simu1\n",
    "from pyleecan.Classes.InputCurrent import InputCurrent\n",
    "from pyleecan.Classes.OPdq import OPdq\n",
    "from pyleecan.Classes.MagFEMM import MagFEMM\n",
    "from pyleecan.Classes.ForceMT import ForceMT\n",
    "from pyleecan.Classes.Output import Output\n",
    "from pyleecan.Functions.load import load\n",
    "from pyleecan.definitions import DATA_DIR\n",
    "\n",
    "# Load the machine\n",
    "SPMSM_4p12s = load(join(DATA_DIR, \"Machine\", \"SPMSM_4p12s.json\"))\n",
    "\n",
    "# Simulation initialization\n",
    "simu = Simu1(name=\"tuto_jmag\", machine=SPMSM_4p12s)\n",
    "\n",
    "# Definition of the enforced output of the electrical module\n",
    "simu.input = InputCurrent(\n",
    "    Na_tot=121 * 4,\n",
    "    Nt_tot=121 * 4,\n",
    ")\n",
    "# Set Id/Iq according to I0/Phi0\n",
    "simu.input.OP = OPdq(N0=1000)\n",
    "simu.input.OP.set_I0_Phi0(I0=250 / sqrt(2), Phi0=140*pi/180)\n",
    "\n",
    "# Definition of the magnetic simulation: with periodicity\n",
    "simu.mag = MagFEMM(is_periodicity_a=True, is_periodicity_t=True, nb_worker=4)\n",
    "simu.force = ForceMT(is_periodicity_a=True, is_periodicity_t=True)\n",
    "\n",
    "# Definition of the open-circuit simulation\n",
    "simu2 = simu.copy()\n",
    "simu2.input.OP.set_Id_Iq(Id=0,Iq=0)\n",
    "\n",
    "# Run simulations\n",
    "out = simu.run()\n",
    "out2 = simu2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##python 기본 csv 라이브러리를 이용해서 딕셔너리로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciDataTool import Data1D, DataLinspace, DataPattern, DataTime, DataFreq, VectorField\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "csv_pd=pd.read_csv('D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_t_case_no_load_4p12s.csv')\n",
    "csv_dict=csv_pd.to_numpy()\n",
    "csv_dict=np.delete(csv_dict,0,1)\n",
    "csv_dict=csv_dict.transpose()\n",
    "\n",
    "# csv_file=open('D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_r_case1_4p12s.csv',\"r\",encoding=\"ms932\",errors=\"\",newline=\"\")\n",
    "\n",
    "#f = csv.DictReader(csv_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## out.mag check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison FEMM & JMAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyleecan.Functions.Plot import dict_2D, dict_3D\n",
    "from numpy import newaxis\n",
    "np.shape(out.mag.B.components['radial'].values)\n",
    "csv_ndarray=csv_dict[:,:,newaxis]\n",
    "out_jmag=out\n",
    "# out2.mag.B.components['radial'].plot_2D_Data(\"angle\")\n",
    "out_jmag.mag.B.components['radial'].values=csv_ndarray\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"angle\")\n",
    "\n",
    "out_jmag.mag.B.plot_2D_Data(\n",
    "    \"angle\", component_list=[\"radial\"], data_list=[out2.mag.B], legend_list=[\"Load\", \"Noload\"],is_auto_range=False\n",
    ")\n",
    "\n",
    "# out_jmag.mag.B.components['tangential'].plot_2D_Data(\"angle\")\n",
    "\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"angle\")\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"time\")\n",
    "\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"wavenumber=[0,96]\")\n",
    "\n",
    "# out_jmag.mag.B.components['tangential'].plot_2D_Data(\"angle\")\n",
    "# out_jmag.mag.B.components['tangential'].plot_2D_Data(\"wavenumber=[0,96]\")\n",
    "# out_jmag.mag.B.plot_3D_Data(\"time\", \"angle{°}\", component_list=[\"radial\"], **dict_3D,is_2D_view=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Time_periodic = DataLinspace(\n",
    "#     name=\"time\",\n",
    "#     unit=\"s\",\n",
    "#     initial=0,\n",
    "#     final=5,\n",
    "#     number=5,\n",
    "#     include_endpoint=False,\n",
    "#     symmetries={\"period\": 6},\n",
    "# )\n",
    "# print(Time_periodic.get_values(is_oneperiod=True))\n",
    "# # # print(Time_periodic.get_values())\n",
    "# # print(out.mag.B.components['radial'])\n",
    "# # dir(out.mag.B.components['radial'])\n",
    "# # print(out.mag.B.components['radial'])\n",
    "\n",
    "# # out.mag.B.components\n",
    "\n",
    "# #aa=list(a)\n",
    "# from pprint import pprint as pp\n",
    "# f = csv.DictReader(csv_file)\n",
    "# #ff=list(f)[10]\n",
    "# # for row in f: \n",
    "#     # print(row)\n",
    "#     # print(type(row))\n",
    "\n",
    "# csv_file.close()\n",
    "# #type(row)\n",
    "\n",
    "# #row.keys()\n",
    "#pp(row)\n",
    "\n",
    "#type(f)\n",
    "#len(row)\n",
    "\n",
    "#row.values()\n",
    "# ordered_dict_from_csv=list(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기서부터 Mesh solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.fft(csv_ndarray[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(121, 121, 1)\n",
      "(121,)\n",
      "(121,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "a=out.mag.B.components['tangential']._get_values()\n",
    "\n",
    "axe=out.mag.B.components['tangential'].get_axes()\n",
    "#print(axe)\n",
    "print(type(a))\n",
    "np.shape(a)\n",
    "a0=axe[0].get_values()\n",
    "a1=axe[1].get_values()\n",
    "a2=axe[2].get_values()\n",
    "type(a0)\n",
    "np.shape(a0)\n",
    "type(a1)\n",
    "np.shape(a1)\n",
    "#a2\n",
    "#a=out.mag.B.components['radial']._get_values()\n",
    "type(a)\n",
    "print(np.shape(a))\n",
    "print(np.shape(a0))\n",
    "print(np.shape(a1))\n",
    "print(np.shape(a2))\n",
    "\n",
    "#print(axe[0].get_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4=a[0][0:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import ones\n",
    "out_dict = dict()\n",
    "out_dict[\"Bt\"] = ones((100, 504))\n",
    "aa=ones((100, 504))\n",
    "out_dict['Bt'][1]\n",
    "type(out_dict)\n",
    "type(aa)\n",
    "\n",
    "\n",
    "out_dict.pop(\"Bt\")\n",
    "#ii=nt\n",
    "#jj=na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_32812/2473797778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrad2deg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'radial'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#out.mag.B.components['radial'].get_axes()[2].symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from SciDataTool import Data1D, DataLinspace, DataPattern, DataTime, DataFreq, VectorField\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''\n",
    "at=np.transpose(ag)\n",
    "print(np.shape(ag))\n",
    "print(np.shape(at))\n",
    "out_dict = dict()\n",
    "out_dict[\"Bt\"] = np.ones((122, 121))\n",
    "out_dict[\"Bt\"] = at\n",
    "out_dict['Bt'][1,0]\n",
    " '''\n",
    "\n",
    "df=pd.read_csv('D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_r_case1_4p12s.csv')\n",
    "ag=df.values\n",
    "radial=out.mag.B.components['radial']._get_values()\n",
    "axes=out.mag.B.components['radial'].get_axes()[1]\n",
    "\n",
    "dd=axes.get_values()\n",
    "dd=np.rad2deg(dd)\n",
    "out.mag.B.components['radial'].get_axes()[2].get_values()\n",
    "#out.mag.B.components['radial'].get_axes()[2].symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30-12280\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mag.B.get_mag_rphiz_along('axes_list')\n",
    "\n",
    "\n",
    "\n",
    "time = np.linspace(0,10,10,endpoint=False)\n",
    "Time = Data1D(\n",
    "    name=\"time\",\n",
    "    unit=\"s\",\n",
    "    values=time,\n",
    ")\n",
    "fieldA = np.ones(10)\n",
    "fieldB = np.ones(10) * 5\n",
    "fieldC = np.ones(10) * 10\n",
    "new_field = np.array([fieldA, fieldB, fieldC])\n",
    "\n",
    "Phases = Data1D(name=\"phases\", unit=\"\", values=[\"Phase A\",\"Phase B\",\"Phase C\"], is_components=True)\n",
    "Field = DataTime(\n",
    "    name=\"Example phase field\",\n",
    "    symbol=\"X\",\n",
    "    axes=[Phases, Time],\n",
    "    values=new_field,\n",
    ")   \n",
    "results = Field.get_along(\"time=0.01\", \"angle{°}\")\n",
    "out.mag.B.components['radial']=Field\n",
    "\n",
    "out.mag.B.get_rphiz_along('angle')\n",
    "#out.mag.B.components['radial']\n",
    "#print(out.mag.B.components['radial']._get_values())\n",
    "\n",
    "#print(out.mag.B.components['tangential']._get_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Make the data to Scidata format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mag.B.components['tangential']._get_axes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mag.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "external B data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B_elem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_32812/1082511153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#temp comp_flux_airgap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m B_sol = build_solution_vector(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mB_elem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0maxis_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Magnetic Flux Density\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'B_elem' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#temp comp_flux_airgap\n",
    "B_sol = build_solution_vector(\n",
    "    field=B_elem,\n",
    "    axis_list=axis_list,\n",
    "    name=\"Magnetic Flux Density\",\n",
    "    symbol=\"B\",\n",
    "    unit=\"T\",\n",
    ")\n",
    "\n",
    "list_solution = [B_sol, H_sol, mu_sol, A_sol]\n",
    "\n",
    "#\n",
    "out_dict[\"meshsolution\"] = build_meshsolution(\n",
    "        list_solution=list_solution,\n",
    "        label=\"FEMM 2D Magnetostatic\",\n",
    "        list_mesh=meshFEMM,\n",
    "        group=groups,\n",
    "    )\n",
    "\n",
    "\n",
    "##not\n",
    "field=B_elem,\n",
    "axis_list=axis_list,\n",
    "\n",
    "\n",
    "symbol=\"B\"\n",
    "unit=\"T\"\n",
    "name=\"Airgap Magnetic Flux Density\"\n",
    "\n",
    "\n",
    "##build_solution_vector \n",
    "#build_solution_vector(field, axis_list, name=\"\", symbol=\"\", unit=\"\", is_real=True):\n",
    "\n",
    "components = {}\n",
    "\n",
    "x_data = DataTime(\n",
    "    name=name,\n",
    "    unit=unit,\n",
    "    symbol=symbol + \"x\",\n",
    "    axes=axis_list,\n",
    "    values=field[..., 0],\n",
    "    is_real=is_real,\n",
    ")\n",
    "components[\"comp_x\"] = x_data\n",
    "\n",
    "y_data = DataTime(\n",
    "    name=name,\n",
    "    unit=unit,\n",
    "    symbol=symbol + \"y\",\n",
    "    axes=axis_list,\n",
    "    values=field[..., 1],\n",
    "    is_real=is_real,\n",
    ")\n",
    "components[\"comp_y\"] = y_data\n",
    "\n",
    "if field.shape[-1] == 3 and not np_all((field[..., 2] == 0)):\n",
    "    z_data = DataTime(\n",
    "        name=name,\n",
    "        unit=unit,\n",
    "        symbol=symbol + \"z\",\n",
    "        axes=axis_list,\n",
    "        values=field[..., 2],\n",
    "        is_real=is_real,\n",
    "    )\n",
    "    components[\"comp_z\"] = z_data\n",
    "\n",
    "\n",
    "\n",
    "Tempfieled = VectorField(name=name, symbol=symbol, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meshFEMM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_32812/596049673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Define axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mindices_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeshFEMM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"triangle\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mIndices_Cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"indice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0maxis_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndices_Cell\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meshFEMM' is not defined"
     ]
    }
   ],
   "source": [
    "        from pyleecan.Functions.MeshSolution.build_solution_vector import build_solution_vector\n",
    "\n",
    "        # Define axis\n",
    "        Time = Time.copy()\n",
    "        indices_cell = meshFEMM[0].cell[\"triangle\"].indice\n",
    "        Indices_Cell = Data1D(name=\"indice\", values=indices_cell, is_components=True)\n",
    "        axis_list = [Time, Indices_Cell]\n",
    "\n",
    "        B_sol = build_solution_vector(\n",
    "            field=B_elem,\n",
    "            axis_list=axis_list,\n",
    "            name=\"Magnetic Flux Density\",\n",
    "            symbol=\"B\",\n",
    "            unit=\"T\",\n",
    "        )\n",
    "        H_sol = build_solution_vector(\n",
    "            field=H_elem,\n",
    "            axis_list=axis_list,\n",
    "            name=\"Magnetic Field\",\n",
    "            symbol=\"H\",\n",
    "            unit=\"A/m\",\n",
    "        )\n",
    "        mu_sol = build_solution_data(\n",
    "            field=mu_elem,\n",
    "            axis_list=axis_list,\n",
    "            name=\"Magnetic Permeability\",\n",
    "            symbol=\"\\mu\",\n",
    "            unit=\"H/m\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('py38_pyleecan139')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "199ee5ddd5cf9db80b3c3131ae104b574c9fd5dd6255d9f837b6f7ea953865a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
