{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running date: August 01, 2022\n",
      "Pyleecan version:1.3.9\n",
      "SciDataTool version:2.4.8\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "print(\"Running date:\", date.today().strftime(\"%B %d, %Y\"))\n",
    "import pyleecan\n",
    "print(\"Pyleecan version:\" + pyleecan.__version__)\n",
    "import SciDataTool\n",
    "print(\"SciDataTool version:\" + SciDataTool.__version__)\n",
    "\n",
    "from SciDataTool import Data1D, DataLinspace, DataPattern, DataTime, DataFreq, VectorField\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# jmag íŒŒì¼ì—ì„œ ê³µê·¹ ì¤‘ì•™ì—ì„œ ê³µê·¹ìì†ë°€ë„ ì¶”ì¶œ\n",
    "\n",
    "\n",
    "#Input.radius = 81.34*10^-3\n",
    "#Input.initial_angle=52.5;                % Motion ì´ˆê¸°ê°ë„ ì„¤ì •   \n",
    "\n",
    "#ê³µê·¹ìì†ë°€ë„ ê¸°ë°˜ìœ¼ë¡œ AGSF ê³„ì‚°\n",
    "\n",
    "#AGSF ê¸°ë°˜ìœ¼ë¡œ 2D FFT ìˆ˜í–‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JMAG acticex ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from win32com import client  #activeXì—°ê²° ëª¨ë“ˆ\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#cont_path=u'c:/work/test/cont.png'\n",
    "#vect_path=u'c:/work/test/vect.png'\n",
    "jprojfile = u'D:\\KDH\\Thesis\\HDEV\\01_JMAG\\Mes_V_excit\\HDEV_V_excitation.jproj'\n",
    "dname=u'Gap magnetic flux density'\n",
    "\n",
    "\n",
    "app = client.dynamic.Dispatch('designer.Application.202') #ì œì´ë§¥ ì—°ê²° ë²„ì ¼ì§€ì •ì‹œ   client.dynamic.Dispatch('designer.Application.180')\n",
    "#app.newproject('project X1')\n",
    "app.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "#import designer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import copy\n",
    "import importlib\n",
    "import gc\n",
    "#import psutil\n",
    "\n",
    "\n",
    "app = client.dynamic.Dispatch('designer.Application.202') #ì œì´ë§¥ ì—°ê²° ë²„ì ¼ì§€ì •ì‹œ   client.dynamic.Dispatch('designer.Application.180')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN param\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "\n",
    "num_epoch = 50\n",
    "num_batch = 10\n",
    "ins_dir = \"\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version\n",
    "py_error = 0\n",
    "# NN param\n",
    "num_epoch = 50\n",
    "num_batch = 10\n",
    "ins_dir = \"\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show_message_immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_message_immediately(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (sys.version >= \"3.8\"):\n",
    "\ttry:\n",
    "\t\timport tensorflow as tf\n",
    "\t\tfrom tensorflow.python.eager import context\n",
    "\t\tfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\t\tfrom sklearn.preprocessing import StandardScaler\n",
    "\t\tfrom sklearn.svm import SVR\n",
    "\t\tfrom sklearn.tree import DecisionTreeRegressor\n",
    "\t\tfrom sklearn.model_selection import KFold\n",
    "\t\tfrom sklearn.metrics import r2_score\n",
    "\t\tfrom sklearn.metrics import mean_squared_error\n",
    "\t\tfrom pathlib import Path\n",
    "\t\ttf.get_logger().setLevel(\"ERROR\")\n",
    "\texcept:\n",
    "\t\ttitle_en = \"Python library error\"\n",
    "\t\ttitle_jp = \"Pythonï¿½@ï¿½ï¿½ï¿½Cï¿½uï¿½ï¿½ï¿½ï¿½ï¿½Gï¿½ï¿½ï¿½[\"\n",
    "\t\tmessage_en = \"The runtime library cannot be found. Please refer to the manual for the required packages.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½^ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½Cï¿½uï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Bï¿½Kï¿½vï¿½Èƒpï¿½bï¿½Pï¿½[ï¿½Wï¿½Íƒ}ï¿½jï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½ï¿½ï¿½Qï¿½Æ‚ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\t\tpy_error = 1\n",
    "\n",
    "if (sys.version < \"3.8\"):\n",
    "\ttitle_en = \"Python Version Error\"\n",
    "\ttitle_jp = \"Pythonï¿½@ï¿½oï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½ï¿½Gï¿½ï¿½ï¿½[\"\n",
    "\tmessage_en = \"Please use Python of newer version over 3.8\"\n",
    "\tmessage_jp = \"ï¿½oï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½3.8ï¿½Èï¿½ï¿½ï¿½Pythonï¿½ï¿½ï¿½gï¿½pï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\tpy_error = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class DialogData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DialogData:\n",
    "\tdef __init__(self):\n",
    "\t\tself.model_path = \"\"\n",
    "\t\tself.compute_mode=0\n",
    "\t\tself.bitmap_mode = 1\n",
    "\t\tself.bitmap_size= 1\n",
    "\t\tself.cross_val = 5\n",
    "\t\tself.cross_frag = 1\n",
    "\t\tself.num_thread = 8 \n",
    "\t\tself.input_dir = \"\"\n",
    "\t\tself.isValid  = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Topology_setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Topology_setting:\n",
    "\tdef __init__(self):\n",
    "\t\tself.num_study = 1\n",
    "\t\tself.AnalysisGroup = 0\n",
    "\t\tself.study_name = []\n",
    "\t\tself.equation_num_study = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "class Surrogate_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Surrogate_data:\n",
    "\tdef __init__(self):\n",
    "\t\tself.Readjcf_name = []\n",
    "\t\tself.OutJCF_name = []\n",
    "\t\tself.Readjcf_name_opt = \"\"\n",
    "\t\tself.bitmap_run_cmd = []\t\n",
    "\t\t\n",
    "\t\tself.Read_file_num = 0\n",
    "\t\tself.JCF_file_num = 0\n",
    "\t\tself.Response_name = []\n",
    "\t\tself.Response_num = 0\n",
    "\t\tself.Response_value = []\n",
    "\t\tself.Response_value_scale = []\n",
    "\t\tself.Response_multi_num = []\n",
    "\t\tself.equation_num_base = 0\n",
    "\t\tself.equation_num_study = []\n",
    "\t\t\n",
    "\t\tself.Bitmap_path = []\n",
    "\t\tself.Bitmap_path_tmp = []\n",
    "\t\tself.Bitmap_data = []\n",
    "\t\tself.Bitmap_data_scale = []\n",
    "\t\t\n",
    "\t\tself.model_path = []\n",
    "\t\tself.output_data = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Make_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Make_model:\n",
    "\tdef __init__(self):\n",
    "\t\tself.model_path = \"\"\n",
    "\t\tself.cross_frag = 1\n",
    "\t\tself.cross_val = 5\n",
    "\t\tself.num_thread = 8\n",
    "\t\tself.compute_mode = 1\n",
    "\t\tself.bitmap_size = 200\n",
    "\t\tself.Modelsavepath = \"\"\n",
    "\t\tself.Responsename = \"\"\n",
    "\t\tself.Res_val = None\n",
    "\t\tself.Bitmap_path_num = 0\n",
    "\t\tself.Bitmap_data = None\n",
    "\t\tself.Bitmap_data_scale = None\t\n",
    "\t\tself.output_data = None\n",
    "\t\tself.sc_y = None\n",
    "\t\tself.OutJCF_name = None\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\tglobal ins_path\n",
    "\t\n",
    "\tif os.getenv(\"JMAG_CNN_MODEL_MAKE_MODE\") != \"1\": \n",
    "\n",
    "\t\tRMS = 0.0\n",
    "\t\tR2 = 0.0\n",
    "\t\tError = 0\n",
    "\t\trandom_seed = random.randint(0,2**32-1)\n",
    "\t\n",
    "\t\tSet_data = Topology_setting()\n",
    "\t\tSur_data = Surrogate_data()\n",
    "\t\n",
    "\t\tAnalysisGroup  = app.GetCurrentAnalysisGroup()\n",
    "\t\tSet_data.AnalysisGroup = 1\n",
    "\n",
    "\t\tif AnalysisGroup.IsValid() == False:\n",
    "\t\t\tSet_data.AnalysisGroup = 0\n",
    "\t\t\tAnalysisGroup = app.GetCurrentStudy()\n",
    "\n",
    "\t\tif AnalysisGroup.IsValid() == False:\n",
    "\t\t\tmessage_en = \"The study or analysis group cannot be found.\"\n",
    "\t\t\tmessage_jp = \"studyï¿½Ü‚ï¿½ï¿½Í‰ï¿½ï¿½ÍƒOï¿½ï¿½ï¿½[ï¿½vï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\treturn\n",
    "\n",
    "\t\tError = Get_Topology_Setting(Set_data,AnalysisGroup)\n",
    "\t\n",
    "\t\tif Error ==  1:\n",
    "\t\t\treturn\n",
    "\t\n",
    "\t\tin_usr_param = get_data_from_input_dialog()\n",
    "\t\tif in_usr_param.isValid == False:\n",
    "\t\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_warning_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check_Run_Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_error_exit_message(message_en, message_jp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create_bitmapcsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\tcheck_path()\n",
    "\t\n",
    "\t\twarning_GPU,warning_CPU = Check_Run_Mode(in_usr_param)\n",
    "\t\n",
    "\t\tif warning_GPU == 1:\n",
    "\t\t\tmessage_en = \"The library to run on the GPU is insufficient, or the corresponding GPU cannot be found. It runs in CPU mode, is that okay?\"\n",
    "\t\t\tmessage_jp = \"GPUï¿½Å“ï¿½ï¿½ì‚³ï¿½ï¿½ï¿½é‚½ï¿½ß‚Ìƒï¿½ï¿½Cï¿½uï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½sï¿½ï¿½ï¿½Aï¿½Ü‚ï¿½ï¿½Í‘Î‰ï¿½ï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½GPUï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½BCPUï¿½ï¿½ï¿½[ï¿½hï¿½Åï¿½ï¿½sï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½ë‚µï¿½ï¿½ï¿½Å‚ï¿½ï¿½å‚¤ï¿½ï¿½ï¿½B\"\n",
    "\t\t\tcancell = show_warning_message(message_en, message_jp)\n",
    "\t\t\tif cancell:\n",
    "\t\t\t\treturn\n",
    "\n",
    "\t\tif warning_CPU != 0:\n",
    "\t\t\tmessage_en = \"The specified number of parallels and the number of parallels executed are different. Designer must be restarted for the settings to take effect.\"\n",
    "\t\t\tmessage_jp = \"ï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ì¬ï¿½ï¿½ï¿½É‚ï¿½ \" + str(warning_CPU) + \" ï¿½ï¿½ï¿½ï¿½ï¿½Åï¿½ï¿½sï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½Bï¿½İ’ï¿½ï¿½ğ”½‰fï¿½ï¿½ï¿½ï¿½ï¿½é‚½ï¿½ß‚É‚ï¿½Designerï¿½ÌÄ‹Nï¿½ï¿½ï¿½ï¿½ï¿½Kï¿½vï¿½Å‚ï¿½ï¿½B\"\n",
    "\t\t\tcancell = show_warning_message(message_en, message_jp)\n",
    "\t\t\n",
    "\t\t\tif cancell:\n",
    "\t\t\t\treturn\n",
    "\t\n",
    "\t\tSearch_jcf(in_usr_param,Sur_data,Set_data)\n",
    "\t\n",
    "\t\tif Sur_data.Read_file_num == 0:\n",
    "\t\t\tmessage_en = \"JCF file not found. Make sure that the path you specified is correct.\"\n",
    "\t\t\tmessage_jp = \"JCFï¿½tï¿½@ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Bï¿½wï¿½è‚µï¿½ï¿½ï¿½pï¿½Xï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½mï¿½Fï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\treturn\n",
    "\t\n",
    "\t\tRead_Response_value(in_usr_param,Set_data,Sur_data)\n",
    "\t\tCreate_bitmapcsv(in_usr_param,Sur_data,Set_data)\n",
    "\t\tMake_dir(in_usr_param,Sur_data)\n",
    "\t\n",
    "\t\tos.environ[\"JMAG_CNN_MODEL_MAKE_MODE\"] = \"1\"\n",
    "\t\tos.environ[\"JMAG_TOPOLOGY_CNN_MODELPATH\"]= in_usr_param.model_path.decode()\n",
    "\n",
    "\t\tfor i in range(Sur_data.Response_num):\n",
    "\t\t\tfor j in range(Sur_data.Response_multi_num[i]):\n",
    "\t\t\t\tstart = time.time()\n",
    "\n",
    "\t\t\t\t#f = open(in_usr_param.model_path.decode() + \"/cnn_memory.log\", 'a')\n",
    "\n",
    "\t\t\t\tif Sur_data.Response_multi_num[i]== 1:\n",
    "\t\t\t\t\tname = Sur_data.Response_name[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tname = Sur_data.Response_name[i] + str(j + 1)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#f.write(name + \"\\n\")\n",
    "\t\t\t\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"   \")\n",
    "\t\t\t\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\")\n",
    "\t\t\t\t#f.flush()\n",
    "\n",
    "\t\t\t\tSave_param(in_usr_param,Sur_data,i,j)\n",
    "\t\t\t\tSTD_scale(in_usr_param,Sur_data,i,j)\n",
    "\n",
    "\t\t\t\tif os.name == 'nt':\t\n",
    "\t\t\t\t\tsubprocess.run([ins_path + r\"/designer.exe\",ins_path + \"/scripts/Make_Surrogate_Model_for_CNN.py\",r\"-w\"])\t\t\t\t\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsubprocess.run([ins_path + r\"/designer\",ins_path + \"/scripts/Make_Surrogate_Model_for_CNN.py\",r\"-w\"])\t\t\n",
    "\n",
    "\t\t\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/Error.csv\"):\n",
    "\t\t\t\t\tErr = np.loadtxt(in_usr_param.model_path.decode() + \"/Error.csv\", encoding=\"utf-8\",delimiter=\",\")\n",
    "\t\t\t\t\tError = int(Err)\n",
    "\n",
    "\t\t\t\tif Error == 1:\n",
    "\t\t\t\t\tmessage_en = \"The save path for the surrogate model is too long. Please shorten the path.\"\n",
    "\t\t\t\t\tmessage_jp = \"ï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ì•Û‘ï¿½ï¿½pï¿½Xï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½Bï¿½pï¿½Xï¿½ï¿½ï¿½Zï¿½ï¿½ï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/csvfilepath.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/param.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/response.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/Error.csv\")\n",
    "\n",
    "\t\t\t\t\treturn\n",
    "\t\t\t\t\n",
    "\t\t\t\tif Error == 2:\n",
    "\t\t\t\t\tmessage_en = \"The response value \" + Sur_data.Response_name[i] + \" may contain an outlier. Delete the case that contains an outlier.\"\n",
    "\t\t\t\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½l\" + Sur_data.Response_name[i] + \"ï¿½ÉˆÙï¿½ï¿½lï¿½ï¿½ï¿½Ü‚Ü‚ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½Â”\\ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½Bï¿½Ùï¿½ï¿½lï¿½ï¿½ï¿½Ü‚Ü‚ï¿½ï¿½ï¿½ï¿½Pï¿½[ï¿½Xï¿½ï¿½ï¿½íœï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/csvfilepath.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/param.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/response.csv\")\n",
    "\t\t\t\t\tos.remove(in_usr_param.model_path.decode() + \"/Error.csv\")\n",
    "\n",
    "\t\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\n",
    "\t\t\t\tend = time.time()\n",
    "\t\t\t\telapsed_time = end - start\n",
    "\t\t\t\t\n",
    "\t\t\t\tif in_usr_param.cross_frag == 1:\n",
    "\t\t\t\t\tRMS,R2 = Load_result(Sur_data,in_usr_param)\n",
    "\t\t\t\t\n",
    "\t\t\t\tsave_set_file(in_usr_param,Set_data,Sur_data,i,j)\t\n",
    "\t\t\t\tsave_zip(Sur_data,i,j)\n",
    "\t\t\t\tsave_csv(in_usr_param,Sur_data,elapsed_time,RMS,R2,i,j)\n",
    "\n",
    "\t\t\t\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"  \")\n",
    "\t\t\t\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\" )\n",
    "\t\t\t\t#f.close()\n",
    "\t\t\n",
    "\t\tos.remove(in_usr_param.model_path.decode() + \"/csvfilepath.csv\")\n",
    "\t\tos.remove(in_usr_param.model_path.decode() + \"/param.csv\")\n",
    "\t\tos.remove(in_usr_param.model_path.decode() + \"/response.csv\")\n",
    "\t\t\n",
    "\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/Error.csv\"):\n",
    "\t\t\tos.remove(in_usr_param.model_path.decode() + \"/Error.csv\")\n",
    "\n",
    "\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/R2RMS.csv\"):\n",
    "\t\t\tos.remove(in_usr_param.model_path.decode() + \"/R2RMS.csv\")\n",
    "\n",
    "\t\tif os.path.isfile(in_usr_param.model_path.decode() + \"/result.csv\"):\n",
    "\t\t\tos.remove(in_usr_param.model_path.decode() + \"/result.csv\")\n",
    "\t\t\n",
    "\t\tif in_usr_param.compute_mode == 1:\n",
    "\t\t\tmessage_en = \"If you want to create a surrogate model using GPU again, restart Designer. Memory may overflow.\"\n",
    "\t\t\tmessage_jp = \"ï¿½Ä‚ï¿½GPUï¿½ï¿½ï¿½pï¿½ï¿½ï¿½Ä‘ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ê‡ï¿½É‚ï¿½Designerï¿½ï¿½ï¿½Ä‹Nï¿½ï¿½ï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Bï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Iï¿½[ï¿½oï¿½[ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½Â”\\ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½B\"\n",
    "\t\t\tshow_warning_message(message_en, message_jp)\n",
    "\n",
    "\t\tshow_normal_exit_message()\t\n",
    "\n",
    "\t\tos.environ.pop(\"JMAG_CNN_MODEL_MAKE_MODE\",None)\n",
    "\t\tos.environ.pop(\"JMAG_TOPOLOGY_CNN_MODELPATH\",None)\n",
    "\t\tos.environ.pop(\"JMAG_CNN_MODEL_ERROR\",None)\n",
    "\n",
    "\telse:\n",
    "\t\tMake_Surrogate_Model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make_Surrogate_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Make_Surrogate_Model():\n",
    "\tmake_data = Make_model()\n",
    "\tmodel_path = os.getenv(\"JMAG_TOPOLOGY_CNN_MODELPATH\")\n",
    "\t\n",
    "\t#f = open(model_path + \"/cnn_memory.log\", 'a')\n",
    "\t#f.write(\"child process \\n\")\n",
    "\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"   \")\n",
    "\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\")\n",
    "\n",
    "\tLoad_param(make_data,model_path)\n",
    "\tLoad_Response_val(make_data)\n",
    "\tLoad_std(make_data)\n",
    "\tLoad_bitmap(make_data)\n",
    "\t\n",
    "\tmodel,optimizers,reduce_lr = CNN_function(make_data)\n",
    "\tError = CNN_model(optimizers,reduce_lr,model,make_data)\n",
    "\n",
    "\tif Error == 1:\n",
    "\t\tError_log(make_data,1)\n",
    "\t\tapp.Quit()\n",
    "\n",
    "\tif make_data.cross_frag == 1:\n",
    "\t\tRMS,R2,Error = CNN_KFold(optimizers,reduce_lr,model,make_data)\n",
    "\t\tsave_result_csv(make_data,RMS,R2,Error)\n",
    "\n",
    "\tif Error == 1:\n",
    "\t\tError_log(make_data,2)\n",
    "\t\tapp.Quit()\n",
    "\t\n",
    "\tos.environ[\"JMAG_CNN_MODEL_ERROR\"] = \"0\"\n",
    "\n",
    "\t#f.write(\"memory  \" + str(psutil.virtual_memory().used) + \"  \")\n",
    "\t#f.write(\"swap_memory  \" + str(psutil.swap_memory().used) + \"\\n\" )\n",
    "\t#f.write(\"child process End\\n\")\n",
    "\t#f.close()\n",
    "\t\n",
    "\tapp.Quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Save_param(in_usr_param,Sur_data,index_i,index_j):\n",
    "\n",
    "\tsave = np.empty(shape=(8,2), dtype=np.object)\n",
    "\n",
    "\tsave[0][0] = \"model_path\" \n",
    "\tsave[1][0] = \"cross_frag\"\n",
    "\tsave[2][0] = \"cross_val\"\n",
    "\tsave[3][0] = \"num_thread\"\n",
    "\tsave[4][0] = \"compute_mode\" \n",
    "\tsave[5][0] = \"bitmap_size\"\n",
    "\tsave[6][0] = \"Modelsavepath\"\n",
    "\tsave[7][0] = \"Responsename\"\n",
    "\n",
    "\tsave[0][1] = str(in_usr_param.model_path.decode())\t\n",
    "\tsave[1][1] = str(in_usr_param.cross_frag)\n",
    "\tsave[2][1] = str(in_usr_param.cross_val)\n",
    "\tsave[3][1] = str(in_usr_param.num_thread)\n",
    "\tsave[4][1] = str(in_usr_param.compute_mode)\n",
    "\tsave[5][1] = str(in_usr_param.bitmap_size)\n",
    "\t\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tname = Sur_data.model_path[index_i] \n",
    "\t\tresname = Sur_data.Response_name[index_i]\n",
    "\telse:\n",
    "\t\tname = Sur_data.model_path[index_i] + str(index_j + 1) \n",
    "\t\tresname = Sur_data.Response_name[index_i] + str(index_j + 1)\n",
    "\n",
    "\tsave[6][1] = name\n",
    "\tsave[7][1] = resname\n",
    "\n",
    "\tfile_name = in_usr_param.model_path.decode() + \"/param.csv\"\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get_Topology_Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Topology_Setting(Set_data,AnalysisGroup):\n",
    "\t\n",
    "\tif Set_data.AnalysisGroup == 1:\n",
    "\t\tSet_data.num_study = AnalysisGroup.NumStudies()\n",
    "\t\tfor i in range(Set_data.num_study):\n",
    "\t\t\tSet_data.study_name.append(AnalysisGroup.GetStudy(i).GetName())\t\n",
    "\t\t\tSet_data.study_name[i] = Set_data.study_name[i].replace(\" \",\"_\")\n",
    "\n",
    "\t\tfor i in range(Set_data.num_study):\n",
    "\t\t\tSet_data.equation_num_study.append(AnalysisGroup.GetStudy(i).GetDesignTable().NumParameters())\n",
    "\telse:\n",
    "\t\tSet_data.equation_num_study.append(0)\n",
    "\t\t\n",
    "\tSet_data.study_name.append(AnalysisGroup.GetName())\n",
    "\tSet_data.study_name[0] = Set_data.study_name[0].replace(\" \",\"_\")\n",
    "\tSet_data.equation_num_base = AnalysisGroup.GetDesignTable().NumParameters()\n",
    "\n",
    "\tif Set_data.AnalysisGroup == 1:\n",
    "\t\tcount = 0 \t\n",
    "\t\tfor i in range(Set_data.equation_num_base):\n",
    "\t\t\tname = AnalysisGroup.GetDesignTable().ParameterName(i)\n",
    "\t\t\tif \"CAD parameters:\" in name:\n",
    "\t\t\t\tcount = count + 1\n",
    "\n",
    "\t\tSet_data.equation_num_base = Set_data.equation_num_base - count \n",
    "\t\n",
    "\tif Set_data.AnalysisGroup == 0:\n",
    "\t\tNum_cond = AnalysisGroup.NumConditions()\n",
    "\t\tfor i in range(Num_cond):\t\n",
    "\t\t\tif AnalysisGroup.GetCondition(i).GetScriptTypeName() == \"SensitivityAnalysis\":\n",
    "\t\t\t\tmessage_en = \"You cannot create a surrogate model with a model for which topology optimization(Sensitivity Analysis) conditions have been set.\"\n",
    "\t\t\t\tmessage_jp = \"ï¿½gï¿½|ï¿½ï¿½ï¿½Wï¿½[ï¿½Å“Kï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½xï¿½ï¿½ï¿½Íjï¿½ï¿½ï¿½İ’è‚µï¿½ï¿½ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Å‘ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìì¬ï¿½Ísï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\treturn 1\n",
    "\telse:\n",
    "\t\tfor i in range(Set_data.num_study):\n",
    "\t\t\tstudy = AnalysisGroup.GetStudy(i)\n",
    "\t\t\tfor j in range(study.NumConditions()):\n",
    "\t\t\t\tif study.GetCondition(j).GetScriptTypeName() == \"SensitivityAnalysis\":\n",
    "\t\t\t\t\tmessage_en = \"You cannot create a surrogate model with a model for which topology optimization(Sensitivity Analysis) conditions have been set.\"\n",
    "\t\t\t\t\tmessage_jp = \"ï¿½gï¿½|ï¿½ï¿½ï¿½Wï¿½[ï¿½Å“Kï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½xï¿½ï¿½ï¿½Íjï¿½ï¿½ï¿½İ’è‚µï¿½ï¿½ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Å‘ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìì¬ï¿½Ísï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\t\treturn 1\n",
    "\n",
    "\tif AnalysisGroup.GetOptimizationTable().NumParameters() != 0:\n",
    "\t\tmessage_en = \"It cannot be used with parametric optimization when creating a surrogate model using CNN.\"\n",
    "\t\tmessage_jp = \"CNNï¿½ï¿½ï¿½pï¿½ï¿½ï¿½Ä‘ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½ì¬ï¿½ï¿½ï¿½ï¿½ï¿½Û‚ÉAï¿½pï¿½ï¿½ï¿½ï¿½ï¿½gï¿½ï¿½ï¿½bï¿½Nï¿½Å“Kï¿½ï¿½ï¿½Æ•ï¿½ï¿½pï¿½Í‚Å‚ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn 1\n",
    "\n",
    "\tif os.getenv(\"JMAG_TOPOLOGY_WITH_PARAMETER\") != None:\n",
    "\t\tmessage_en = \"It cannot be used with parametric optimization when creating a surrogate model using CNN.\"\n",
    "\t\tmessage_jp = \"CNNï¿½ï¿½ï¿½pï¿½ï¿½ï¿½Ä‘ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½ì¬ï¿½ï¿½ï¿½ï¿½ï¿½Û‚ÉAï¿½pï¿½ï¿½ï¿½ï¿½ï¿½gï¿½ï¿½ï¿½bï¿½Nï¿½Å“Kï¿½ï¿½ï¿½Æ•ï¿½ï¿½pï¿½Í‚Å‚ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn 1\n",
    "\n",
    "\treturn 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read_Response_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Read_Response_value(in_usr_param,Set_data,Sur_data):\n",
    "\tglobal ins_path\t\n",
    "\n",
    "\tindex = []\n",
    "\tRes_val_max = 0\n",
    "\t\n",
    "\tfor i in range(Set_data.num_study):\n",
    "\t\tif Set_data.AnalysisGroup == 0:\n",
    "\t\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/\" + Set_data.study_name[i] + \"*.csv\"\n",
    "\t\telse:\n",
    "\t\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/**/\" + Set_data.study_name[i] + \"*.csv\"\n",
    "\n",
    "\t\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\t\tpathlist =list(glob.glob(search_path))\t\n",
    "\n",
    "\t\tfor j in range(len(pathlist)):\t\t\t\t\n",
    "\t\t\tfilename = os.path.splitext(os.path.basename(pathlist[j]))[0]\t\t\n",
    "\t\t\tinclude = 0\n",
    "\t\t\tfor k in range(len(Sur_data.Response_name)):\n",
    "\t\t\t\tif Sur_data.Response_name[k] == filename:\n",
    "\t\t\t\t\tinclude = 1\n",
    "\t\t\t\t\tbreak;\n",
    "\t\t\tif \tinclude == 0:\n",
    "\t\t\t\tval_tmp = []\n",
    "\t\t\t\tSur_data.Response_name.append(filename)\n",
    "\t\t\t\tSur_data.equation_num_study.append(Set_data.equation_num_study[i])\n",
    "\t\t\t\tval_tmp = np.loadtxt(pathlist[j], encoding=\"utf-8\",delimiter=\",\", skiprows=Set_data.equation_num_base + Set_data.equation_num_study[i] + 3,usecols=1,dtype=np.object)\n",
    "\t\t\t\tlen_tmp = len(val_tmp)\n",
    "\t\t\t\tindex.append(0)\n",
    "\n",
    "\t\t\t\tSur_data.Response_multi_num.append(len_tmp - 1)\n",
    "\t\t\t\tif Res_val_max < len_tmp:\n",
    "\t\t\t\t\tRes_val_max = len_tmp\n",
    "\t\t\t\t\n",
    "\tRes_val_max = Res_val_max - 1\n",
    "\tSur_data.Response_num = len(Sur_data.Response_name)\n",
    "\tSur_data.Response_value = np.empty(shape=(Sur_data.Read_file_num,Sur_data.Response_num,Res_val_max), dtype=np.float64)\n",
    "\tSur_data.OutJCF_name = np.empty(shape=(Sur_data.Read_file_num,Sur_data.Response_num), dtype=np.object)\n",
    "\n",
    "\tfor i in range(Sur_data.JCF_file_num):\n",
    "\t\tfor j in range(Sur_data.Response_num):\n",
    "\t\t\tpath_tmp = Sur_data.Readjcf_name[i] \n",
    "\t\t\tpath_tmp = path_tmp.replace(\"Designer.jcf\",Sur_data.Response_name[j]+\".csv\")\n",
    "\t\t\t\n",
    "\t\t\tif os.path.isfile(path_tmp):\n",
    "\t\t\t\tval_tmp = np.loadtxt(path_tmp, encoding=\"utf-8\",delimiter=\",\", skiprows=Set_data.equation_num_base + Sur_data.equation_num_study[j] + 4,usecols=1,dtype=np.object)\t\n",
    "\t\t\t\tSur_data.OutJCF_name[index[j]][j] = Sur_data.Readjcf_name[i] \n",
    "\t\t\t\n",
    "\t\t\t\tif Sur_data.Response_multi_num[j] > 1:\n",
    "\t\t\t\t\tfor k in range(Sur_data.Response_multi_num[j]):\n",
    "\t\t\t\t\t\tSur_data.Response_value[index[j]][j][k] = float(val_tmp[k])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tSur_data.Response_value[index[j]][j][0] = float(val_tmp)\t\n",
    "\t\t\t\n",
    "\t\t\t\tindex[j] = index[j] + 1 \n",
    "\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search_jcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Search_jcf(in_usr_param,Sur_data,Set_data):\n",
    "\tglobal ins_path\t\n",
    "\n",
    "\tif os.name == 'nt':\t\n",
    "\t\ttobitmap_exe = ins_path.replace(os.path.sep, '/') + \"/createbitmap.exe\"\n",
    "\telse:\n",
    "\t\ttobitmap_exe = ins_path.replace(os.path.sep, '/') + \"/solver/bin/createbitmap\"\n",
    "\t\n",
    "\trename_bitmap = \"_bitmap_\" + str(in_usr_param.bitmap_size) + \".csv\"\n",
    "\t\n",
    "\tif Set_data.AnalysisGroup == 0:\n",
    "\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/Designer.jcf\"\n",
    "\t\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\telse:\n",
    "\t\tsearch_path = glob.escape(in_usr_param.input_dir.decode()) + \"/**/**/Designer.jcf\"\n",
    "\t\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\n",
    "\tpathlist =list(glob.glob(search_path))\n",
    "\torg_jcf_path = in_usr_param.input_dir.decode() +  \"/Designer.jcf\"\n",
    "\tSur_data.Readjcf_name_opt = org_jcf_path\n",
    "\tsearch_path = search_path.replace(os.path.sep, '/')\n",
    "\n",
    "\tn_data = len(pathlist)\n",
    "\tpathlist = sorted(pathlist)\n",
    "\n",
    "\tfor i in range(n_data):\n",
    "\t\tpath,ext = os.path.splitext(pathlist[i])\n",
    "\t\tcsvpath = path + rename_bitmap\n",
    "\t\tcsvpath = csvpath.replace(os.path.sep, '/')\n",
    "\t\t#if os.path.exists(csvpath) == False:\n",
    "\t\tpathlist[i] = pathlist[i].replace(os.path.sep, '/')\n",
    "\t\tcmd = tobitmap_exe ,pathlist[i] ,csvpath ,str(in_usr_param.bitmap_size) ,str(in_usr_param.btimap_mode) ,org_jcf_path\n",
    "\t\t\n",
    "\t\tSur_data.Readjcf_name.append(pathlist[i])\n",
    "\t\t\n",
    "\t\tif Set_data.AnalysisGroup == 0:\n",
    "\t\t\tSur_data.Bitmap_path.append(csvpath)\n",
    "\t\t\tSur_data.bitmap_run_cmd.append(cmd)\n",
    "\t\telse:\n",
    "\t\t\tif \"/0000/\" in csvpath:\n",
    "\t\t\t\tSur_data.Bitmap_path.append(csvpath)\n",
    "\t\t\t\tSur_data.bitmap_run_cmd.append(cmd)\n",
    "\n",
    "\tSur_data.Read_file_num = len(Sur_data.Bitmap_path)\n",
    "\tSur_data.JCF_file_num = len(Sur_data.Readjcf_name)\n",
    "\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Error_log(make_data,num):\n",
    "\tError = np.empty(shape=(1), dtype=np.object)\n",
    "\tError[0] = str(num)\n",
    "\t\n",
    "\tfile_name = make_data.model_path + \"/Error.csv\"\n",
    "\tnp.savetxt(file_name,Error,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def Load_param(make_data,model_path):\n",
    "\n",
    "\tparam = np.loadtxt(model_path + \"/param.csv\", encoding=\"utf-8\",delimiter=\",\",usecols=1,dtype=np.object)\n",
    "\t\n",
    "\tmake_data.model_path = param[0]\n",
    "\tmake_data.cross_frag = int(param[1])\n",
    "\tmake_data.cross_val = int(int(param[2]))\n",
    "\tmake_data.num_thread = int(param[3])\n",
    "\tmake_data.compute_mode = int(param[4])\n",
    "\tmake_data.bitmap_size = int(param[5])\n",
    "\tmake_data.Modelsavepath = param[6]\n",
    "\tmake_data.Responsename = param[7]\n",
    "\n",
    "def Load_std(make_data):\n",
    "\tpath = make_data.Modelsavepath\n",
    "\tmodel_name = make_data.Responsename\n",
    "\tmake_data.sc_y = pickle.load(open(path +\"/\" + model_name + \"_y.pkl\", 'rb'))\t\n",
    "\n",
    "def Load_Response_val(make_data):\n",
    "\tdata = np.loadtxt(make_data.model_path + \"/response.csv\", encoding=\"utf-8\",delimiter=\",\",usecols=0,dtype=np.float64)\n",
    "\tmake_data.Res_val = data\t\n",
    "\n",
    "def Load_bitmap(make_data):\n",
    "\tpath =  np.loadtxt(make_data.model_path + \"/csvfilepath.csv\", encoding=\"utf-8\",delimiter=\",\",dtype=np.object)\n",
    "\tmake_data.Bitmap_path_num = len(path)\n",
    "\tmake_data.OutJCF_name = path\n",
    "\tbitmap = []\n",
    "\n",
    "\tmake_data.Bitmap_data = np.zeros((make_data.Bitmap_path_num,make_data.bitmap_size,make_data.bitmap_size,1))\n",
    "\n",
    "\tfor i in range(make_data.Bitmap_path_num):\n",
    "\t\timage = pd.read_csv(path[i],header=None)\n",
    "\t\timage = image.values\n",
    "\t\timage = image.reshape(make_data.bitmap_size,make_data.bitmap_size,1)\n",
    "\t\tmake_data.Bitmap_data[i] = image\n",
    "\n",
    "\tmax_btimap = np.amax(make_data.Bitmap_data)\n",
    "\tmake_data.Bitmap_data_scale = make_data.Bitmap_data / max_btimap\n",
    "\t\n",
    "def save_set_file(in_usr_param,Set_data,Sur_data,index_i,index_j):\n",
    "\t\n",
    "\tsave = np.empty(shape=(9,2), dtype=np.object)\n",
    "\tres_name = Sur_data.Response_name[index_i]\n",
    "\n",
    "\tfor i in range(Set_data.num_study):\t\n",
    "\t\tres_name = res_name.replace(Set_data.study_name[i]+\"_\",\"\")\n",
    "\n",
    "\tsave[0][0] = \"model\" \n",
    "\tsave[1][0] = \"btimapsize\"\n",
    "\tsave[2][0] = \"res_name\" \n",
    "\tsave[3][0] = \"AnalysisGroup\"\n",
    "\tsave[4][0] = \"Response_multi_num\"\n",
    "\tsave[5][0] = \"Response_multi_index\"\n",
    "\tsave[6][0] = \"Path\"\n",
    "\tsave[7][0] = \"equation_num_base\"\n",
    "\tsave[8][0] = \"equation_num_study\"\n",
    "\n",
    "\tsave[0][1] = str(in_usr_param.btimap_mode)\n",
    "\tsave[1][1] = str(in_usr_param.bitmap_size)\n",
    "\tsave[2][1] = str(res_name)\n",
    "\tsave[3][1] = str(Set_data.AnalysisGroup)\n",
    "\tsave[4][1] = str(Sur_data.Response_multi_num[index_i])\n",
    "\tsave[5][1] = str(index_j)\n",
    "\n",
    "\tif Set_data.AnalysisGroup == 0:\n",
    "\t\tsave[6][1] = \"\"\n",
    "\telse:\n",
    "\t\tsave[6][1] = os.path.basename(os.path.dirname(Sur_data.OutJCF_name[0][index_i]))\n",
    "\t\n",
    "\tsave[7][1] =  str(Set_data.equation_num_base) \n",
    "\tsave[8][1] =  str(Sur_data.equation_num_study[index_i]) \n",
    "\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tfile_name = Sur_data.model_path[index_i] + \"/CNN_param.csv\"\n",
    "\telse:\n",
    "\t\tfile_name = Sur_data.model_path[index_i] + str(index_j + 1) + \"/CNN_param.csv\"\n",
    "\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def Load_result(Sur_data,in_usr_param):\n",
    "\tpath = in_usr_param.model_path.decode()\n",
    "\tSur_data.output_data = np.loadtxt(path + \"/result.csv\", encoding=\"utf-8\",delimiter=\",\",dtype=np.object)\n",
    "\t\n",
    "\tpath = in_usr_param.model_path.decode() \n",
    "\tRMS_R2 = np.loadtxt(path + \"/R2RMS.csv\", encoding=\"utf-8\",delimiter=\",\",usecols=1,dtype=np.object)\n",
    "\t\n",
    "\treturn RMS_R2[0],RMS_R2[1]\n",
    "\n",
    "def check_path():\n",
    "\tglobal \tins_path\n",
    "\n",
    "\tif os.name == 'nt':\t\n",
    "\t\tpath_tmp = os.getenv(\"path\")\n",
    "\t\tpath_tmp = path_tmp.split(';')\n",
    "\n",
    "\t\tfor i in range(len(path_tmp)):\n",
    "\t\t\tif os.path.isfile(path_tmp[i] + \"/scripts/Make_Surrogate_Model_for_CNN.py\"):\n",
    "\t\t\t\tins_path = path_tmp[i]\n",
    "\t\t\t\treturn 0\n",
    "\t\tif os.path.isfile(r\"C:/Program Files/JMAG-Designer21.0/scripts/Make_Surrogate_Model_for_CNN.py\"):\n",
    "\t\t\tins_path = \"C:/Program Files/JMAG-Designer21.0\"\n",
    "\t\t\treturn 0\n",
    "\t\tif os.getenv('InsDir') != None:\n",
    "\t\t\tins_path = os.getenv('InsDir')\n",
    "\t\t\treturn 0\n",
    "\n",
    "\t\tmessage_en = \"The installation directory cannot be found. Set the environment variable path or insdir to the installation directory.\"\n",
    "\t\tmessage_jp = \"ï¿½Cï¿½ï¿½ï¿½Xï¿½gï¿½[ï¿½fï¿½Bï¿½ï¿½ï¿½Nï¿½gï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Bï¿½Â‹ï¿½ï¿½Ïï¿½pathï¿½Í‚Ü‚ï¿½ï¿½ï¿½insdirï¿½ÉƒCï¿½ï¿½ï¿½Xï¿½gï¿½[ï¿½ï¿½ï¿½fï¿½Bï¿½ï¿½ï¿½Nï¿½gï¿½ï¿½ï¿½ï¿½ï¿½İ’è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\tins_path = os.getenv('InsDir')\n",
    "\t\treturn 0\n",
    "\n",
    "def Make_dir(in_usr_param,Sur_data):\n",
    "\tfor i in range(Sur_data.Response_num):\n",
    "\t\tSur_data.model_path.append(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i])\n",
    "\t\tif Sur_data.Response_multi_num[i]== 1:\n",
    "\t\t\tif not os.path.exists(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i]):\n",
    "\t\t\t\tos.mkdir(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i])\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(Sur_data.Response_multi_num[i]):\n",
    "\t\t\t\tif not os.path.exists(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i] + str(j + 1)):\n",
    "\t\t\t\t\tos.mkdir(in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[i] + str(j + 1))\n",
    "\n",
    "def STD_scale(in_usr_param,Sur_data,index_i,index_j):\n",
    "\t\n",
    "\tcorrect_data = np.zeros((Sur_data.Read_file_num, 1))\n",
    "\t\n",
    "\tsc_y = StandardScaler()\n",
    "\tfor i in range(Sur_data.Read_file_num):\n",
    "\t\tcorrect_data[i,0] = Sur_data.Response_value[i][index_i][index_j]\n",
    "\n",
    "\tin_y = sc_y.fit_transform(correct_data)\n",
    "\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tpickle.dump(sc_y, open(Sur_data.model_path[index_i] + \"/\" + Sur_data.Response_name[index_i] + \"_y.pkl\", 'wb'))\n",
    "\telse:\n",
    "\t\tpickle.dump(sc_y, open(Sur_data.model_path[index_i] + str(index_j + 1) + \"/\" + Sur_data.Response_name[index_i] + str(index_j + 1) + \"_y.pkl\", 'wb'))\n",
    "\n",
    "\tfile_name = in_usr_param.model_path.decode() + \"/response.csv\"\n",
    "\tnp.savetxt(file_name,np.array(in_y),fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "\treturn in_y,sc_y\n",
    "\n",
    "def Create_bitmapcsv(in_usr_param,Sur_data,Set_data):\n",
    "\t\n",
    "\tproc_list = []\n",
    "\tnumproc = in_usr_param.num_thread\n",
    "\tif len(Sur_data.bitmap_run_cmd) < numproc:\n",
    "\t\tnumproc = len(Sur_data.bitmap_run_cmd)\n",
    "\t\n",
    "\tn_data = len(Sur_data.bitmap_run_cmd)\n",
    "\tSur_data.Bitmap_data = np.zeros((Sur_data.Read_file_num,in_usr_param.bitmap_size,in_usr_param.bitmap_size))\n",
    "\t\n",
    "\tif os.name == 'nt':\t\n",
    "\t\tstartupinfo = subprocess.STARTUPINFO()\n",
    "\t\tstartupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n",
    "\t\tstartupinfo.wShowWindow = subprocess.SW_HIDE\n",
    "\telse:\n",
    "\t\tstartupinfo = None\n",
    "\n",
    "\tfor i in range(n_data):\n",
    "\t\tproc = subprocess.Popen(Sur_data.bitmap_run_cmd[i],stdout=subprocess.DEVNULL,startupinfo=startupinfo)\n",
    "\t\tproc_list.append(proc)\n",
    "\t\tif len(proc_list) % numproc == 0 or (i + 1) == n_data:\n",
    "\t\t\tfor subproc in proc_list:\n",
    "\t\t\t\tsubproc.wait()\n",
    "\t\tproc_list = []\t\n",
    "\n",
    "\tcsv_path = []\n",
    "\t\n",
    "\tfor i in range(Sur_data.Read_file_num):\n",
    "\t\tif Set_data.AnalysisGroup == 0:\n",
    "\t\t\tcsv_path.append(Sur_data.Bitmap_path[i])\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tif \"/0000/\"  in Sur_data.Bitmap_path[i]:\n",
    "\t\t\t\tcsv_path.append(Sur_data.Bitmap_path[i])\n",
    "\n",
    "\tfile_name = in_usr_param.model_path.decode() + \"/csvfilepath.csv\"\n",
    "\tnp.savetxt(file_name,np.array(csv_path),fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "\n",
    "def save_zip(Sur_data,index_i,index_j):\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tshutil.make_archive(Sur_data.model_path[index_i], format='zip', root_dir = Sur_data.model_path[index_i])\n",
    "\t\tshutil.rmtree(Sur_data.model_path[index_i])\n",
    "\telse:\n",
    "\t\tshutil.make_archive(Sur_data.model_path[index_i] + str(index_j + 1), format='zip', root_dir = Sur_data.model_path[index_i] + str(index_j + 1))\n",
    "\t\tshutil.rmtree(Sur_data.model_path[index_i] + str(index_j + 1))\n",
    "\t\n",
    "def CNN_function(make_data):\n",
    "\n",
    "\toptimizers = tf.keras.optimizers.Adam(lr=0.0005)\n",
    "\treduce_lr = ReduceLROnPlateau(monitor='loss',factor=0.5,patience=2,min_lr=0.0001)\n",
    "\n",
    "\tif make_data.compute_mode == 0:\n",
    "\t\tos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\t\t\n",
    "\t\tset_thread = tf.config.threading.get_inter_op_parallelism_threads()\n",
    "\t\tif set_thread == 0:\n",
    "\t\t\tcontext._context = None\n",
    "\t\t\tcontext._create_context()\n",
    "\t\t\n",
    "\t\t\ttf.config.threading.set_inter_op_parallelism_threads(make_data.num_thread)\n",
    "\t\t\ttf.config.threading.set_intra_op_parallelism_threads(make_data.num_thread)\n",
    "\t\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\n",
    "\tmodel.add(tf.keras.layers.InputLayer(input_shape=(make_data.bitmap_size,make_data.bitmap_size, 1)))\n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))  \n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\",activation=\"relu\")) \n",
    "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\",activation=\"relu\")) \n",
    "\tmodel.add(tf.keras.layers.Conv2D(filters=10, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))  \n",
    "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(tf.keras.layers.Flatten())\n",
    "\tmodel.add(tf.keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "\tmodel.add(tf.keras.layers.Dense(units=512, activation=\"relu\")) \n",
    "\tmodel.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "\tmodel.compile(optimizer = optimizers, loss = \"mean_squared_error\")\n",
    "\n",
    "\treturn model,optimizers,reduce_lr\n",
    "\n",
    "def Check_Run_Mode(in_usr_param):\n",
    "\t\n",
    "\twarning_GPU = 0\n",
    "\twarning_CPU = 0\n",
    "\n",
    "\tif in_usr_param.compute_mode == 0:\n",
    "\t\tos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\t\t\n",
    "\t\tset_thread = tf.config.threading.get_inter_op_parallelism_threads()\n",
    "\t\tif (set_thread != in_usr_param.num_thread) and (set_thread != 0):\n",
    "\t\t\twarning_CPU = set_thread\n",
    "\telse:\n",
    "\t\tgpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "\t\tif len(gpus) < 1:\n",
    "\t\t\twarning_GPU\t = 1\n",
    "\n",
    "\treturn warning_GPU,warning_CPU\n",
    "\n",
    "def CNN_model(optimizers,reduce_lr,model,make_data):\n",
    "\tError = 0\n",
    "\t\n",
    "\tfor ix, layer in enumerate(model.layers):\n",
    "\t\t\tif hasattr(model.layers[ix], 'kernel_initializer') and \\\n",
    "\t\t\t\thasattr(model.layers[ix], 'bias_initializer'):\n",
    "\t\t\t\tweight_initializer = model.layers[ix].kernel_initializer\n",
    "\t\t\t\tbias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "\t\t\t\told_weights, old_biases = model.layers[ix].get_weights()\n",
    "\n",
    "\t\t\t\tmodel.layers[ix].set_weights([\n",
    "\t\t\t\t\tweight_initializer(shape=old_weights.shape),\n",
    "\t\t\t\t\tbias_initializer(shape=len(old_biases))])\n",
    "\n",
    "\tmodel.fit(make_data.Bitmap_data_scale,make_data.Res_val, epochs = num_epoch, batch_size = num_batch, verbose=0,callbacks=[reduce_lr])\n",
    "\n",
    "\ttry:\n",
    "\t\tsave_path = make_data.Modelsavepath\n",
    "\t\tmodel_name = make_data.Responsename\n",
    "\t\tmodel.save(save_path+ \"/tmp/\")\n",
    "\t\tos.rename(save_path + \"/tmp/\" , save_path + \"/\" + model_name + \".surm\")\n",
    "\texcept:\n",
    "\t\tError = 1\n",
    "\n",
    "\ttf.keras.backend.clear_session()\n",
    "\tgc.collect()\n",
    "\n",
    "\treturn Error\n",
    "\n",
    "\t\n",
    "def CNN_KFold(optimizers,reduce_lr,model,make_data):\n",
    "\trandom_seed = random.randint(0,2**32-1)\n",
    "\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tError = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\n",
    "\tmake_data.output_data = np.empty(shape=(make_data.Bitmap_path_num,4), dtype=np.object)\n",
    "\n",
    "\tkf = KFold(n_splits = make_data.cross_val, shuffle=True,random_state = random_seed)\n",
    "\t\n",
    "\tfor train_index, test_index in kf.split(make_data.Bitmap_data_scale):\t\n",
    "\t\t\n",
    "\t\tfor ix, layer in enumerate(model.layers):\n",
    "\t\t\tif hasattr(model.layers[ix], 'kernel_initializer') and \\\n",
    "\t\t\t\thasattr(model.layers[ix], 'bias_initializer'):\n",
    "\t\t\t\tweight_initializer = model.layers[ix].kernel_initializer\n",
    "\t\t\t\tbias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "\t\t\t\told_weights, old_biases = model.layers[ix].get_weights()\n",
    "\n",
    "\t\t\t\tmodel.layers[ix].set_weights([\n",
    "\t\t\t\t\tweight_initializer(shape=old_weights.shape),\n",
    "\t\t\t\t\tbias_initializer(shape=len(old_biases))])\n",
    "\t\t\n",
    "\t\tmodel.fit(make_data.Bitmap_data_scale[train_index,:],make_data.Res_val[train_index], epochs = num_epoch, batch_size = num_batch, verbose=0,callbacks=[reduce_lr])\n",
    "\t\t\n",
    "\t\tresult_predict_tmp = make_data.sc_y.inverse_transform(model.predict(make_data.Bitmap_data_scale[test_index, :]))\n",
    "\t\tresult_correct_tmp = make_data.sc_y.inverse_transform(make_data.Res_val[test_index])\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,make_data)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\n",
    "\t\ttf.keras.backend.clear_session()\n",
    "\t\tgc.collect()\n",
    "\n",
    "\treturn RMS/make_data.cross_val,R2/make_data.cross_val,Error\n",
    "\n",
    "def save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,make_data):\n",
    "\t\n",
    "\tfor i in range(len(test_index)):\n",
    "\t\tmake_data.output_data[Start_index][0] = str(index_count)\n",
    "\t\tmake_data.output_data[Start_index][1] = float(result_correct_tmp[i])\n",
    "\t\tmake_data.output_data[Start_index][2] = float(result_predict_tmp[i])\n",
    "\t\tfilename = \"Designer_bitmap_\" + str(make_data.bitmap_size) + \".csv\"\n",
    "\t\tmake_data.output_data[Start_index][3] = make_data.OutJCF_name[test_index[i]].replace(filename,\"Designer.jcf\")\n",
    "\n",
    "\t\tStart_index = Start_index + 1\n",
    "\treturn Start_index\n",
    "\n",
    "def save_result_csv(make_data,RMS,R2,Error):\n",
    "\t\n",
    "\tsave_path = make_data.model_path + \"/result.csv\"\n",
    "\tnp.savetxt(save_path,np.array(make_data.output_data),encoding=\"utf-8\",fmt=\"%s\",delimiter=',')\n",
    "\n",
    "\tsave = np.empty(shape=(2,2), dtype=np.object)\n",
    "\n",
    "\tsave[0][0] = \"RMS\" \n",
    "\tsave[1][0] = \"R2\"\n",
    "\t\n",
    "\tsave[0][1] = str(RMS)\n",
    "\tsave[1][1] = str(R2)\n",
    "\n",
    "\tsave_path = make_data.model_path + \"/R2RMS.csv\"\n",
    "\tnp.savetxt(save_path,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def save_csv(in_usr_param,Sur_data,elapsed_time,RMS,R2,index_i,index_j):\n",
    "\t\n",
    "\tif in_usr_param.cross_frag == 1:\n",
    "\t\tsave = np.empty(shape=(Sur_data.Read_file_num+7,6), dtype=np.object)\n",
    "\t\tfor i in range(Sur_data.Read_file_num+7):\n",
    "\t\t\tfor j in range(6):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\n",
    "\t\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i]\n",
    "\t\telse:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i] + str(index_j + 1)\n",
    "\t\t\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tsave[1][1] = \"CNN\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\tsave[3][0] = \"RMS\"\n",
    "\t\tsave[3][1] = str(RMS)\n",
    "\t\tsave[4][0] = \"R2\"\n",
    "\t\tsave[4][1] = str(R2)\n",
    "\t\tsave[6][0] = \"case\"\n",
    "\t\tsave[6][1] = \"K-fold\" \n",
    "\t\tsave[6][2] = \"correct\"\n",
    "\t\tsave[6][3] = \"predict\"\n",
    "\n",
    "\t\tfor i in range(Sur_data.Read_file_num):\n",
    "\t\t\tsave[i+7][0] = str(i)\n",
    "\t\t\tsave[i+7][1] = str(Sur_data.output_data[i][0])\n",
    "\t\t\tsave[i+7][2] = float(Sur_data.output_data[i][1])\n",
    "\t\t\tsave[i+7][3] = float(Sur_data.output_data[i][2])\n",
    "\t\t\tsave[i+7][5] = str(Sur_data.output_data[i][3])\n",
    "\t\t\t\n",
    "\telse:\n",
    "\t\tsave = np.empty(shape=(3,2), dtype=np.object)\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tfor j in range(2):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i]\n",
    "\t\telse:\n",
    "\t\t\tsave[0][0] = Sur_data.Response_name[index_i] + str(index_j + 1)\n",
    "\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tsave[1][1] = \"CNN\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\n",
    "\tif Sur_data.Response_multi_num[index_i]== 1:\n",
    "\t\tfile_name = in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[index_i] + \".csv\"\n",
    "\telse:\n",
    "\t\tfile_name = in_usr_param.model_path.decode() + \"/\" + Sur_data.Response_name[index_i] + str(index_j + 1) + \".csv\"\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",encoding=\"utf-8\",delimiter=',')\n",
    "\n",
    "def get_data_from_input_dialog():\n",
    "\tdialog = create_input_dialog()\n",
    "\tdialog.Show()\n",
    "\tif dialog.WasCancelled() == False:\n",
    "\t\tdata = get_values_from_input_dialog(dialog)\n",
    "\t\treturn data\n",
    "\treturn DialogData()\n",
    "\n",
    "def get_values_from_input_dialog(dialog):\n",
    "\tdata = DialogData()\n",
    "\tdata.model_path = dialog.GetValue(\"surrogate_model_path\")\n",
    "\tdata.cross_val = dialog.GetValue(\"cross_val\")\n",
    "\tdata.btimap_mode = dialog.GetValue(\"model\")\n",
    "\tdata.bitmap_size = dialog.GetValue(\"bitmap_size\")\n",
    "\tdata.cross_frag = dialog.GetValue(\"cross_frag\")\n",
    "\tdata.num_thread = dialog.GetValue(\"num_thread\")\n",
    "\tdata.compute_mode = dialog.GetValue(\"compute_mode\")\n",
    "\tdata.input_dir = dialog.GetValue(\"input_dir\")\t\n",
    "\t\n",
    "\tif (data.bitmap_size < 50) or (data.bitmap_size > 1000) or (data.bitmap_size == \"\"):\n",
    "\t\tmessage_en = \"The size of the bitmap must range from 50 to 1000.\"\n",
    "\t\tmessage_jp = \"bitmapï¿½ÌƒTï¿½Cï¿½Yï¿½ï¿½50ï¿½`1000ï¿½Ì”ÍˆÍ‚Åwï¿½è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.input_dir == \"\":\n",
    "\t\tmessage_en = \"Specify input file name.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½Íƒtï¿½@ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½wï¿½è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isdir(data.input_dir) == 0:\n",
    "\t\tmessage_en = \"Specify input file name.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½Íƒtï¿½Hï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.model_path == b\"\":\n",
    "\t\tmessage_en = \"Specify output directory name.\"\n",
    "\t\tmessage_jp = \"ï¿½oï¿½Íƒtï¿½Hï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½ï¿½ï¿½wï¿½è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isdir(data.model_path) == 0:\n",
    "\t\tmessage_en = \"The output folder is incorrect.\"\n",
    "\t\tmessage_jp = \"ï¿½oï¿½Íƒtï¿½Hï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tif data.cross_val <= 1:\n",
    "\t\tmessage_en = \"Set the number of divisions to 2 or more.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½2ï¿½Èï¿½ï¿½Åİ’è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.num_thread == \"\" or data.num_thread < 1:\n",
    "\t\tmessage_en = \"Please enter an integer greater than or equal to 1.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½ñ”‚Í‚Pï¿½Èï¿½ï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Í‚ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tdata.isValid = True\n",
    "\treturn data\n",
    "\n",
    "def create_input_dialog():\n",
    "\tapp = designer.GetApplication()\n",
    "\tdialog = app.CreateDialogBox()\n",
    "\n",
    "\ttitle_jp = \"CNNï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ì¬(ï¿½ï¿½ï¿½ï¿½)\"\n",
    "\ttitle_en = \"Create a surrogate model for CNN (beta version)\"\n",
    "\toutputlbl_jp = \"ï¿½oï¿½ï¿½:\"\n",
    "\toutputlbl_en = \"Output:\"\n",
    "\tinputlbl_jp = \"ï¿½ï¿½ï¿½ï¿½:\"\n",
    "\tinputlbl_en = \"Input:\"\n",
    "\tsurrogate_path_jp = \"ï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½oï¿½Íƒpï¿½X\"\n",
    "\tsurrogate_path_en = \"Surrogate model output path\" \n",
    "\tcross_val_jp = \"K-ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\"\n",
    "\tcross_val_en = \"K-Fold Cross validation\"\t\n",
    "\tfold_val_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\"\n",
    "\tfold_val_en = \"K-fold\"\n",
    "\tresponse_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½l\"\n",
    "\tresponse_en = \"Response value\"\t\n",
    "\tcross_use_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\"\n",
    "\tcross_use_en = \"Cross validation\"\n",
    "\tcross_notuse_jp = \"ï¿½ï¿½ï¿½Ø‚È‚ï¿½\" \n",
    "\tcross_notuse_en = \"No verification\"\n",
    "\tinput_dir_jp = \"ï¿½wï¿½Kï¿½fï¿½[ï¿½^ï¿½Zï¿½bï¿½gï¿½pï¿½X\"\n",
    "\tinput_dir_en = \"Training datasetï¿½@path\" \n",
    "\tOutput_area_jp = \"ï¿½oï¿½Í—Ìˆï¿½\"\n",
    "\tOutput_area_en = \"Output area\"\n",
    "\tOutput_area_All_jp = \"ï¿½ï¿½ï¿½×‚ï¿½\"\n",
    "\tOutput_area_ALL_en = \"ALL\"\n",
    "\tOutput_area_Topt_jp = \"ï¿½gï¿½|ï¿½ï¿½ï¿½Wï¿½[ï¿½Å“Kï¿½ï¿½ï¿½Ìˆï¿½\" \n",
    "\tOutput_area_Topt_en = \"Topology optimization area\"\n",
    "\tBitmap_num_ja = \"ï¿½rï¿½bï¿½gï¿½ï¿½\"\n",
    "\tBitmap_num_en = \"Number of bits\"\n",
    "\tParalell_num_ja = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\" \n",
    "\tParalell_num_en = \"Number of parallels\"\n",
    "\tSurrogate_para_ja = \"ï¿½ï¿½ï¿½ï¿½ï¿½vï¿½Z(ï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ì¬ï¿½j\"\n",
    "\tSurrogate_para_en = \"Parallel computing (surrogate model creation)\"\n",
    "\tBitmap_para_ja = \"ï¿½ï¿½ï¿½ñ”iï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ì¬ï¿½yï¿½ï¿½bitmapï¿½tï¿½@ï¿½Cï¿½ï¿½ï¿½ì¬ï¿½j\"\n",
    "\tBitmap_para_en = \"Parallel number (surrogate model creation and bitmap file creation)\"\n",
    "\tCompute_Capability_ja = \"ï¿½ï¿½ï¿½j Compute Capability 8.6 ï¿½ï¿½GPUï¿½É‚Í‘Î‰ï¿½ï¿½ï¿½ï¿½Ä‚ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\tCompute_Capability_en = \"noteï¿½j Compute Capability 8.6 GPU is not supported.\"\n",
    "\t\n",
    "\tdialog.SetTranslation(title_en, title_jp)\n",
    "\n",
    "\tdialog.SetTranslation(response_en, response_jp)\n",
    "\tdialog.SetTranslation(fold_val_en, fold_val_jp)\n",
    "\tdialog.SetTranslation(cross_val_en, cross_val_jp)\n",
    "\tdialog.SetTranslation(outputlbl_en, outputlbl_jp)\n",
    "\tdialog.SetTranslation(surrogate_path_en, surrogate_path_jp)\n",
    "\tdialog.SetTranslation(cross_use_en, cross_use_jp)\n",
    "\tdialog.SetTranslation(cross_notuse_en, cross_notuse_jp)\n",
    "\tdialog.SetTranslation(inputlbl_en,inputlbl_jp)\n",
    "\tdialog.SetTranslation(input_dir_en,input_dir_jp)\n",
    "\tdialog.SetTranslation(Output_area_en,Output_area_jp)\n",
    "\tdialog.SetTranslation(Output_area_ALL_en,Output_area_All_jp)\n",
    "\tdialog.SetTranslation(Output_area_Topt_jp,Output_area_Topt_jp)\n",
    "\tdialog.SetTranslation(Bitmap_num_en,Bitmap_num_ja)\n",
    "\tdialog.SetTranslation(Paralell_num_en,Paralell_num_ja)\n",
    "\tdialog.SetTranslation(Surrogate_para_en,Surrogate_para_ja)\t\n",
    "\tdialog.SetTranslation(Bitmap_para_en,Bitmap_para_ja)\n",
    "\tdialog.SetTranslation(Output_area_Topt_en,Output_area_Topt_jp)\n",
    "\tdialog.SetTranslation(Compute_Capability_en,Compute_Capability_ja)\n",
    "\t\n",
    "\tdialog.SetTitle(title_en)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(cross_val_en)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_use_en,1)\n",
    "\tdialog.AddInteger(\"cross_val\", fold_val_en, 5)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_notuse_en, 2)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(Output_area_en)\n",
    "\tdialog.AddRadio(\"model\", Output_area_ALL_en, 1)\n",
    "\tdialog.AddRadio(\"model\", Output_area_Topt_en, 2)\n",
    "\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(Surrogate_para_en)\n",
    "\tdialog.AddRadio(\"compute_mode\", \"CPU\", 0)\n",
    "\tdialog.AddRadio(\"compute_mode\", \"GPU\", 1)\n",
    "\tdialog.AddLabel(Compute_Capability_en)\n",
    "\n",
    "\tdialog.AddLine()\n",
    "\tdialog.AddLabel(Bitmap_para_en)\n",
    "\tdialog.AddInteger(\"num_thread\", Paralell_num_en, 8)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddInteger(\"bitmap_size\",Bitmap_num_en, 200)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(inputlbl_en)\n",
    "\tdialog.AddDirectoryPath(\"input_dir\", input_dir_en,\"\")\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddLabel(outputlbl_en)\n",
    "\tdialog.AddDirectoryPath(\"surrogate_model_path\", surrogate_path_en,\"./\")\n",
    "\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\treturn dialog\n",
    "\n",
    "def show_normal_exit_message():\n",
    "\ttitle_en = \"Finished\"\n",
    "\ttitle_jp = \"ï¿½Iï¿½ï¿½\"\n",
    "\tmessage_en = \"Finished.\"\n",
    "\tmessage_jp = \"ï¿½Iï¿½ï¿½\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_error_exit_message(message_en, message_jp):\n",
    "\ttitle_en = \"Error\"\n",
    "\ttitle_jp = \"ï¿½Gï¿½ï¿½ï¿½[\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_message(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\n",
    "def show_warning_message(message_en, message_jp):\n",
    "\ttitle_en = \"warning\"\n",
    "\ttitle_jp = \"ï¿½xï¿½ï¿½\"\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\t\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\t\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\treturn msgdlg.WasCancelled()\n",
    "\n",
    "if py_error == 0:\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class DialogData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import math\n",
    "#import designer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "\n",
    "py_error = 0\n",
    "\n",
    "# NN param\n",
    "num_neuron = 20\n",
    "num_layer = 3\n",
    "num_epoch = 100\n",
    "num_batch = 10\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def show_message_immediately(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\n",
    "if (sys.version >= \"3.8\"):\n",
    "\ttry:\n",
    "\t\timport tensorflow as tf\n",
    "\t\tfrom sklearn.preprocessing import StandardScaler\n",
    "\t\tfrom sklearn.svm import SVR\n",
    "\t\tfrom sklearn.tree import DecisionTreeRegressor\n",
    "\t\tfrom sklearn.model_selection import KFold\n",
    "\t\tfrom sklearn.metrics import r2_score\n",
    "\t\tfrom sklearn.metrics import mean_squared_error\n",
    "\texcept:\n",
    "\t\ttitle_en = \"Python library error\"\n",
    "\t\ttitle_jp = \"Pythonï¿½ï¿½ï¿½Cï¿½uï¿½ï¿½ï¿½ï¿½ï¿½Gï¿½ï¿½ï¿½[\"\n",
    "\t\tmessage_en = \"The runtime library cannot be found. Please refer to the manual for the required packages.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½^ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½Cï¿½uï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Bï¿½Kï¿½vï¿½Èƒpï¿½bï¿½Pï¿½[ï¿½Wï¿½Íƒ}ï¿½jï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½ï¿½ï¿½Qï¿½Æ‚ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\t\tpy_error = 1\n",
    "\n",
    "if (sys.version < \"3.8\"):\n",
    "\ttitle_en = \"Python Version Error\"\n",
    "\ttitle_jp = \"Pythonï¿½oï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½ï¿½Gï¿½ï¿½ï¿½[\"\n",
    "\tmessage_en = \"Please use Python of newer version over 3.8\"\n",
    "\tmessage_jp = \"ï¿½oï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½3.8ï¿½Èï¿½ï¿½ï¿½Pythonï¿½ï¿½ï¿½gï¿½pï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\tshow_message_immediately(title_en, title_jp, message_en, message_jp)\n",
    "\tpy_error = 1\n",
    "\n",
    "class DialogData:\n",
    "\tdef __init__(self):\n",
    "\t\tself.model_path = \"\"\n",
    "\t\tself.csv_path   = \"\"\n",
    "\t\tself.model = 1\n",
    "\t\tself.cross_val = 5\n",
    "\t\tself.cross_frag = 1\n",
    "\t\tself.response_name = []\n",
    "\t\tself.isValid  = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "\tobj_list = []\n",
    "\tparam_list = []\n",
    "\tmodel_save_path = []\n",
    "\trandom_seed = 0\n",
    "\tnum_case = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\trandom_seed = random.randint(0,2**32-1)\n",
    "\t\n",
    "\tAnalysisGroup  = app.GetCurrentAnalysisGroup()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tAnalysisGroup = app.GetCurrentStudy()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tmessage_en = \"The study or analysis group cannot be found.\"\n",
    "\t\tmessage_jp = \"studyï¿½Ü‚ï¿½ï¿½Í‰ï¿½ï¿½ÍƒOï¿½ï¿½ï¿½[ï¿½vï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn\n",
    "\n",
    "\tdata = get_data_from_input_dialog()\n",
    "\tif data.isValid == False:\n",
    "\t\treturn\n",
    "\n",
    "\tOptTable = AnalysisGroup.GetOptimizationTable()\n",
    "\tnum_param = OptTable.NumParameters()\t\n",
    "\tnum_obj = len(data.response_name)\n",
    "\tkfold_split = data.cross_val\n",
    " \n",
    "\tfor i in range(num_obj):\n",
    "\t\ttmp = data.response_name[i]\n",
    "\t\tobj_list.append(tmp.decode())\n",
    "\t\tmodel_save_path.append(data.model_path + b\"/\" + data.response_name[i] + b\"/\" + data.response_name[i])\n",
    "\t\tif not os.path.exists(data.model_path + b\"/\" + data.response_name[i]):\n",
    "\t\t\tos.mkdir(data.model_path + b\"/\" + data.response_name[i])\n",
    "\t\t\n",
    "\tfor i in range(num_param):\n",
    "\t\tparam = OptTable.GetParametricItem(i)\n",
    "\t\tif param.GetItemName() != \"\":\n",
    "\t\t\tparam_list.append(param.GetItemName())\n",
    "\t\telse:\n",
    "\t\t\tparam_list.append(param.GetParameterName())\n",
    "\n",
    "\tinput_param,result_correct,Error,learn_data =loadcsv(data.csv_path,param_list,obj_list)\n",
    "\tif Error == 1:\n",
    "\t\treturn\n",
    "\n",
    "\tnum_case = len(input_param)\n",
    "\n",
    "\tcorrect_data = np.zeros([num_case])\n",
    "\tresult_out_csv = np.zeros([num_case,num_param + 3])\n",
    "\n",
    "\tif data.model ==1:\n",
    "\t\ttf.get_logger().setLevel(\"ERROR\")\n",
    "\t\tann_tmp = NN_function()\n",
    "\n",
    "\tfor i in range(num_obj):\n",
    "\t\tsc_X = StandardScaler()\n",
    "\t\tsc_y = StandardScaler()\n",
    "\t\tfor j in range(num_case):\n",
    "\t\t\tcorrect_data[j] = result_correct[j][i]\t\n",
    "\t\tcorrect_data = correct_data.reshape(num_case, 1)\n",
    "\n",
    "\t\ttmp_X = sc_X.fit_transform(input_param)\n",
    "\t\ttmp_y = sc_y.fit_transform(correct_data)\n",
    "\t\tpickle.dump(sc_X, open(model_save_path[i] + b\"_x.pkl\", 'wb'))\n",
    "\t\tpickle.dump(sc_y, open(model_save_path[i] + b\"_y.pkl\", 'wb'))\n",
    "\t\t\n",
    "\t\tstart = time.time()\n",
    "\t\tif data.cross_frag == 1:\n",
    "\t\t\tif data.model ==1:\n",
    "\t\t\t\tNN_model(tmp_X,tmp_y,sc_y,model_save_path,i,ann_tmp)\n",
    "\t\t\t\tRMS,R2,Error = NN_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split,ann_tmp)\n",
    "\t\t\telif data.model ==2:\n",
    "\t\t\t\tSVR_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\t\tRMS,R2,Error = SVR_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split)\n",
    "\t\t\telif data.model ==3:\n",
    "\t\t\t\tRT_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\t\tRMS,R2,Error = RT_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split)\n",
    "\t\telse:\n",
    "\t\t\tif data.model ==1:\n",
    "\t\t\t\tNN_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\telif data.model ==2:\n",
    "\t\t\t\tSVR_model(tmp_X,tmp_y,sc_y,model_save_path,i)\n",
    "\t\t\telif data.model ==3:\n",
    "\t\t\t\tRT_model(tmp_X,tmp_y,sc_y,model_save_path,i)\t \n",
    "\t\t\n",
    "\t\tend = time.time()\n",
    "\t\telapsed_time = end - start\n",
    "\t\t\n",
    "\t\tsave_csv(model_save_path,result_out_csv,i,num_case,num_param,param_list,elapsed_time,obj_list,RMS,R2,data)\n",
    "\t\tsave_zip(model_save_path,data,i,learn_data)\n",
    "\n",
    "\t\tif Error:\n",
    "\t\t\tmessage_en = \"The response value \" + data.response_name[i].decode() + \" may contain an outlier. Delete the case that contains an outlier.\"\n",
    "\t\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½l\" + data.response_name[i].decode() + \"ï¿½ÉˆÙï¿½ï¿½lï¿½ï¿½ï¿½Ü‚Ü‚ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½Â”\\ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½Bï¿½Ùï¿½ï¿½lï¿½ï¿½ï¿½Ü‚Ü‚ï¿½ï¿½ï¿½ï¿½Pï¿½[ï¿½Xï¿½ï¿½ï¿½íœï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\n",
    "\tshow_normal_exit_message()\n",
    "\n",
    "def save_zip(model_save_path,data,index,learn_data):\n",
    "\tsave_path = data.model_path + b\"/\" + data.response_name[index] + b\"/learn_data.csv\"\n",
    "\tsave_path = save_path.decode()\n",
    "\n",
    "\twith open(save_path, \"a\",encoding=\"cp932\") as f:\n",
    "\t\tfor i in range(len(learn_data)):\n",
    "\t\t\tfor j in range(len(learn_data[0])):\n",
    "\t\t\t\tf.write(\"\\\"\"+learn_data[i][j] + \"\\\"\" + \",\")\n",
    "\t\t\tf.write(\"\\n\")\n",
    "\n",
    "\tdirname = data.model_path + b\"/\" + data.response_name[index]\n",
    "\tdirname = dirname.decode()\n",
    "\tshutil.make_archive(dirname, format='zip', root_dir = data.model_path + b\"/\" + data.response_name[index])\n",
    "\tshutil.rmtree(dirname)\n",
    "\n",
    "def NN_function():\n",
    "\tann = tf.keras.models.Sequential()\n",
    "\tfor i in range(num_layer):\n",
    "\t\tann.add(tf.keras.layers.Dense(units=num_neuron, activation='relu'))\n",
    "\tann.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "\treturn ann \n",
    "\n",
    "def NN_model(tmp_X,tmp_y,sc_y,model_save_path,index,ann_tmp):\n",
    "\tlocal_y = tmp_y\n",
    "\tlocal_y = np.reshape(local_y,(-1))\n",
    "\tann = tf.keras.models.clone_model(ann_tmp)\n",
    "\tann.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\tann.fit(tmp_X,local_y, epochs = num_epoch, batch_size = num_batch, verbose=0)\n",
    "\tann.save(model_save_path[index] + b\".surm\")\n",
    "\n",
    "def NN_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split,ann_tmp):\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tError = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tkf = KFold(n_splits=kfold_split, shuffle=True,random_state =random_seed)\n",
    "\n",
    "\tfor train_index, test_index in kf.split(tmp_X):\n",
    "\t\tlocal_y = tmp_y[train_index, :]\n",
    "\t\tlocal_y = np.reshape(local_y,(-1))\n",
    "\t\t\n",
    "\t\tann = tf.keras.models.clone_model(ann_tmp)\n",
    "\t\tann.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\t\tann.fit(tmp_X[train_index, :],local_y, epochs = num_epoch, batch_size = num_batch, verbose=0)\n",
    "\t\tresult_predict_tmp = sc_y.inverse_transform(ann.predict(tmp_X[test_index, :]))\n",
    "\t\tresult_correct_tmp = sc_y.inverse_transform(tmp_y[test_index, :])\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\treturn RMS/kfold_split,R2/kfold_split,Error\n",
    "\n",
    "def SVR_model(tmp_X,tmp_y,sc_y,model_save_path,i):\n",
    "\tregressor_svr = SVR(kernel='rbf')\n",
    "\tlocal_y = tmp_y\n",
    "\tlocal_y = np.reshape(local_y,(-1))\n",
    "\tregressor_svr.fit(tmp_X,local_y)\n",
    "\tpickle.dump(regressor_svr, open(model_save_path[i] + b\".surm\", 'wb'))\n",
    "\n",
    "def SVR_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split):\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\tkf = KFold(n_splits=kfold_split, shuffle=True,random_state =random_seed)\n",
    "\n",
    "\tfor train_index, test_index in kf.split(tmp_X):\n",
    "\t\tlocal_y = tmp_y[train_index, :]\n",
    "\t\tlocal_y = np.reshape(local_y,(-1))\n",
    "\t\tregressor_svr = SVR(kernel='rbf')\n",
    "\t\tregressor_svr.fit(tmp_X[train_index, :],local_y)\n",
    "\t\tresult_predict_tmp = sc_y.inverse_transform(regressor_svr.predict(tmp_X[test_index, :]))\n",
    "\t\tresult_correct_tmp = sc_y.inverse_transform(tmp_y[test_index, :])\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\treturn RMS/kfold_split,R2/kfold_split,Error\n",
    "\n",
    "def RT_model(tmp_X,tmp_y,sc_y,model_save_path,i):\n",
    "\tregressor_tree = DecisionTreeRegressor(random_state=0)\n",
    "\tlocal_y = tmp_y\n",
    "\tlocal_y = np.reshape(local_y,(-1))\n",
    "\tregressor_tree.fit(tmp_X,local_y)\n",
    "\tpickle.dump(regressor_tree, open(model_save_path[i] + b\".surm\", 'wb'))\n",
    "\n",
    "def RT_KFold(random_seed,tmp_X,tmp_y,sc_y,result_out_csv,num_param,input_param,kfold_split):\n",
    "\tindex_count = 0\n",
    "\tStart_index = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\n",
    "\tkf = KFold(n_splits=kfold_split, shuffle=True,random_state =random_seed)\n",
    "\tfor train_index, test_index in kf.split(tmp_X):\n",
    "\t\tlocal_y = tmp_y[train_index, :]\n",
    "\t\tlocal_y = np.reshape(local_y,(-1))\n",
    "\t\tregressor_tree = DecisionTreeRegressor(random_state=0)\n",
    "\t\tregressor_tree.fit(tmp_X[train_index, :],local_y)\n",
    "\t\tresult_predict_tmp = sc_y.inverse_transform(regressor_tree.predict(tmp_X[test_index, :]))\n",
    "\t\tresult_correct_tmp = sc_y.inverse_transform(tmp_y[test_index, :])\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tRMS = RMS + np.sqrt(mean_squared_error(result_correct_tmp, result_predict_tmp))\n",
    "\t\t\tR2 = R2 + r2_score(result_correct_tmp, result_predict_tmp) \n",
    "\t\texcept:\n",
    "\t\t\tError = 1\n",
    "\n",
    "\t\tindex_count = index_count + 1\n",
    "\t\tStart_index_tmp = save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param)\n",
    "\t\tStart_index = Start_index_tmp\n",
    "\treturn RMS/kfold_split,R2/kfold_split,Error\n",
    "\n",
    "def save_result(test_index,Start_index,index_count,result_predict_tmp,result_correct_tmp,result_out_csv,num_param,input_param):\n",
    "\tfor i in range(len(test_index)):\n",
    "\t\tresult_out_csv[Start_index][0] = index_count\n",
    "\t\tresult_out_csv[Start_index][1] = result_correct_tmp[i]\n",
    "\t\tresult_out_csv[Start_index][2] = result_predict_tmp[i]\n",
    "\t\tfor j in range(num_param):\n",
    "\t\t\tresult_out_csv[Start_index][3+j] = input_param[test_index[i]][j]\n",
    "\t\tStart_index = Start_index + 1\n",
    "\treturn Start_index\n",
    "\n",
    "def save_csv(model_save_path,result_out_csv,index,num_case,num_param,param_list,elapsed_time,obj_list,RMS,R2,data):\n",
    "\t\n",
    "\n",
    "\tif data.cross_frag == 1:\n",
    "\t\tsave = np.empty(shape=(num_case+7,num_param+5), dtype=np.object)\n",
    "\t\tfor i in range(num_case+7):\n",
    "\t\t\tfor j in range(num_param+5):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\n",
    "\t\tsave[0][0] = obj_list[index]\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tif data.model ==1:\n",
    "\t\t\tsave[1][1] = \"NN\"\n",
    "\t\telif data.model ==2:\n",
    "\t\t\tsave[1][1] = \"SVR\"\n",
    "\t\telif data.model == 3:\n",
    "\t\t\tsave[1][1] = \"RT\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\tsave[3][0] = \"RMS\"\n",
    "\t\tsave[3][1] = str(RMS)\n",
    "\t\tsave[4][0] = \"R2\"\n",
    "\t\tsave[4][1] = str(R2)\n",
    "\t\tsave[6][0] = \"case\"\n",
    "\t\tsave[6][1] = \"K-fold\" \n",
    "\t\tsave[6][2] = \"correct\"\n",
    "\t\tsave[6][3] = \"predict\"\n",
    "\t\tfor j in range(num_param):\n",
    "\t\t\tsave[6][5+j] = param_list[j]\n",
    "\n",
    "\t\tfor i in range(num_case):\n",
    "\t\t\tsave[i+7][0] = str(i)\n",
    "\t\t\tsave[i+7][1] = str(result_out_csv[i][0])\n",
    "\t\t\tsave[i+7][2] = str(result_out_csv[i][1])\n",
    "\t\t\tsave[i+7][3] = str(result_out_csv[i][2])\n",
    "\t\t\tfor j in range(num_param):\n",
    "\t\t\t\tsave[i+7][5+j] = str(result_out_csv[i][3+j])\n",
    "\telse:\n",
    "\t\tsave = np.empty(shape=(3,2), dtype=np.object)\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tfor j in range(2):\n",
    "\t\t\t\tsave[i][j] = \"\"\t\t\n",
    "\t\n",
    "\t\tsave[0][0] = obj_list[index]\n",
    "\t\tsave[1][0] = \"model\"\n",
    "\t\tif data.model ==1:\n",
    "\t\t\tsave[1][1] = \"NN\"\n",
    "\t\telif data.model ==2:\n",
    "\t\t\tsave[1][1] = \"SVR\"\n",
    "\t\telif data.model == 3:\n",
    "\t\t\tsave[1][1] = \"RT\"\n",
    "\t\tsave[2][0] = \"time(s)\"\n",
    "\t\tsave[2][1] = str(elapsed_time)\n",
    "\t\n",
    "\tfile_name = data.model_path + b\"/\" + data.response_name[index] + b\".csv\"\n",
    "\tfile_name = file_name.decode()\n",
    "\tnp.savetxt(file_name,save,fmt=\"%s\",delimiter=',')\n",
    "\n",
    "def loadcsv(csv_path,param_list,obj_list):\n",
    "\terror = 0\n",
    "\trow_offset = 0\n",
    "\tindex_param = []\n",
    "\tindex_result = []\n",
    "\tinput_param = None\n",
    "\tresult_correct = None\n",
    "\twith open(csv_path, \"r\",encoding='cp932') as f:\n",
    "\t\tfor tmp_col in csv.reader(f):\n",
    "\t\t\tbreak;\n",
    "\n",
    "\tcol_param = len(param_list)\t\n",
    "\tcol_correct = len(obj_list)\n",
    "\n",
    "\tif tmp_col[0] == \"Objective Values\":\n",
    "\t\trow_offset = 1\n",
    "\t\tcount = 0\n",
    "\t\twith open(csv_path, \"r\",encoding='cp932') as f:\n",
    "\t\t\tfor tmp_col in csv.reader(f):\n",
    "\t\t\t\tif count == 1:\n",
    "\t\t\t\t\tbreak;\n",
    "\t\t\t\tcount = count + 1\n",
    "\t\n",
    "\tcol = len(tmp_col)\n",
    "\n",
    "\tfor i in range(col_param):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tif param_list[i] == tmp_col[j]:\n",
    "\t\t\t\tindex_param.append(j) \n",
    "\t\t\t\tbreak;\n",
    "\t\t\tif j == (col-1):\n",
    "\t\t\t\tmessage_en = \"The variable name \" + param_list[i] + \"ï¿½@cannot be found in the csv file.\"\n",
    "\t\t\t\tmessage_jp = \"ï¿½Ïï¿½ï¿½ï¿½ \" + param_list[i] + \"ï¿½@ï¿½ï¿½csvfileï¿½ï¿½ï¿½çŒ©ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\t\t\t\treturn input_param,result_correct,error\n",
    "\t\n",
    "\tfor i in range(col_correct):\n",
    "\t\tfor j in range(col):\n",
    "\t\t\tif obj_list[i] == tmp_col[j]:\n",
    "\t\t\t\tindex_result.append(j) \n",
    "\t\t\t\tbreak;\n",
    "\t\t\tif j == (col-1):\n",
    "\t\t\t\tmessage_en = \"The variable name \" + param_list[i] + \"ï¿½@cannot be found in the csv file.\"\n",
    "\t\t\t\tmessage_jp = \"ï¿½Ïï¿½ï¿½ï¿½ \" + obj_list[i] + \"ï¿½@ï¿½ï¿½csvfileï¿½ï¿½ï¿½çŒ©ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\t\t\t\treturn input_param,result_correct,error\n",
    "\t\n",
    "\twith open(csv_path, \"r\",encoding='cp932') as f:\n",
    "\t\treader = csv.reader(f)\n",
    "\t\tstring_list = [row for row in reader]\n",
    "\trow = len(string_list)\n",
    "\t\n",
    "\tinput_param = np.zeros([row - 1 - row_offset,col_param])\n",
    "\tresult_correct = np.zeros([row - 1- row_offset,col_correct])\n",
    "\n",
    "\tfor i in range(row_offset,row - 1):\n",
    "\t\tfor j in range(col_param):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tinput_param[i-row_offset][j]=float(string_list[i+1][int(index_param[j])])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmessage_en = \"A character string was detected in the \" + str(i) + \"row and \" +  str(j) + \"column. Please delete it.\"\n",
    "\t\t\t\tmessage_jp = str(i + 2 + row_offset) + \"ï¿½sï¿½ï¿½ \" + str(j) + \"ï¿½ï¿½ï¿½Ú‚É•ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½mï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Bï¿½íœï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\t\t\t\n",
    "\tfor i in range(row_offset,row- 1):\n",
    "\t\tfor j in range(col_correct):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresult_correct[i - row_offset][j] = float(string_list[i+1][int(index_result[j])])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmessage_en = \"A character string was detected in the \" + str(i) + \"row and \" +  str(j) + \"column. Please delete it.\"\n",
    "\t\t\t\tmessage_jp = str(i + 2 + row_offset) + \"ï¿½sï¿½ï¿½ \" + str(j) + \"ï¿½ï¿½ï¿½Ú‚É•ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½mï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½Bï¿½íœï¿½ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\t\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\t\t\terror = 1\n",
    "\n",
    "\tlearn_data_tmp = []\n",
    "\tfor i in range(row_offset,row):\n",
    "\t\tlearn_data_tmp.append(string_list[i]) \n",
    "\n",
    "\treturn input_param,result_correct,error,learn_data_tmp\n",
    "\n",
    "def get_data_from_input_dialog():\n",
    "\tdialog = create_input_dialog()\n",
    "\tdialog.Show()\n",
    "\tif dialog.WasCancelled() == False:\n",
    "\t\tdata = get_values_from_input_dialog(dialog)\n",
    "\t\treturn data\n",
    "\treturn DialogData()\n",
    "\n",
    "def get_values_from_input_dialog(dialog):\n",
    "\tdata = DialogData()\n",
    "\tdata.model_path = dialog.GetValue(\"surrogate_model_path\")\n",
    "\tdata.csv_path = dialog.GetValue(\"csv_file_name\")\n",
    "\tdata.cross_val = dialog.GetValue(\"cross_val\")\n",
    "\tdata.model = dialog.GetValue(\"model\")\n",
    "\tdata.cross_frag = dialog.GetValue(\"cross_frag\")\n",
    "\tparam_tmp = dialog.GetValue(\"response_name\")\n",
    "\tparam_tmp = param_tmp.decode()\n",
    "\tparam = param_tmp.split(',')\n",
    "\t\n",
    "\tif data.csv_path == b\"\":\n",
    "\t\tmessage_en = \"Specify input file name.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½Íƒtï¿½@ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½wï¿½è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif data.model_path == b\"\":\n",
    "\t\tmessage_en = \"Specify output directory name.\"\n",
    "\t\tmessage_jp = \"ï¿½oï¿½Íƒtï¿½Hï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½ï¿½ï¿½wï¿½è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isfile(data.csv_path) == 0 :\n",
    "\t\tmessage_en = \"The input file path is incorrect.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½Íƒtï¿½@ï¿½Cï¿½ï¿½ï¿½pï¿½Xï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\n",
    "\tif os.path.isdir(data.model_path) == 0:\n",
    "\t\tmessage_en = \"The output folder is incorrect.\"\n",
    "\t\tmessage_jp = \"ï¿½oï¿½Íƒtï¿½Hï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tif param_tmp == \"\":\n",
    "\t\tmessage_en = \"Specify the name of the response value.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½lï¿½Ì–ï¿½ï¿½Oï¿½ï¿½ï¿½wï¿½è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tif data.cross_val <= 1:\n",
    "\t\tmessage_en = \"Set the number of divisions to 2 or more.\"\n",
    "\t\tmessage_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½2ï¿½Èï¿½ï¿½Åİ’è‚µï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn data\n",
    "\t\n",
    "\tfor i in range(len(param)):\n",
    "\t\tError = 0\n",
    "\t\tfor j in range(len(data.response_name)):\n",
    "\t\t\tif param[i].encode() == data.response_name[j]:\n",
    "\t\t\t\tError = 1\n",
    "\t\tif Error == 0:\n",
    "\t\t\tdata.response_name.append(param[i].encode())\n",
    "\n",
    "\tdata.isValid = True\n",
    "\treturn data\n",
    "\n",
    "def create_input_dialog():\n",
    "\tapp = designer.GetApplication()\n",
    "\tdialog = app.CreateDialogBox()\n",
    "\n",
    "\ttitle_jp = \"ï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ì¬(ï¿½ï¿½ï¿½ï¿½)\"\n",
    "\ttitle_en = \"Create a surrogate model (beta version)\"\n",
    "\tinputlbl_jp = \"ï¿½ï¿½ï¿½ï¿½:\"\n",
    "\tinputlbl_en = \"Input:\"\n",
    "\toutputlbl_jp = \"ï¿½oï¿½ï¿½:\"\n",
    "\toutputlbl_en = \"Output:\"\n",
    "\tcsvinput_jp = \"ï¿½wï¿½Kï¿½fï¿½[ï¿½^ï¿½Zï¿½bï¿½g\"\n",
    "\tcsvinput_en = \"Training dataset\" \n",
    "\tsurrogate_path_jp = \"ï¿½ã—ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½oï¿½Íƒpï¿½X\"\n",
    "\tsurrogate_path_en = \"Surrogate model output path\" \n",
    "\tcross_val_jp = \"K-ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\"\n",
    "\tcross_val_en = \"K-Fold  Cross validation\"\t\n",
    "\tfold_val_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\"\n",
    "\tfold_val_en = \"K-fold\"\n",
    "\tresponse_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½l\"\n",
    "\tresponse_en = \"Response value\"\t\n",
    "\tresponse_name_jp = \"ï¿½Ïï¿½ï¿½ï¿½ï¿½iï¿½Jï¿½ï¿½ï¿½}ï¿½ï¿½ï¿½Ø‚ï¿½ï¿½j\"\n",
    "\tresponse_name_en = \"Variable name(Comma separated)\"\t\n",
    "\tcross_use_jp = \"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\"\n",
    "\tcross_use_en = \"Cross validation\"\n",
    "\tcross_notuse_jp = \"ï¿½ï¿½ï¿½Ø‚È‚ï¿½\" \n",
    "\tcross_notuse_en = \"No verification\"\n",
    "\n",
    "\tdialog.SetTranslation(title_en, title_jp)\n",
    "\n",
    "\tdialog.SetTranslation(response_en, response_jp)\n",
    "\tdialog.SetTranslation(response_name_en, response_name_jp)\n",
    "\tdialog.SetTranslation(fold_val_en, fold_val_jp)\n",
    "\tdialog.SetTranslation(cross_val_en, cross_val_jp)\n",
    "\tdialog.SetTranslation(inputlbl_en, inputlbl_jp)\n",
    "\tdialog.SetTranslation(outputlbl_en, outputlbl_jp)\n",
    "\tdialog.SetTranslation(csvinput_en, csvinput_jp)\n",
    "\tdialog.SetTranslation(surrogate_path_en, surrogate_path_jp)\n",
    "\tdialog.SetTranslation(cross_use_en, cross_use_jp)\n",
    "\tdialog.SetTranslation(cross_notuse_en, cross_notuse_jp)\n",
    "\n",
    "\tdialog.AddLabel(response_en)\n",
    "\tdialog.AddString(\"response_name\", response_name_en, \"\")\n",
    "\tdialog.AddLine()\n",
    "\t\n",
    "\tdialog.AddLabel(cross_val_en)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_use_en, 1)\n",
    "\tdialog.AddInteger(\"cross_val\", fold_val_en, 5)\n",
    "\tdialog.AddRadio(\"cross_frag\", cross_notuse_en, 2)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.AddRadio(\"model\", \"Neural network\", 1)\n",
    "\tdialog.AddRadio(\"model\", \"Support Vector Regression\", 2)\n",
    "\tdialog.AddRadio(\"model\", \"Regression tree\", 3)\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\tdialog.SetTitle(title_en)\n",
    "\tdialog.AddLabel(inputlbl_en)\n",
    "\tdialog.AddOpenFilename(\"csv_file_name\", csvinput_en,\"\",\"CSV file (*.csv)\")\n",
    "\t\n",
    "\tdialog.AddLine()\n",
    "\tdialog.AddLabel(outputlbl_en)\n",
    "\tdialog.AddDirectoryPath(\"surrogate_model_path\", surrogate_path_en,\"./\")\n",
    "\tdialog.AddLine()\n",
    "\n",
    "\treturn dialog\n",
    "\n",
    "def show_normal_exit_message():\n",
    "\ttitle_en = \"Finished\"\n",
    "\ttitle_jp = \"ï¿½Iï¿½ï¿½\"\n",
    "\tmessage_en = \"Finished.\"\n",
    "\tmessage_jp = \"ï¿½Iï¿½ï¿½\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_error_exit_message(message_en, message_jp):\n",
    "\ttitle_en = \"Error\"\n",
    "\ttitle_jp = \"ï¿½Gï¿½ï¿½ï¿½[\"\n",
    "\n",
    "\tshow_message(title_en, title_jp, message_en, message_jp)\n",
    "\n",
    "def show_message(title_en, title_jp, message_en, message_jp):\n",
    "\tmsgdlg = app.CreateDialogBox()\n",
    "\n",
    "\tmsgdlg.SetTranslation(title_en, title_jp)\n",
    "\tmsgdlg.SetTranslation(message_en, message_jp)\n",
    "\n",
    "\tmsgdlg.SetCancelButtonVisible(False)\n",
    "\tmsgdlg.SetTitle(title_en)\n",
    "\tmsgdlg.AddLabel(message_en)\n",
    "\tmsgdlg.Show()\n",
    "\n",
    "if py_error == 0:\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_54592/2700465325.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_54592/2700465325.py\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    AnalysisGroup  = app.GetCurrentAnalysisGroup()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\tobj_list = []\n",
    "\tparam_list = []\n",
    "\tmodel_save_path = []\n",
    "\trandom_seed = 0\n",
    "\tnum_case = 0\n",
    "\tRMS = 0.0\n",
    "\tR2 = 0.0\n",
    "\tError = 0\n",
    "\trandom_seed = random.randint(0,2**32-1)\n",
    "\t\t\n",
    " AnalysisGroup  = app.GetCurrentAnalysisGroup()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tAnalysisGroup = app.GetCurrentStudy()\n",
    "\tif AnalysisGroup.IsValid() == False:\n",
    "\t\tmessage_en = \"The study or analysis group cannot be found.\"\n",
    "\t\tmessage_jp = \"studyï¿½Ü‚ï¿½ï¿½Í‰ï¿½ï¿½ÍƒOï¿½ï¿½ï¿½[ï¿½vï¿½ï¿½ï¿½ï¿½ï¿½Â‚ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½ï¿½B\"\n",
    "\t\tshow_error_exit_message(message_en, message_jp)\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jmagì—ì„œ export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import os\n",
    "from win32com import client  #activeXì—°ê²° ëª¨ë“ˆ\n",
    "\n",
    "jprojfile = u'D:\\KDH\\Thesis\\HDEV\\01_JMAG\\HYH\\ironloss.jproj'\n",
    "dname=u'Gap magnetic flux density'\n",
    "\n",
    "\n",
    "designer = client.dynamic.Dispatch('designer.Application.210') #ì œì´ë§¥ ì—°ê²° ë²„ì ¼ì§€ì •ì‹œ   client.dynamic.Dispatch('designer.Application.180')\n",
    "designer.SetCurrentStudy(u\"Load_Hysteresis_steel_noload\")\n",
    "designer.GetDataManager().GetGraphModel(u\"[Cases] untitled 1\").WriteTable(u\"D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_r_case_no_load_4p12s.csv\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyleecan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:55] Starting running simulation tuto_jmag (machine=SPMSM_4p12s)\n",
      "[20:04:55] Starting Magnetic module\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:04:56] Solving time steps: 0%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:04] Solving time steps: 25%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:10] Solving time steps: 50%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:15] Solving time steps: 75%\n",
      "[20:05:21] Solving time step: 100%\n",
      "[20:05:21] Solving time step: 100%\n",
      "[20:05:21] Solving time step: 100%\n",
      "[20:05:22] Solving time step: 100%\n",
      "[20:05:22] Starting Force module\n",
      "[20:05:22] End of simulation tuto_jmag\n",
      "[20:05:22] Starting running simulation tuto_jmag (machine=SPMSM_4p12s)\n",
      "[20:05:22] Starting Magnetic module\n",
      "[20:05:22] Solving time steps: 0%\n",
      "[20:05:22] Solving time steps: 0%\n",
      "[20:05:23] Solving time steps: 0%\n",
      "[20:05:23] Solving time steps: 0%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:29] Solving time steps: 25%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:35] Solving time steps: 50%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:40] Solving time steps: 75%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Solving time step: 100%\n",
      "[20:05:46] Starting Force module\n",
      "[20:05:46] End of simulation tuto_jmag\n"
     ]
    }
   ],
   "source": [
    "# Import Pyleecan modules\n",
    "from numpy import exp, sqrt, pi\n",
    "from os.path import join\n",
    "from pyleecan.Classes.Simu1 import Simu1\n",
    "from pyleecan.Classes.InputCurrent import InputCurrent\n",
    "from pyleecan.Classes.OPdq import OPdq\n",
    "from pyleecan.Classes.MagFEMM import MagFEMM\n",
    "from pyleecan.Classes.ForceMT import ForceMT\n",
    "from pyleecan.Classes.Output import Output\n",
    "from pyleecan.Functions.load import load\n",
    "from pyleecan.definitions import DATA_DIR\n",
    "\n",
    "# Load the machine\n",
    "SPMSM_4p12s = load(join(DATA_DIR, \"Machine\", \"SPMSM_4p12s.json\"))\n",
    "\n",
    "# Simulation initialization\n",
    "simu = Simu1(name=\"tuto_jmag\", machine=SPMSM_4p12s)\n",
    "\n",
    "# Definition of the enforced output of the electrical module\n",
    "simu.input = InputCurrent(\n",
    "    Na_tot=121 * 4,\n",
    "    Nt_tot=121 * 4,\n",
    ")\n",
    "# Set Id/Iq according to I0/Phi0\n",
    "simu.input.OP = OPdq(N0=1000)\n",
    "simu.input.OP.set_I0_Phi0(I0=250 / sqrt(2), Phi0=140*pi/180)\n",
    "\n",
    "# Definition of the magnetic simulation: with periodicity\n",
    "simu.mag = MagFEMM(is_periodicity_a=True, is_periodicity_t=True, nb_worker=4)\n",
    "simu.force = ForceMT(is_periodicity_a=True, is_periodicity_t=True)\n",
    "\n",
    "# Definition of the open-circuit simulation\n",
    "simu2 = simu.copy()\n",
    "simu2.input.OP.set_Id_Iq(Id=0,Iq=0)\n",
    "\n",
    "# Run simulations\n",
    "out = simu.run()\n",
    "out2 = simu2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##python ê¸°ë³¸ csv ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciDataTool import Data1D, DataLinspace, DataPattern, DataTime, DataFreq, VectorField\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "csv_pd=pd.read_csv('D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_t_case_no_load_4p12s.csv')\n",
    "csv_dict=csv_pd.to_numpy()\n",
    "csv_dict=np.delete(csv_dict,0,1)\n",
    "csv_dict=csv_dict.transpose()\n",
    "\n",
    "# csv_file=open('D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_r_case1_4p12s.csv',\"r\",encoding=\"ms932\",errors=\"\",newline=\"\")\n",
    "\n",
    "#f = csv.DictReader(csv_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## out.mag check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison FEMM & JMAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyleecan.Functions.Plot import dict_2D, dict_3D\n",
    "from numpy import newaxis\n",
    "np.shape(out.mag.B.components['radial'].values)\n",
    "csv_ndarray=csv_dict[:,:,newaxis]\n",
    "out_jmag=out\n",
    "# out2.mag.B.components['radial'].plot_2D_Data(\"angle\")\n",
    "out_jmag.mag.B.components['radial'].values=csv_ndarray\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"angle\")\n",
    "\n",
    "out_jmag.mag.B.plot_2D_Data(\n",
    "    \"angle\", component_list=[\"radial\"], data_list=[out2.mag.B], legend_list=[\"Load\", \"Noload\"],is_auto_range=False\n",
    ")\n",
    "\n",
    "# out_jmag.mag.B.components['tangential'].plot_2D_Data(\"angle\")\n",
    "\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"angle\")\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"time\")\n",
    "\n",
    "# out_jmag.mag.B.components['radial'].plot_2D_Data(\"wavenumber=[0,96]\")\n",
    "\n",
    "# out_jmag.mag.B.components['tangential'].plot_2D_Data(\"angle\")\n",
    "# out_jmag.mag.B.components['tangential'].plot_2D_Data(\"wavenumber=[0,96]\")\n",
    "# out_jmag.mag.B.plot_3D_Data(\"time\", \"angle{Â°}\", component_list=[\"radial\"], **dict_3D,is_2D_view=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Time_periodic = DataLinspace(\n",
    "#     name=\"time\",\n",
    "#     unit=\"s\",\n",
    "#     initial=0,\n",
    "#     final=5,\n",
    "#     number=5,\n",
    "#     include_endpoint=False,\n",
    "#     symmetries={\"period\": 6},\n",
    "# )\n",
    "# print(Time_periodic.get_values(is_oneperiod=True))\n",
    "# # # print(Time_periodic.get_values())\n",
    "# # print(out.mag.B.components['radial'])\n",
    "# # dir(out.mag.B.components['radial'])\n",
    "# # print(out.mag.B.components['radial'])\n",
    "\n",
    "# # out.mag.B.components\n",
    "\n",
    "# #aa=list(a)\n",
    "# from pprint import pprint as pp\n",
    "# f = csv.DictReader(csv_file)\n",
    "# #ff=list(f)[10]\n",
    "# # for row in f: \n",
    "#     # print(row)\n",
    "#     # print(type(row))\n",
    "\n",
    "# csv_file.close()\n",
    "# #type(row)\n",
    "\n",
    "# #row.keys()\n",
    "#pp(row)\n",
    "\n",
    "#type(f)\n",
    "#len(row)\n",
    "\n",
    "#row.values()\n",
    "# ordered_dict_from_csv=list(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì—¬ê¸°ì„œë¶€í„° Mesh solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.fft(csv_ndarray[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(121, 121, 1)\n",
      "(121,)\n",
      "(121,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "a=out.mag.B.components['tangential']._get_values()\n",
    "\n",
    "axe=out.mag.B.components['tangential'].get_axes()\n",
    "#print(axe)\n",
    "print(type(a))\n",
    "np.shape(a)\n",
    "a0=axe[0].get_values()\n",
    "a1=axe[1].get_values()\n",
    "a2=axe[2].get_values()\n",
    "type(a0)\n",
    "np.shape(a0)\n",
    "type(a1)\n",
    "np.shape(a1)\n",
    "#a2\n",
    "#a=out.mag.B.components['radial']._get_values()\n",
    "type(a)\n",
    "print(np.shape(a))\n",
    "print(np.shape(a0))\n",
    "print(np.shape(a1))\n",
    "print(np.shape(a2))\n",
    "\n",
    "#print(axe[0].get_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4=a[0][0:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import ones\n",
    "out_dict = dict()\n",
    "out_dict[\"Bt\"] = ones((100, 504))\n",
    "aa=ones((100, 504))\n",
    "out_dict['Bt'][1]\n",
    "type(out_dict)\n",
    "type(aa)\n",
    "\n",
    "\n",
    "out_dict.pop(\"Bt\")\n",
    "#ii=nt\n",
    "#jj=na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_32812/2473797778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrad2deg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'radial'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#out.mag.B.components['radial'].get_axes()[2].symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from SciDataTool import Data1D, DataLinspace, DataPattern, DataTime, DataFreq, VectorField\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''\n",
    "at=np.transpose(ag)\n",
    "print(np.shape(ag))\n",
    "print(np.shape(at))\n",
    "out_dict = dict()\n",
    "out_dict[\"Bt\"] = np.ones((122, 121))\n",
    "out_dict[\"Bt\"] = at\n",
    "out_dict['Bt'][1,0]\n",
    " '''\n",
    "\n",
    "df=pd.read_csv('D:/KDH/Thesis/HDEV/01_JMAG/HYH/B_r_case1_4p12s.csv')\n",
    "ag=df.values\n",
    "radial=out.mag.B.components['radial']._get_values()\n",
    "axes=out.mag.B.components['radial'].get_axes()[1]\n",
    "\n",
    "dd=axes.get_values()\n",
    "dd=np.rad2deg(dd)\n",
    "out.mag.B.components['radial'].get_axes()[2].get_values()\n",
    "#out.mag.B.components['radial'].get_axes()[2].symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30-12280\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mag.B.get_mag_rphiz_along('axes_list')\n",
    "\n",
    "\n",
    "\n",
    "time = np.linspace(0,10,10,endpoint=False)\n",
    "Time = Data1D(\n",
    "    name=\"time\",\n",
    "    unit=\"s\",\n",
    "    values=time,\n",
    ")\n",
    "fieldA = np.ones(10)\n",
    "fieldB = np.ones(10) * 5\n",
    "fieldC = np.ones(10) * 10\n",
    "new_field = np.array([fieldA, fieldB, fieldC])\n",
    "\n",
    "Phases = Data1D(name=\"phases\", unit=\"\", values=[\"Phase A\",\"Phase B\",\"Phase C\"], is_components=True)\n",
    "Field = DataTime(\n",
    "    name=\"Example phase field\",\n",
    "    symbol=\"X\",\n",
    "    axes=[Phases, Time],\n",
    "    values=new_field,\n",
    ")   \n",
    "results = Field.get_along(\"time=0.01\", \"angle{Â°}\")\n",
    "out.mag.B.components['radial']=Field\n",
    "\n",
    "out.mag.B.get_rphiz_along('angle')\n",
    "#out.mag.B.components['radial']\n",
    "#print(out.mag.B.components['radial']._get_values())\n",
    "\n",
    "#print(out.mag.B.components['tangential']._get_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Make the data to Scidata format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mag.B.components['tangential']._get_axes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mag.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "external B data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B_elem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_32812/1082511153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#temp comp_flux_airgap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m B_sol = build_solution_vector(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mB_elem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0maxis_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Magnetic Flux Density\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'B_elem' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#temp comp_flux_airgap\n",
    "B_sol = build_solution_vector(\n",
    "    field=B_elem,\n",
    "    axis_list=axis_list,\n",
    "    name=\"Magnetic Flux Density\",\n",
    "    symbol=\"B\",\n",
    "    unit=\"T\",\n",
    ")\n",
    "\n",
    "list_solution = [B_sol, H_sol, mu_sol, A_sol]\n",
    "\n",
    "#\n",
    "out_dict[\"meshsolution\"] = build_meshsolution(\n",
    "        list_solution=list_solution,\n",
    "        label=\"FEMM 2D Magnetostatic\",\n",
    "        list_mesh=meshFEMM,\n",
    "        group=groups,\n",
    "    )\n",
    "\n",
    "\n",
    "##not\n",
    "field=B_elem,\n",
    "axis_list=axis_list,\n",
    "\n",
    "\n",
    "symbol=\"B\"\n",
    "unit=\"T\"\n",
    "name=\"Airgap Magnetic Flux Density\"\n",
    "\n",
    "\n",
    "##build_solution_vector \n",
    "#build_solution_vector(field, axis_list, name=\"\", symbol=\"\", unit=\"\", is_real=True):\n",
    "\n",
    "components = {}\n",
    "\n",
    "x_data = DataTime(\n",
    "    name=name,\n",
    "    unit=unit,\n",
    "    symbol=symbol + \"x\",\n",
    "    axes=axis_list,\n",
    "    values=field[..., 0],\n",
    "    is_real=is_real,\n",
    ")\n",
    "components[\"comp_x\"] = x_data\n",
    "\n",
    "y_data = DataTime(\n",
    "    name=name,\n",
    "    unit=unit,\n",
    "    symbol=symbol + \"y\",\n",
    "    axes=axis_list,\n",
    "    values=field[..., 1],\n",
    "    is_real=is_real,\n",
    ")\n",
    "components[\"comp_y\"] = y_data\n",
    "\n",
    "if field.shape[-1] == 3 and not np_all((field[..., 2] == 0)):\n",
    "    z_data = DataTime(\n",
    "        name=name,\n",
    "        unit=unit,\n",
    "        symbol=symbol + \"z\",\n",
    "        axes=axis_list,\n",
    "        values=field[..., 2],\n",
    "        is_real=is_real,\n",
    "    )\n",
    "    components[\"comp_z\"] = z_data\n",
    "\n",
    "\n",
    "\n",
    "Tempfieled = VectorField(name=name, symbol=symbol, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meshFEMM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KDH201~1\\AppData\\Local\\Temp/ipykernel_32812/596049673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Define axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mindices_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeshFEMM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"triangle\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mIndices_Cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"indice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0maxis_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndices_Cell\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meshFEMM' is not defined"
     ]
    }
   ],
   "source": [
    "        from pyleecan.Functions.MeshSolution.build_solution_vector import build_solution_vector\n",
    "\n",
    "        # Define axis\n",
    "        Time = Time.copy()\n",
    "        indices_cell = meshFEMM[0].cell[\"triangle\"].indice\n",
    "        Indices_Cell = Data1D(name=\"indice\", values=indices_cell, is_components=True)\n",
    "        axis_list = [Time, Indices_Cell]\n",
    "\n",
    "        B_sol = build_solution_vector(\n",
    "            field=B_elem,\n",
    "            axis_list=axis_list,\n",
    "            name=\"Magnetic Flux Density\",\n",
    "            symbol=\"B\",\n",
    "            unit=\"T\",\n",
    "        )\n",
    "        H_sol = build_solution_vector(\n",
    "            field=H_elem,\n",
    "            axis_list=axis_list,\n",
    "            name=\"Magnetic Field\",\n",
    "            symbol=\"H\",\n",
    "            unit=\"A/m\",\n",
    "        )\n",
    "        mu_sol = build_solution_data(\n",
    "            field=mu_elem,\n",
    "            axis_list=axis_list,\n",
    "            name=\"Magnetic Permeability\",\n",
    "            symbol=\"\\mu\",\n",
    "            unit=\"H/m\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('py38_pyleecan139')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "199ee5ddd5cf9db80b3c3131ae104b574c9fd5dd6255d9f837b6f7ea953865a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
